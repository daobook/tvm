
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Relay 中的模式匹配 &#8212; TVM  文档</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../../_static/translations.js"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="shortcut icon" href="../../../_static/tvm-logo-square.png"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="Hybrid 前端语言参考" href="hybrid_script.html" />
    <link rel="prev" title="Relay 核心张量算子" href="relay_op.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/tvm-logo-small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TVM  文档</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   TVM 文档
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../start.html">
   快速上手
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../install/index.html">
     安装 TVM
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../install/from_source.html">
       从源码安装
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../install/nnpack.html">
         NNPACK Contrib Installation
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../install/docker.html">
       Docker 镜像
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../install/nnpack.html">
       NNPACK Contrib Installation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../contribute/index.html">
     贡献者指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/community.html">
       TVM 社区指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/pull_request.html">
       提交 Pull Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/code_review.html">
       Code Reviews
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/committer_guide.html">
       Committer Guide
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/document.html">
       Documentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/code_guide.html">
       Code Guide and Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/git_howto.html">
       Git Usage Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/ci.html">
       Using TVM’s CI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/release_process.html">
       Release Process
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../contribute/error_handling.html">
       Error Handling Guide
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../user-guide.html">
   用户手册
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorial/index.html">
     用户指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/introduction.html">
       TVM 和模型优化的概述
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tvmc_command_line_driver.html">
       用 TVMC 编译和优化模型
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tvmc_python.html">
       开始使用 TVMC Python：TVM 的高级 API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/autotvm_relay_x86.html">
       用 Python 接口编译和优化模型（AutoTVM）
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tensor_expr_get_started.html">
       使用张量表达式处理算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/autotvm_matmul_x86.html">
       用调度模板和 AutoTVM 优化算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/auto_scheduler_matmul_x86.html">
       使用自动调度优化运算
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/tensor_ir_blitz_course.html">
       TensorIR 的突击课程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/cross_compilation_and_rpc.html">
       交叉编译和RPC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/relay_quick_start.html">
       编译深度学习模型的快速入门教程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/intro_topi.html">
       TOPI 简介
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorial/uma.html">
       通过 UMA 使您的硬件加速器 TVM-ready
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../how_to/index.html">
     How To 指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/compile_models/index.html">
       编译深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_pytorch.html">
         编译 PyTorch 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_tensorflow.html">
         Compile Tensorflow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_mxnet.html">
         编译 MXNet 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_onnx.html">
         Compile ONNX Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_keras.html">
         Compile Keras Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_tflite.html">
         Compile TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_coreml.html">
         Compile CoreML Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_darknet.html">
         Compile YOLO-V2 and YOLO-V3 in DarkNet Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_caffe2.html">
         Compile Caffe2 Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_oneflow.html">
         Compile OneFlow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/compile_models/from_paddle.html">
         Compile PaddlePaddle Models
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/deploy/index.html">
       部署模型并集成到 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/cpp_deploy.html">
         使用 C++ API 部署 TVM Module
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/android.html">
         Deploy to Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/integrate.html">
         集成 TVM 到你的项目
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/hls.html">
         HLS Backend Example
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/arm_compute_lib.html">
         集成 Relay Arm
         <sup>
          ®
         </sup>
         计算库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/tensorrt.html">
         Relay TensorRT Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/vitis_ai.html">
         Vitis AI Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy/bnns.html">
         Relay BNNS Integration
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/deploy_models/index.html">
       部署深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_model_on_android.html">
         Deploy the Pretrained Model on Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_model_on_rasp.html">
         Deploy the Pretrained Model on Raspberry Pi
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_object_detection_pytorch.html">
         编译 PyTorch 目标检测模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_prequantized.html">
         使用 TVM 部署框架预量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_prequantized_tflite.html">
         Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_quantized.html">
         在 CUDA 上部署已量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_sparse.html">
         Deploy a Hugging Face Pruned Model on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/deploy_models/deploy_ssd_gluoncv.html">
         部署 Single Shot Multibox Detector(SSD) 模型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/work_with_relay/index.html">
       使用 Relay
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_relay/build_gcn.html">
         构建图卷积网络
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_relay/using_external_lib.html">
         在 Relay 中使用外部库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_relay/using_pipeline_executor.html">
         在 Relay 中使用管道执行器
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_relay/using_relay_viz.html">
         使用 Relay Visualizer 可视化 Relay
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/work_with_schedules/index.html">
       使用 Tensor Expression 和 Schedules
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/schedule_primitives.html">
         TVM 中的调度原语
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/reduction.html">
         Reduction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/intrin_math.html">
         Intrinsics and Math Functions
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/scan.html">
         Scan and Recurrent Kernel
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/extern_op.html">
         外部张量函数
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/tensorize.html">
         Use Tensorize to Leverage Hardware Intrinsics
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/tuple_inputs.html">
         Compute and Reduce with Tuple Inputs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_schedules/tedd.html">
         使用 TEDD 进行可视化
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/optimize_operators/index.html">
       优化张量算子
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/optimize_operators/opt_gemm.html">
         How to optimize GEMM on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/optimize_operators/opt_conv_cuda.html">
         How to optimize convolution on GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/optimize_operators/opt_conv_tensorcore.html">
         How to optimize convolution using TensorCores
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/tune_with_autotvm/index.html">
       Auto-Tune with Templates and AutoTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autotvm/tune_conv2d_cuda.html">
         Tuning High Performance Convolution on NVIDIA GPUs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autotvm/tune_relay_cuda.html">
         Auto-tuning a Convolutional Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autotvm/tune_relay_x86.html">
         Auto-tuning a Convolutional Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autotvm/tune_relay_arm.html">
         Auto-tuning a Convolutional Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autotvm/tune_relay_mobile_gpu.html">
         Auto-tuning a Convolutional Network for Mobile GPU
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/tune_with_autoscheduler/index.html">
       使用自动调度器进行无模板调度
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.html">
         Auto-scheduling a Convolution Layer for GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autoscheduler/tune_network_x86.html">
         Auto-scheduling a Neural Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autoscheduler/tune_network_cuda.html">
         Auto-scheduling a Neural Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autoscheduler/tune_network_arm.html">
         Auto-scheduling a Neural Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autoscheduler/tune_network_mali.html">
         Auto-scheduling a Neural Network for mali GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/tune_with_autoscheduler/tune_sparse_x86.html">
         Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/work_with_microtvm/index.html">
       使用 microTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_aot.html">
         microTVM Host-Driven AoT
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_autotune.html">
         使用 microTVM Autotuning
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_ethosu.html">
         在 bare metal Arm® Cortex®-M55 CPU 和 Ethos™-U55 NPU 上运行 TVM
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_reference_vm.html">
         microTVM 参考虚拟机
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_tflite.html">
         microTVM with TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_train.html">
         Training Vision Models for microTVM on Arduino
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/work_with_microtvm/micro_tvmc.html">
         Executing a Tiny Model with TVMC Micro
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/extend_tvm/index.html">
       拓展 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/extend_tvm/low_level_custom_pass.html">
         编写定制 Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/extend_tvm/use_pass_infra.html">
         如何使用 TVM Pass Infra
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/extend_tvm/use_pass_instrument.html">
         如何使用 TVM Pass Instrument
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/extend_tvm/bring_your_own_datatypes.html">
         自定义 TVM 数据类型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../how_to/profile/index.html">
       模型剖析
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../how_to/profile/papi.html">
         PAPI 快速上手
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../errors.html">
       处理 TVM 的错误
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../faq.html">
       常见问题
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../developer-guide.html">
   开发手册
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dev/tutorial/index.html">
     开发者教程
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/tutorial/codebase_walkthrough.html">
       TVM 代码库的实例演练
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../dev/how_to/how_to.html">
     开发者指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/debugging_tvm.html">
       Debugging TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/relay_add_op.html">
       添加算子到 Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/relay_add_pass.html">
       Adding a Compiler Pass to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/relay_bring_your_own_codegen.html">
       带你自己的 Codegen 到 TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../dev/how_to/pytest_target_parametrization.html">
       Python 目标参数化
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../arch/index.html">
   设计与架构
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/runtime.html">
     TVM 运行时系统
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/debugger.html">
     调试器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/virtual_machine.html">
     将 VM 放入 TVM：Relay Virtual Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/introduction_to_module_serialization.html">
     模块序列化简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/pass_infra.html">
     Pass Infrastructure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/device_target_interactions.html">
     Device/Target Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/inferbound.html">
     InferBound Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/hybrid_script.html">
     Hybrid 前端开发指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/relay_intro.html">
     Relay IR 简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/relay_op_strategy.html">
     Relay 算子策略
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/convert_layout.html">
     Convert Layout Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/benchmark.html">
     基准性能日志格式
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/frontend/tensorflow.html">
     TensorFlow Frontend
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/security.html">
     安全指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/microtvm_design.html">
     microTVM Design Document
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/microtvm_project_api.html">
     microTVM Project API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/model_library_format.html">
     Model 库格式
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../topic-guides.html">
   主题指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../topic/microtvm/index.html">
     microTVM：裸机上的 TVM
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../topic/vta/index.html">
     VTA：通用张量加速器
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../topic/vta/install.html">
       VTA 安装指南
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../topic/vta/dev/index.html">
       VTA 设计和开发指南
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
      <label for="toctree-checkbox-25">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/dev/config.html">
         VTA 配置
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/dev/hardware.html">
         VTA 硬件指南
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../topic/vta/tutorials/index.html">
       VTA 教程
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
      <label for="toctree-checkbox-26">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/matrix_multiply.html">
         简单的矩阵乘法
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/frontend/index.html">
         编译深度学习模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/optimize/index.html">
         优化 Tensor 算子
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../topic/vta/tutorials/autotvm/index.html">
         自动调优
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../../reference-guide.html">
   参考指南
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
  <label for="toctree-checkbox-27">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     语言参考
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
    <label for="toctree-checkbox-28">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="relay_expr.html">
       Relay 表达式
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="relay_type.html">
       Relay 类型系统
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="relay_adt.html">
       Algebraic Data Types in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="relay_op.html">
       Relay 核心张量算子
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Relay 中的模式匹配
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hybrid_script.html">
       Hybrid 前端语言参考
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../api/python/index.html">
     Python API
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/runtime.html">
       tvm.runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/ndarray.html">
       tvm.runtime.ndarray
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/error.html">
       tvm.error
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/ir/module.html">
       tvm.ir.module
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/ir/index.html">
       tvm.ir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/target.html">
       tvm.target
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/tir.html">
       tvm.tir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/te.html">
       tvm.te
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/driver.html">
       tvm.driver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/index.html">
       tvm.relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/frontend.html">
       tvm.relay.frontend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/nn.html">
       tvm.relay.nn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/vision.html">
       tvm.relay.vision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/image.html">
       tvm.relay.image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/transform.html">
       tvm.relay.transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/analysis.html">
       tvm.relay.analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/backend.html">
       tvm.relay.backend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/dataflow_pattern.html">
       tvm.relay.dataflow_pattern
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/relay/testing.html">
       tvm.relay.testing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/autotvm.html">
       tvm.autotvm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/auto_scheduler.html">
       tvm.auto_scheduler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/rpc.html">
       tvm.rpc
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/micro.html">
       tvm.micro
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/contrib.html">
       tvm.contrib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/graph_executor.html">
       tvm.contrib.graph_executor
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/topi.html">
       tvm.topi
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/python/vta/index.html">
       vta
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/links.html">
     其他 API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../publications.html">
     出版物
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../refs/index.html">
   参考
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../refs/_ffi/index.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       _ffi
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/base.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.base
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/libinfo.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.libinfo
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/object.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi._ctypes.object
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/registry.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.registry
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../refs/_ffi/runtime_ctypes.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.runtime_ctypes
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/docs/reference/langref/relay_pattern.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> 导航
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pattern-examples">
   模式示例
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-one-of-two-ops">
     匹配两个 Ops 中的一个
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-an-op-with-attributes">
     使用属性匹配 Op
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-an-optional-op">
     匹配 Optional Op
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-types">
     匹配类型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-non-call-nodes">
     匹配 Non-Call 节点
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-diamonds-and-post-dominator-graphs">
     匹配 Diamond 和 Post-Dominator Graph
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matching-fuzzy-patterns">
   模糊匹配模式
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pattern-language-design">
   模式语言设计
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#expression-pattern">
     表达式模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wildcard">
     通配符
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#type-pattern">
     类型模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dtype-pattern">
     DType 模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#shape-pattern">
     Shape 模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attribute-pattern">
     属性模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#variable-pattern">
     变量模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternate">
     备用
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#domination">
     Domination
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#function-pattern">
     函数模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if-pattern">
     If 模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-pattern">
     Let 模式
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   应用
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pattern-rewriting">
     模式重写
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pattern-partitioning">
     模式分区
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Relay 中的模式匹配</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> 导航 </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pattern-examples">
   模式示例
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-one-of-two-ops">
     匹配两个 Ops 中的一个
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-an-op-with-attributes">
     使用属性匹配 Op
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-an-optional-op">
     匹配 Optional Op
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-types">
     匹配类型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-non-call-nodes">
     匹配 Non-Call 节点
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching-diamonds-and-post-dominator-graphs">
     匹配 Diamond 和 Post-Dominator Graph
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matching-fuzzy-patterns">
   模糊匹配模式
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pattern-language-design">
   模式语言设计
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#expression-pattern">
     表达式模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wildcard">
     通配符
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#type-pattern">
     类型模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dtype-pattern">
     DType 模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#shape-pattern">
     Shape 模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attribute-pattern">
     属性模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#variable-pattern">
     变量模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternate">
     备用
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#domination">
     Domination
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#function-pattern">
     函数模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if-pattern">
     If 模式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-pattern">
     Let 模式
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   应用
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pattern-rewriting">
     模式重写
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pattern-partitioning">
     模式分区
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="pattern-matching-in-relay">
<h1>Relay 中的模式匹配<a class="headerlink" href="#pattern-matching-in-relay" title="永久链接至标题">#</a></h1>
<p>在 TVM 中有很多地方，决定了 Relay 程序的纯数据流子图，并试图以某种方式变换它们，例如融合、量化、外部代码生成和设备特定的优化，如 bitpacking 和 VTA 使用的层切片。</p>
<p>今天，许多这样的方法都需要大量无聊的样板代码来实现，并要求用户从 visitor 和 AST 匹配的角度考虑问题。许多这样的变换可以很容易地用图重写来描述。为了构建 rewriter 或其他高级机制，首先需要模式语言来描述可以匹配的内容。</p>
<p>这样的语言不仅对构建 rewriter 有用，而且还为现有的 pass 提供了扩展点。例如，融合 pass 可以通过一组描述硬件能力的融合模式来参数化，量化通道可以采用一组模式来描述在给定平台上可以量化的算子。</p>
<p>在后端世界，可以使用相同的机制来构建更高级别的 API，使用自己的代码生成。这个 API 采用了一组描述你的硬件能力的模式和外部编译器，提供了相对平稳的开箱即用的异构体验。</p>
<section id="pattern-examples">
<h2>模式示例<a class="headerlink" href="#pattern-examples" title="永久链接至标题">#</a></h2>
<p>有相当多的算子的属性值得匹配。下面将研究如何匹配树的属性，并扩展原型中未充分探索的一些用例。本节演示如何编写模式。建议查看 <a class="reference external" href="https://github.com/apache/tvm/blob/main/tests/python/relay/test_dataflow_pattern.py">tests/python/relay/test_dataflow_pattern.py</a> 了解更多用例。</p>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>如果您无法找到与您想要的 Relay 节点匹配的对应模式节点，欢迎您提出 issue 或提交 PR 来添加它。</p>
</div>
<section id="matching-one-of-two-ops">
<h3>匹配两个 Ops 中的一个<a class="headerlink" href="#matching-one-of-two-ops" title="永久链接至标题">#</a></h3>
<p>第一个例子是简单的例子，想要匹配带有单输入的算子或另一个单输入的算子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_op_or</span><span class="p">():</span>
    <span class="n">is_add_or_sub</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;add&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;subtract&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">is_add_or_sub</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;add&quot;</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">is_add_or_sub</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;subtract&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="matching-an-op-with-attributes">
<h3>使用属性匹配 Op<a class="headerlink" href="#matching-an-op-with-attributes" title="永久链接至标题">#</a></h3>
<p>下一个例子是 dense 运算，带有任何标记为 element-wise 的算子:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_no_match_attr</span><span class="p">():</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.dense&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">has_attr</span><span class="p">({</span><span class="s2">&quot;TOpPattern&quot;</span><span class="p">:</span> <span class="n">K_ELEMWISE</span><span class="p">})</span>
    <span class="n">op_pat</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">op_pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>下面是另一个使用特定属性匹配 op 的例子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_data_layout</span><span class="p">():</span>
    <span class="n">is_conv2d</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span><span class="o">.</span><span class="n">has_attr</span><span class="p">({</span><span class="s2">&quot;data_layout&quot;</span><span class="p">:</span> <span class="s2">&quot;NHWC&quot;</span><span class="p">})</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">is_conv2d</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>或者具有特定 kernel 大小的卷积：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_kernel_size</span><span class="p">():</span>
    <span class="n">is_conv2d</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s2">&quot;nn.conv2d&quot;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span><span class="o">.</span><span class="n">has_attr</span><span class="p">({</span><span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]})</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">is_conv2d</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="matching-an-optional-op">
<h3>匹配 Optional Op<a class="headerlink" href="#matching-an-optional-op" title="永久链接至标题">#</a></h3>
<p>下一个例子是用可选算子匹配一个模式。在这个模式中，可以匹配 conv2d+bias_add+relu graph 或 conv2d+bias_add graph。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_optional</span><span class="p">():</span>
    <span class="n">conv_node</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span>
    <span class="n">bias_node</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.bias_add&#39;</span><span class="p">)(</span><span class="n">conv_node</span><span class="p">,</span> <span class="n">wildcard</span><span class="p">())</span>
    <span class="n">pat</span> <span class="o">=</span> <span class="n">bias_node</span><span class="o">.</span><span class="n">optional</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">))</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>
    <span class="n">relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relu</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="matching-types">
<h3>匹配类型<a class="headerlink" href="#matching-types" title="永久链接至标题">#</a></h3>
<p>除了用属性来匹配 ops，还可以根据形状和数据类型，制作模式来匹配它们的类型。这里有一些例子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_type</span><span class="p">():</span>
    <span class="c1"># Match any op with float32</span>
    <span class="n">pat1</span> <span class="o">=</span> <span class="n">has_dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pat1</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Match any op with shape (10, 10)</span>
    <span class="n">pat2</span> <span class="o">=</span> <span class="n">has_shape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pat2</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Match conv2d+relu with a certain shape</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span>
    <span class="n">pat3</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.relu&#39;</span><span class="p">)(</span><span class="n">conv2d</span><span class="p">)</span><span class="o">.</span><span class="n">has_shape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pat3</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relu</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="matching-non-call-nodes">
<h3>匹配 Non-Call 节点<a class="headerlink" href="#matching-non-call-nodes" title="永久链接至标题">#</a></h3>
<p>有时可能还想匹配包含 Tuple 或 TupleGetItem 节点的模式。由于不是 call 节点，需要使用特定的模式节点来匹配它们：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_tuple</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
    <span class="n">tuple_pattern</span> <span class="o">=</span> <span class="n">is_tuple</span><span class="p">((</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">()))</span>
    <span class="k">assert</span> <span class="n">tuple_pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">Tuple</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">)))</span>
</pre></div>
</div>
<p>下一个例子是匹配 <code class="docutils literal notranslate"><span class="pre">batch_norm</span> <span class="pre">-&gt;</span> <span class="pre">get(0)</span> <span class="pre">-&gt;</span> <span class="pre">relu</span></code>。注意，您还可以使用 <code class="docutils literal notranslate"><span class="pre">is_tuple_get_item(bn_node)</span></code> 来匹配 <code class="docutils literal notranslate"><span class="pre">TupleGetItem</span></code> 节点和任何索引。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_tuple_get_item</span><span class="p">():</span>
    <span class="n">bn_node</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.batch_norm&#39;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span>
    <span class="n">tuple_get_item_node</span> <span class="o">=</span> <span class="n">is_tuple_get_item</span><span class="p">(</span><span class="n">bn_node</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">pat</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.relu&#39;</span><span class="p">)(</span><span class="n">tuple_get_item_node</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,))</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;beta&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,))</span>
    <span class="n">moving_mean</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;moving_mean&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,))</span>
    <span class="n">moving_var</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;moving_var&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,))</span>
    <span class="n">bn_node</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">moving_mean</span><span class="p">,</span> <span class="n">moving_var</span><span class="p">)</span>
    <span class="n">tuple_get_item_node</span> <span class="o">=</span> <span class="n">bn_node</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tuple_get_item_node</span><span class="p">)</span>
    <span class="n">pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>如果有跨越函数边界的模式，可能希望匹配函数本身</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_func</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">wc1</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
    <span class="n">wc2</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
    <span class="n">func_pattern</span> <span class="o">=</span> <span class="n">FunctionPattern</span><span class="p">([</span><span class="n">wc1</span><span class="p">,</span> <span class="n">wc2</span><span class="p">],</span> <span class="n">wc1</span> <span class="o">+</span> <span class="n">wc2</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">func_pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">Function</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>下一个例子是匹配 constant 节点的值。这对于检查子图中的特定参数是否被绑定很有用。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_constant</span><span class="p">():</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">is_constant</span><span class="p">())</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.bias_add&#39;</span><span class="p">)(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">wildcard</span><span class="p">())</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">func</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Function</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">out</span><span class="p">)</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">IRModule</span><span class="o">.</span><span class="n">from_expr</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>

    <span class="c1"># Two inputs of the conv2d in the graph are VarNode by default, so no match.</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s1">&#39;main&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>

    <span class="c1"># The second input (weight) has been bind with constant values so it is now a constant node.</span>
    <span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bind_params_by_name</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">],</span>
                                    <span class="p">{</span><span class="s1">&#39;w&#39;</span><span class="p">:</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))})</span>
    <span class="k">assert</span> <span class="n">pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">mod</span><span class="p">[</span><span class="s1">&#39;main&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>
</div>
<p>另一方面，如果需要将常数与特定值匹配，可以直接使用 <code class="docutils literal notranslate"><span class="pre">is_expr</span></code>。这对代数简化很有用。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_plus_zero</span><span class="p">():</span>
    <span class="n">zero</span> <span class="o">=</span> <span class="p">(</span><span class="n">is_expr</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">|</span> <span class="n">is_expr</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)))</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span> <span class="o">+</span> <span class="n">zero</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">relay</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>下一个例子是将函数节点与特定属性匹配：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_function</span><span class="p">():</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span><span class="o">.</span><span class="n">has_attr</span><span class="p">({</span><span class="s2">&quot;Composite&quot;</span><span class="p">:</span> <span class="s2">&quot;add&quot;</span><span class="p">})</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">Function</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">with_attr</span><span class="p">(</span><span class="s2">&quot;Composite&quot;</span><span class="p">,</span> <span class="s2">&quot;add&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<p>Relay <code class="docutils literal notranslate"><span class="pre">If</span></code> 表达式，如果它的所有条件，真分支和假分支都匹配，就可以匹配：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_if</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">is_var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">is_var</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">pat</span> <span class="o">=</span> <span class="n">is_if</span><span class="p">(</span><span class="n">is_op</span><span class="p">(</span><span class="s2">&quot;less&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">y</span>

    <span class="k">assert</span> <span class="n">pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">If</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>如果 Relay <code class="docutils literal notranslate"><span class="pre">Let</span></code> 表达式的所有变量、值和 body 都匹配，那么它就可以被匹配：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_let</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">is_var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">is_var</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">let_var</span> <span class="o">=</span> <span class="n">is_var</span><span class="p">(</span><span class="s2">&quot;let&quot;</span><span class="p">)</span>
    <span class="n">pat</span> <span class="o">=</span> <span class="n">is_let</span><span class="p">(</span><span class="n">let_var</span><span class="p">,</span> <span class="n">is_op</span><span class="p">(</span><span class="s2">&quot;less&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">let_var</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">lv</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s2">&quot;let&quot;</span><span class="p">)</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">y</span>
    <span class="k">assert</span> <span class="n">pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">relay</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">Let</span><span class="p">(</span><span class="n">lv</span><span class="p">,</span> <span class="n">cond</span><span class="p">,</span> <span class="n">lv</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="matching-diamonds-and-post-dominator-graphs">
<h3>匹配 Diamond 和 Post-Dominator Graph<a class="headerlink" href="#matching-diamonds-and-post-dominator-graphs" title="永久链接至标题">#</a></h3>
<p>下一个例子是在 diamond 的顶部匹配两个 inputs</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_diamond</span><span class="p">():</span>
    <span class="c1"># Pattern</span>
    <span class="n">is_conv2d</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">)(</span><span class="n">is_var</span><span class="p">(),</span> <span class="n">is_var</span><span class="p">())</span>
    <span class="n">path1</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.relu&#39;</span><span class="p">)(</span><span class="n">is_conv2d</span><span class="p">)</span>
    <span class="n">path2</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.leaky_relu&#39;</span><span class="p">)(</span><span class="n">is_conv2d</span><span class="p">)</span>
    <span class="n">diamond</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;add&#39;</span><span class="p">)(</span><span class="n">path1</span><span class="p">,</span> <span class="n">path2</span><span class="p">)</span>

    <span class="c1"># Expr</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="n">relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">)</span>
    <span class="n">leaky_relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">relu</span> <span class="o">+</span> <span class="n">leaky_relu</span>

    <span class="c1"># Check</span>
    <span class="k">assert</span> <span class="n">diamond</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>最后一个例子是将 diamond 与 post-dominator 的关系相匹配。在模式语言中嵌入支配分析作为匹配类型，以允许未知拓扑的模式匹配。这很重要，因为希望能够使用语言来描述融合模式，比如 elementwise 运算后面跟着 conv2d:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_match_dom_diamond</span><span class="p">():</span>
    <span class="c1"># Pattern</span>
    <span class="n">is_conv2d</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;nn.conv2d&#39;</span><span class="p">)(</span><span class="n">is_var</span><span class="p">(),</span> <span class="n">is_var</span><span class="p">())</span>
    <span class="n">reduction</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s1">&#39;add&#39;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">())</span>
    <span class="n">diamond</span> <span class="o">=</span> <span class="n">dominates</span><span class="p">(</span><span class="n">is_conv2d</span><span class="p">,</span> <span class="n">is_elemwise</span><span class="p">,</span> <span class="n">reduction</span><span class="p">)</span>

    <span class="c1"># Expr</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
    <span class="n">conv2d</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="n">relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">)</span>
    <span class="n">leaky_relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">relu</span> <span class="o">+</span> <span class="n">leaky_relu</span>

    <span class="c1"># Check</span>
    <span class="k">assert</span> <span class="n">diamond</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="matching-fuzzy-patterns">
<h2>模糊匹配模式<a class="headerlink" href="#matching-fuzzy-patterns" title="永久链接至标题">#</a></h2>
<p>上面的 Dominator 分析允许匹配 Relay AST 的子图，该子图不与一组模式节点精确地 1-to-1 对应。在其他一些地方，也支持这种模糊（”fuzzy”）匹配。</p>
<p>Tuple、Function 和具有任意数量输入的 Call 节点可以通过传递 <code class="docutils literal notranslate"><span class="pre">None</span></code> 作为参数值来匹配，即</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tuple_pattern</span> <span class="o">=</span> <span class="n">is_tuple</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="n">func_pattern</span> <span class="o">=</span> <span class="n">FunctionPattern</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">wildcard</span><span class="p">()</span> <span class="o">+</span> <span class="n">wildcard</span><span class="p">())</span>
<span class="n">call_pattern</span> <span class="o">=</span> <span class="n">func_pattern</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>这些模式通过限制参数的使用而不是参数的数量来匹配更通用的类模式。</p>
<p>此外，支持模糊体匹配（fuzzy bodies）函数，即受模式约束的函数体。模式 <code class="docutils literal notranslate"><span class="pre">FunctionPattern([is_var(),</span> <span class="pre">is_var()],</span> <span class="pre">wildcard()</span> <span class="pre">+</span> <span class="pre">wildcard()])</span></code> 将匹配 <code class="docutils literal notranslate"><span class="pre">relay.Function([x,</span> <span class="pre">y],</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y)</span></code>，但它也将匹配 <code class="docutils literal notranslate"><span class="pre">relay.Function([x,</span> <span class="pre">y],</span> <span class="pre">x</span> <span class="pre">*</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y)</span></code>。在第二种情况下，模式没有完美地约束函数体，因此产生的匹配是模糊的。</p>
</section>
<section id="pattern-language-design">
<h2>模式语言设计<a class="headerlink" href="#pattern-language-design" title="永久链接至标题">#</a></h2>
<p>提出的模式语言被设计成 Relay IR 的镜像，并对常见场景提供额外的支持。模式语言的目标是提供类似正则表达式的功能来匹配数据流图并进行重写。</p>
<p>高层次的设计是引入模式语言，现在提出这种语言为</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Pattern ::= expr
        | *
        | pattern(pattern1, ... patternN)
        | has_type(type)
        | has_dtype(type)
        | has_shape(shape)
        | has_attr(attrs)
        | is_var(name)
        | is_constant()
        | is_expr(expr)
        | is_op(op_name)
        | is_tuple()
        | is_tuple_get_item(pattern, index = None)
        | is_if(cond, tru, fls)
        | is_let(var, value, body)
        | pattern1 `|` pattern2
        | dominates(parent_pattern, path_pattern, child_pattern)
        | FunctionPattern(params, body)
</pre></div>
</div>
<p>然后，上述语言提供了匹配接口，可以选择子图，以及验证图是否匹配模式。</p>
<section id="expression-pattern">
<h3>表达式模式<a class="headerlink" href="#expression-pattern" title="永久链接至标题">#</a></h3>
<p>匹配 literal 表达式。</p>
</section>
<section id="wildcard">
<h3>通配符<a class="headerlink" href="#wildcard" title="永久链接至标题">#</a></h3>
<p>匹配任何表达式。</p>
</section>
<section id="type-pattern">
<h3>类型模式<a class="headerlink" href="#type-pattern" title="永久链接至标题">#</a></h3>
<p>检查嵌套模式匹配的表达式是否具有特定的类型。</p>
</section>
<section id="dtype-pattern">
<h3>DType 模式<a class="headerlink" href="#dtype-pattern" title="永久链接至标题">#</a></h3>
<p>检查嵌套模式匹配的表达式是否具有特定的数据类型。</p>
</section>
<section id="shape-pattern">
<h3>Shape 模式<a class="headerlink" href="#shape-pattern" title="永久链接至标题">#</a></h3>
<p>检查与嵌套模式匹配的表达式是否具有特定的输出形状。</p>
</section>
<section id="attribute-pattern">
<h3>属性模式<a class="headerlink" href="#attribute-pattern" title="永久链接至标题">#</a></h3>
<p>检查与模式匹配的算子是否具有具有特定值的属性。</p>
</section>
<section id="variable-pattern">
<h3>变量模式<a class="headerlink" href="#variable-pattern" title="永久链接至标题">#</a></h3>
<p>检查表达式是否是 relay 变量，并可选地提供与变量名匹配的名称。</p>
</section>
<section id="alternate">
<h3>备用<a class="headerlink" href="#alternate" title="永久链接至标题">#</a></h3>
<p>要么匹配第一种模式，要么匹配第二种模式。</p>
</section>
<section id="domination">
<h3>Domination<a class="headerlink" href="#domination" title="永久链接至标题">#</a></h3>
<p>匹配子模式，找到父模式的匹配，确保子模式最终主导父模式（即，模式之外的节点没有使用父模式的输出），并且子模式和模式之间的任何节点都匹配路径模式。</p>
</section>
<section id="function-pattern">
<h3>函数模式<a class="headerlink" href="#function-pattern" title="永久链接至标题">#</a></h3>
<p>用函数体和参数匹配函数</p>
</section>
<section id="if-pattern">
<h3>If 模式<a class="headerlink" href="#if-pattern" title="永久链接至标题">#</a></h3>
<p>将 If 与条件、真分支和假分支匹配</p>
</section>
<section id="let-pattern">
<h3>Let 模式<a class="headerlink" href="#let-pattern" title="永久链接至标题">#</a></h3>
<p>将 Let 与变量、值和 body 匹配</p>
</section>
</section>
<section id="applications">
<h2>应用<a class="headerlink" href="#applications" title="永久链接至标题">#</a></h2>
<p>模式语言不仅提供模式匹配，还提供模式处理。这里将介绍两种模式处理方法并提供一些示例。</p>
<section id="pattern-rewriting">
<h3>模式重写<a class="headerlink" href="#pattern-rewriting" title="永久链接至标题">#</a></h3>
<p>如果您想用另一个子图替换匹配的模式，您可以利用 <code class="docutils literal notranslate"><span class="pre">rewrite</span></code> 变换。下面是使用单个 batch_norm op 重写一系列算术算子的示例。构造函数参数 <code class="docutils literal notranslate"><span class="pre">require_type</span></code> 指示是否需要在回调之前运行 InferType。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BatchnormCallback</span><span class="p">(</span><span class="n">DFPatternCallback</span><span class="p">):</span>
    <span class="c1"># A callback class to rewrite the matched pattern to a batch_norm op.</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">require_type</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">require_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">wildcard</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span><span class="o">/</span><span class="n">is_op</span><span class="p">(</span><span class="s2">&quot;sqrt&quot;</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>

    <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">node_map</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">node_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">node_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">node_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">node_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">node_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">node_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="n">eps</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># A graph of arithmetic operators that are functional equivalent to batch_norm.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;var&#39;</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;gamma&#39;</span><span class="p">)</span>
    <span class="n">BN</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">/</span><span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">relay</span><span class="o">.</span><span class="n">const</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">))</span> <span class="o">+</span> <span class="n">beta</span>

    <span class="kn">from</span> <span class="nn">tvm.relay.dataflow_pattern</span> <span class="kn">import</span> <span class="n">rewrite</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">rewrite</span><span class="p">(</span><span class="n">BatchnormCallback</span><span class="p">(),</span> <span class="n">BN</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tvm</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">structural_equal</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">callback(self,</span> <span class="pre">pre,</span> <span class="pre">post,</span> <span class="pre">node_map)</span></code> 将在 rewriter 匹配 <code class="docutils literal notranslate"><span class="pre">self.pattern</span></code> 时被调用。<code class="docutils literal notranslate"><span class="pre">node_map</span></code> 是从模式节点映射到图中匹配节点的字典。</p>
<p>回调函数将在返回的模式上递归调用，直到模式停止变化。因此，如果 <code class="docutils literal notranslate"><span class="pre">self.pattern</span></code> 匹配回调返回的图的任何部分，rewriter 将循环运行。如果你想避免多次重写，你可以向构造函数传递 <code class="docutils literal notranslate"><span class="pre">rewrite_once=True</span></code> 参数。</p>
</section>
<section id="pattern-partitioning">
<h3>模式分区<a class="headerlink" href="#pattern-partitioning" title="永久链接至标题">#</a></h3>
<p>如果您想对匹配的子图执行更复杂的处理，而您不满足于 <code class="docutils literal notranslate"><span class="pre">rewrite</span></code>，您可以考虑将匹配的子图划分到单独的 Relay 函数，并对该函数执行其他处理。这里使用 <code class="docutils literal notranslate"><span class="pre">pattern.partition</span></code> 为每个匹配的子图创建新的 Relay 函数。该功能类似于 TVM 中的 op 融合 pass：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># A pattern matching conv2d+relu.</span>
<span class="n">pattern</span> <span class="o">=</span> <span class="n">is_op</span><span class="p">(</span><span class="s2">&quot;nn.relu&quot;</span><span class="p">)(</span><span class="n">is_op</span><span class="p">(</span><span class="s2">&quot;nn.conv2d&quot;</span><span class="p">)(</span><span class="n">wildcard</span><span class="p">(),</span> <span class="n">wildcard</span><span class="p">()))</span>

<span class="c1"># A graph.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="n">conv2d</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">relu</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
<span class="c1"># free_var %x: Tensor[(1, 3, 224, 224), float32]</span>
<span class="c1"># free_var %w: Tensor[(3, 3, 3, 3), float32]</span>
<span class="c1"># %0 = nn.conv2d(%x, %w, padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 3, 222, 222), float32] */;</span>
<span class="c1"># free_var %b: Tensor[(3), float32]</span>
<span class="c1"># nn.bias_add(%0, %b) /* ty=Tensor[(1, 3, 222, 222), float32] */</span>

<span class="c1"># After partition.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pattern</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">relu</span><span class="p">))</span>
<span class="c1"># free_var %x: Tensor[(1, 3, 224, 224), float32]</span>
<span class="c1"># free_var %w: Tensor[(3, 3, 3, 3), float32]</span>
<span class="c1"># free_var %b: Tensor[(3), float32]</span>
<span class="c1"># %1 = fn (%FunctionVar_0_0, %FunctionVar_0_1,</span>
<span class="c1">#          %FunctionVar_0_2, PartitionedFromPattern=&quot;nn.conv2d_nn.bias_add_&quot;) {</span>
<span class="c1">#   %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[0, 0, 0, 0]);</span>
<span class="c1">#   nn.bias_add(%0, %FunctionVar_0_2)</span>
<span class="c1"># };</span>
<span class="c1"># %1(%x, %w, %b)</span>
</pre></div>
</div>
<p>注意，你也可以为创建的函数指定属性：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">pattern</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">relu</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;Composite&#39;</span><span class="p">:</span> <span class="s1">&#39;one_layer&#39;</span><span class="p">}))</span>
<span class="c1"># free_var %x: Tensor[(1, 3, 224, 224), float32]</span>
<span class="c1"># free_var %w: Tensor[(3, 3, 3, 3), float32]</span>
<span class="c1"># free_var %b: Tensor[(3), float32]</span>
<span class="c1"># %1 = fn (%FunctionVar_0_0, %FunctionVar_0_1,</span>
<span class="c1">#          %FunctionVar_0_2, Composite=&quot;one_layer&quot;,</span>
<span class="c1">#                            PartitionedFromPattern=&quot;nn.conv2d_nn.bias_add_&quot;) {</span>
<span class="c1">#   %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[0, 0, 0, 0]);</span>
<span class="c1">#   nn.bias_add(%0, %FunctionVar_0_2)</span>
<span class="c1"># };</span>
<span class="c1"># %1(%x, %w, %b)</span>
</pre></div>
</div>
<p>如果需要使用模式语言无法指定的自定义检查函数，可以在分区时指定 <code class="docutils literal notranslate"><span class="pre">check</span></code> 函数。下面的例子是演示检查子图输入数据布局的案例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="n">pre</span><span class="p">):</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">pre</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">attrs</span><span class="o">.</span><span class="n">data_layout</span> <span class="o">==</span> <span class="s2">&quot;NCHW&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">checked_type</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">pattern</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">relu</span><span class="p">,</span> <span class="n">check</span><span class="o">=</span><span class="n">check</span><span class="p">)</span>
</pre></div>
</div>
<p>在这个例子中，检查匹配的子图的第一个参数（即 <code class="docutils literal notranslate"><span class="pre">pre.args[0]</span></code> ）是否有数据布局 “NCHW” 以及它的批大小是否为 1。如果模式匹配的条件不能通过分析模式本身来验证，那么这个特性就很有用。</p>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="relay_op.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title">Relay 核心张量算子</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="hybrid_script.html" title="下一页 页">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">Hybrid 前端语言参考</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By xinetzone<br/>
  
      &copy; Copyright 2022, xinetzone.<br/>
    Last updated on 2022-11-14, 06:55:56.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>