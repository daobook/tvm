
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>用 TVMC 编译和优化模型 &#8212; TVM  文档</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/translations.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="开始使用 TVMC Python：TVM 的高级 API" href="tvmc_python.html" />
    <link rel="prev" title="TVM 和模型优化的概述" href="introduction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/tvm-logo-small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TVM  文档</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   TVM 文档
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../start.html">
   快速上手
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../install/index.html">
     安装 TVM
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../install/from_source.html">
       从源码安装
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../install/nnpack.html">
         NNPACK Contrib Installation
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../install/docker.html">
       Docker 镜像
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../install/nnpack.html">
       NNPACK Contrib Installation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../contribute/index.html">
     贡献者指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/community.html">
       TVM 社区指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/pull_request.html">
       提交 Pull Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/code_review.html">
       Code Reviews
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/committer_guide.html">
       Committer Guide
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/document.html">
       Documentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/code_guide.html">
       Code Guide and Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/git_howto.html">
       Git Usage Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/ci.html">
       Using TVM’s CI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/release_process.html">
       Release Process
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/error_handling.html">
       Error Handling Guide
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../user-guide.html">
   用户手册
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     用户指南
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="introduction.html">
       TVM 和模型优化的概述
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       用 TVMC 编译和优化模型
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tvmc_python.html">
       开始使用 TVMC Python：TVM 的高级 API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="autotvm_relay_x86.html">
       用 Python 接口编译和优化模型（AutoTVM）
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tensor_expr_get_started.html">
       使用张量表达式处理算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="autotvm_matmul_x86.html">
       用调度模板和 AutoTVM 优化算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_scheduler_matmul_x86.html">
       使用自动调度优化运算
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tensor_ir_blitz_course.html">
       TensorIR 的突击课程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_compilation_and_rpc.html">
       交叉编译和RPC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="relay_quick_start.html">
       编译深度学习模型的快速入门教程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="intro_topi.html">
       TOPI 简介
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="uma.html">
       通过 UMA 使您的硬件加速器 TVM-ready
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../how_to/index.html">
     How To 指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/compile_models/index.html">
       编译深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_pytorch.html">
         编译 PyTorch 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_tensorflow.html">
         Compile Tensorflow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_mxnet.html">
         编译 MXNet 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_onnx.html">
         Compile ONNX Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_keras.html">
         Compile Keras Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_tflite.html">
         Compile TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_coreml.html">
         Compile CoreML Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_darknet.html">
         Compile YOLO-V2 and YOLO-V3 in DarkNet Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_caffe2.html">
         Compile Caffe2 Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_oneflow.html">
         Compile OneFlow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_paddle.html">
         Compile PaddlePaddle Models
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/deploy/index.html">
       部署模型并集成到 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/cpp_deploy.html">
         使用 C++ API 部署 TVM Module
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/android.html">
         Deploy to Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/integrate.html">
         集成 TVM 到你的项目
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/hls.html">
         HLS Backend Example
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/arm_compute_lib.html">
         集成 Relay Arm
         <sup>
          ®
         </sup>
         计算库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/tensorrt.html">
         Relay TensorRT Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/vitis_ai.html">
         Vitis AI Integration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy/bnns.html">
         Relay BNNS Integration
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/deploy_models/index.html">
       部署深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_model_on_android.html">
         Deploy the Pretrained Model on Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_model_on_rasp.html">
         Deploy the Pretrained Model on Raspberry Pi
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_object_detection_pytorch.html">
         编译 PyTorch 目标检测模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_prequantized.html">
         使用 TVM 部署框架预量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_prequantized_tflite.html">
         Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_quantized.html">
         在 CUDA 上部署已量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_sparse.html">
         Deploy a Hugging Face Pruned Model on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_ssd_gluoncv.html">
         部署 Single Shot Multibox Detector(SSD) 模型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_relay/index.html">
       使用 Relay
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/build_gcn.html">
         构建图卷积网络
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_external_lib.html">
         在 Relay 中使用外部库
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_pipeline_executor.html">
         在 Relay 中使用管道执行器
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_relay_viz.html">
         使用 Relay Visualizer 可视化 Relay
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_schedules/index.html">
       使用 Tensor Expression 和 Schedules
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/schedule_primitives.html">
         TVM 中的调度原语
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/reduction.html">
         Reduction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/intrin_math.html">
         Intrinsics and Math Functions
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/scan.html">
         Scan and Recurrent Kernel
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/extern_op.html">
         外部张量函数
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tensorize.html">
         Use Tensorize to Leverage Hardware Intrinsics
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tuple_inputs.html">
         Compute and Reduce with Tuple Inputs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tedd.html">
         使用 TEDD 进行可视化
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/optimize_operators/index.html">
       优化张量算子
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_gemm.html">
         How to optimize GEMM on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_conv_cuda.html">
         How to optimize convolution on GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_conv_tensorcore.html">
         How to optimize convolution using TensorCores
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/tune_with_autotvm/index.html">
       Auto-Tune with Templates and AutoTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_conv2d_cuda.html">
         Tuning High Performance Convolution on NVIDIA GPUs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_cuda.html">
         Auto-tuning a Convolutional Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_x86.html">
         Auto-tuning a Convolutional Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_arm.html">
         Auto-tuning a Convolutional Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_mobile_gpu.html">
         Auto-tuning a Convolutional Network for Mobile GPU
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/tune_with_autoscheduler/index.html">
       使用自动调度器进行无模板调度
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.html">
         Auto-scheduling a Convolution Layer for GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_x86.html">
         Auto-scheduling a Neural Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_cuda.html">
         Auto-scheduling a Neural Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_arm.html">
         Auto-scheduling a Neural Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_mali.html">
         Auto-scheduling a Neural Network for mali GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_sparse_x86.html">
         Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_microtvm/index.html">
       使用 microTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_aot.html">
         microTVM Host-Driven AoT
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_autotune.html">
         使用 microTVM Autotuning
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_ethosu.html">
         在 bare metal Arm® Cortex®-M55 CPU 和 Ethos™-U55 NPU 上运行 TVM
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_reference_vm.html">
         microTVM 参考虚拟机
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_tflite.html">
         microTVM with TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_train.html">
         Training Vision Models for microTVM on Arduino
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_tvmc.html">
         Executing a Tiny Model with TVMC Micro
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/extend_tvm/index.html">
       拓展 TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/low_level_custom_pass.html">
         编写定制 Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/use_pass_infra.html">
         如何使用 TVM Pass Infra
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/use_pass_instrument.html">
         如何使用 TVM Pass Instrument
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/bring_your_own_datatypes.html">
         自定义 TVM 数据类型
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/profile/index.html">
       模型剖析
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/profile/papi.html">
         PAPI 快速上手
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../errors.html">
       处理 TVM 的错误
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../faq.html">
       常见问题
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../developer-guide.html">
   开发手册
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev/tutorial/index.html">
     开发者教程
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/tutorial/codebase_walkthrough.html">
       TVM 代码库的实例演练
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev/how_to/how_to.html">
     开发者指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/debugging_tvm.html">
       Debugging TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_add_op.html">
       添加算子到 Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_add_pass.html">
       Adding a Compiler Pass to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_bring_your_own_codegen.html">
       带你自己的 Codegen 到 TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/pytest_target_parametrization.html">
       Python 目标参数化
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../arch/index.html">
   设计与架构
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/runtime.html">
     TVM 运行时系统
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/debugger.html">
     调试器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/virtual_machine.html">
     将 VM 放入 TVM：Relay Virtual Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/introduction_to_module_serialization.html">
     模块序列化简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/pass_infra.html">
     Pass Infrastructure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/device_target_interactions.html">
     Device/Target Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/inferbound.html">
     InferBound Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/hybrid_script.html">
     Hybrid 前端开发指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/relay_intro.html">
     Relay IR 简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/relay_op_strategy.html">
     Relay 算子策略
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/convert_layout.html">
     Convert Layout Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/benchmark.html">
     基准性能日志格式
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/frontend/tensorflow.html">
     TensorFlow Frontend
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/security.html">
     安全指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/microtvm_design.html">
     microTVM Design Document
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/microtvm_project_api.html">
     microTVM Project API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/model_library_format.html">
     Model 库格式
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../topic-guides.html">
   主题指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../topic/microtvm/index.html">
     microTVM：裸机上的 TVM
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../topic/vta/index.html">
     VTA：通用张量加速器
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../topic/vta/install.html">
       VTA 安装指南
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../topic/vta/dev/index.html">
       VTA 设计和开发指南
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
      <label for="toctree-checkbox-25">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/dev/config.html">
         VTA 配置
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/dev/hardware.html">
         VTA 硬件指南
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../topic/vta/tutorials/index.html">
       VTA 教程
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
      <label for="toctree-checkbox-26">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/matrix_multiply.html">
         简单的矩阵乘法
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/frontend/index.html">
         编译深度学习模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/optimize/index.html">
         优化 Tensor 算子
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/autotvm/index.html">
         自动调优
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../reference-guide.html">
   参考指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
  <label for="toctree-checkbox-27">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../reference/langref/index.html">
     语言参考
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
    <label for="toctree-checkbox-28">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_expr.html">
       Relay 表达式
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_type.html">
       Relay 类型系统
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_adt.html">
       Algebraic Data Types in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_op.html">
       Relay 核心张量算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_pattern.html">
       Relay 中的模式匹配
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/hybrid_script.html">
       Hybrid 前端语言参考
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../reference/api/python/index.html">
     Python API
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/runtime.html">
       tvm.runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ndarray.html">
       tvm.runtime.ndarray
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/error.html">
       tvm.error
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ir/module.html">
       tvm.ir.module
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ir/index.html">
       tvm.ir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/target.html">
       tvm.target
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/tir.html">
       tvm.tir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/te.html">
       tvm.te
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/driver.html">
       tvm.driver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/index.html">
       tvm.relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/frontend.html">
       tvm.relay.frontend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/nn.html">
       tvm.relay.nn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/vision.html">
       tvm.relay.vision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/image.html">
       tvm.relay.image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/transform.html">
       tvm.relay.transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/analysis.html">
       tvm.relay.analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/backend.html">
       tvm.relay.backend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/dataflow_pattern.html">
       tvm.relay.dataflow_pattern
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/testing.html">
       tvm.relay.testing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/autotvm.html">
       tvm.autotvm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/auto_scheduler.html">
       tvm.auto_scheduler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/rpc.html">
       tvm.rpc
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/micro.html">
       tvm.micro
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/contrib.html">
       tvm.contrib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/graph_executor.html">
       tvm.contrib.graph_executor
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/topi.html">
       tvm.topi
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/vta/index.html">
       vta
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/api/links.html">
     其他 API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/publications.html">
     出版物
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../refs/index.html">
   参考
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../refs/_ffi/index.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       _ffi
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/base.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.base
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/libinfo.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.libinfo
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/object.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi._ctypes.object
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/registry.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.registry
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/runtime_ctypes.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.runtime_ctypes
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/docs/tutorial/tvmc_command_line_driver.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> 导航
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   使用 TVMC
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   获得模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx-tvm">
   将 ONNX 模型编译到 TVM 运行时中
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   用 TVMC 从编译的模块中运行模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     输入预处理
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     运行已编译的模块
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     输出后处理
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnet">
   自动调优 ResNet 模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   用调优数据编译优化后的模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   比较已调谐和未调谐的模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   小结
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>用 TVMC 编译和优化模型</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> 导航 </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   使用 TVMC
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   获得模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx-tvm">
   将 ONNX 模型编译到 TVM 运行时中
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   用 TVMC 从编译的模块中运行模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     输入预处理
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     运行已编译的模块
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     输出后处理
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnet">
   自动调优 ResNet 模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   用调优数据编译优化后的模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   比较已调谐和未调谐的模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   小结
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="tvmc">
<span id="sphx-glr-tutorial-tvmc-command-line-driver-py"></span><h1>用 TVMC 编译和优化模型<a class="headerlink" href="#tvmc" title="永久链接至标题">#</a></h1>
<p>原作者：<a class="reference external" href="https://github.com/leandron">Leandro Nunes</a>, <a class="reference external" href="https://github.com/mbaret">Matthew Barrett</a>, <a class="reference external" href="https://github.com/hogepodge">Chris Hoge</a></p>
<p>在本节中，将使用 TVMC，即 TVM 命令行驱动程序。TVMC 工具，它暴露了 TVM 的功能，如 auto-tuning、编译、profiling 和通过命令行界面执行模型。</p>
<p>在完成本节内容后，将使用 TVMC 来完成以下任务：</p>
<ul class="simple">
<li><p>为 TVM 运行时编译预训练 ResNet-50 v2 模型。</p></li>
<li><p>通过编译后的模型运行真实图像，并解释输出和模型的性能。</p></li>
<li><p>使用 TVM 在 CPU 上调优模型。</p></li>
<li><p>使用 TVM 收集的调优数据重新编译优化模型。</p></li>
<li><p>通过优化后的模型运行图像，并比较输出和模型的性能。</p></li>
</ul>
<p>本节的目的是让你了解 TVM 和 TVMC 的能力，并为理解 TVM 的工作原理奠定基础。</p>
<section id="id1">
<h2>使用 TVMC<a class="headerlink" href="#id1" title="永久链接至标题">#</a></h2>
<p>TVMC 是 Python 应用程序，是 TVM Python 软件包的一部分。当你使用 Python 包安装 TVM 时，你将得到 TVMC 作为命令行应用程序，名为 <code class="docutils literal notranslate"><span class="pre">tvmc</span></code>。这个命令的位置将取决于你的平台和安装方法。</p>
<p>另外，如果你在 <code class="docutils literal notranslate"><span class="pre">$PYTHONPATH</span></code> 上将 TVM 作为 Python 模块，你可以通过可执行的 python 模块 <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">tvm.driver.tvmc</span></code> 访问命令行驱动功能。</p>
<p>为简单起见，本教程将提到 TVMC 命令行使用 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">&lt;options&gt;</span></code>，但同样的结果可以用 <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">tvm.driver.tvmc</span> <span class="pre">&lt;options&gt;</span></code>。</p>
<p>你可以使用帮助页面查看：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m tvm.driver.tvmc --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: tvmc [--config CONFIG] [-v] [--version] [-h]
            {micro,run,tune,compile} ...

TVM compiler driver

options:
  --config CONFIG       configuration json file
  -v, --verbose         increase verbosity
  --version             print the version and exit
  -h, --help            show this help message and exit.

commands:
  {micro,run,tune,compile}
    micro               select micro context.
    run                 run a compiled module
    tune                auto-tune a model
    compile             compile a model.

TVMC - TVM driver command-line interface
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tvmc</span></code> 可用的 TVM 的主要功能来自子命令 <code class="docutils literal notranslate"><span class="pre">compile</span></code> 和 <code class="docutils literal notranslate"><span class="pre">run</span></code>，以及 <code class="docutils literal notranslate"><span class="pre">tune</span></code>。要了解某个子命令下的具体选项，请使用 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">&lt;subcommand&gt;</span> <span class="pre">--help</span></code>。将在本教程中逐一介绍这些命令，但首先需要下载预训练模型来使用。</p>
</section>
<section id="id2">
<h2>获得模型<a class="headerlink" href="#id2" title="永久链接至标题">#</a></h2>
<p>在本教程中，将使用 ResNet-50 v2。ResNet-50 是卷积神经网络，有 50 层深度，设计用于图像分类。将使用的模型已经在超过一百万张图片上进行了预训练，有 1000 种不同的分类。该网络输入图像大小为 224x224。如果你有兴趣探究更多关于 ResNet-50 模型的结构，建议下载 `<a class="reference external" href="https://netron.app">Netron</a>，它免费提供的 ML 模型查看器。</p>
<p>在本教程中，将使用 ONNX 格式的模型。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v2-7.onnx
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2022-04-26 13:07:52--  https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v2-7.onnx
Resolving github.com (github.com)... 20.205.243.166
Connecting to github.com (github.com)|20.205.243.166|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://media.githubusercontent.com/media/onnx/models/main/vision/classification/resnet/model/resnet50-v2-7.onnx [following]
--2022-04-26 13:07:53--  https://media.githubusercontent.com/media/onnx/models/main/vision/classification/resnet/model/resnet50-v2-7.onnx
Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...
Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 102442450 (98M) [application/octet-stream]
Saving to: ‘resnet50-v2-7.onnx’

resnet50-v2-7.onnx  100%[===================&gt;]  97.70M  4.51MB/s    in 25s     

2022-04-26 13:08:27 (3.89 MB/s) - ‘resnet50-v2-7.onnx’ saved [102442450/102442450]
</pre></div>
</div>
</div>
</div>
<p>为了让该模型可以被其他教程使用，需要：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>mv resnet50-v2-7.onnx ../../_models/resnet50-v2-7.onnx
</pre></div>
</div>
</div>
</div>
<div class="admonition- admonition">
<p class="admonition-title">支持的模型格式</p>
<p>TVMC 支持用 Keras、ONNX、TensorFlow、TFLite 和 Torch 创建的模型。如果你需要明确地提供你所使用的模型格式，请使用选项 <code class="docutils literal notranslate"><span class="pre">--model-format</span></code>。</p>
</div>
<p>更多信息见：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m tvm.driver.tvmc compile --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: tvmc compile [-h] [--cross-compiler CROSS_COMPILER]
                    [--cross-compiler-options CROSS_COMPILER_OPTIONS]
                    [--desired-layout {NCHW,NHWC}] [--dump-code FORMAT]
                    [--model-format {keras,onnx,pb,tflite,pytorch,paddle}]
                    [-o OUTPUT] [-f {so,mlf}] [--pass-config name=value]
                    [--target TARGET]
                    [--target-example_target_hook-from_device TARGET_EXAMPLE_TARGET_HOOK_FROM_DEVICE]
                    [--target-example_target_hook-libs TARGET_EXAMPLE_TARGET_HOOK_LIBS]
                    [--target-example_target_hook-model TARGET_EXAMPLE_TARGET_HOOK_MODEL]
                    [--target-example_target_hook-tag TARGET_EXAMPLE_TARGET_HOOK_TAG]
                    [--target-example_target_hook-device TARGET_EXAMPLE_TARGET_HOOK_DEVICE]
                    [--target-example_target_hook-keys TARGET_EXAMPLE_TARGET_HOOK_KEYS]
                    [--target-ext_dev-from_device TARGET_EXT_DEV_FROM_DEVICE]
                    [--target-ext_dev-libs TARGET_EXT_DEV_LIBS]
                    [--target-ext_dev-model TARGET_EXT_DEV_MODEL]
                    [--target-ext_dev-system-lib TARGET_EXT_DEV_SYSTEM_LIB]
                    [--target-ext_dev-tag TARGET_EXT_DEV_TAG]
                    [--target-ext_dev-device TARGET_EXT_DEV_DEVICE]
                    [--target-ext_dev-keys TARGET_EXT_DEV_KEYS]
                    [--target-llvm-fast-math TARGET_LLVM_FAST_MATH]
                    [--target-llvm-opt-level TARGET_LLVM_OPT_LEVEL]
                    [--target-llvm-unpacked-api TARGET_LLVM_UNPACKED_API]
                    [--target-llvm-from_device TARGET_LLVM_FROM_DEVICE]
                    [--target-llvm-fast-math-ninf TARGET_LLVM_FAST_MATH_NINF]
                    [--target-llvm-mattr TARGET_LLVM_MATTR]
                    [--target-llvm-num-cores TARGET_LLVM_NUM_CORES]
                    [--target-llvm-libs TARGET_LLVM_LIBS]
                    [--target-llvm-fast-math-nsz TARGET_LLVM_FAST_MATH_NSZ]
                    [--target-llvm-link-params TARGET_LLVM_LINK_PARAMS]
                    [--target-llvm-interface-api TARGET_LLVM_INTERFACE_API]
                    [--target-llvm-fast-math-contract TARGET_LLVM_FAST_MATH_CONTRACT]
                    [--target-llvm-system-lib TARGET_LLVM_SYSTEM_LIB]
                    [--target-llvm-tag TARGET_LLVM_TAG]
                    [--target-llvm-mtriple TARGET_LLVM_MTRIPLE]
                    [--target-llvm-model TARGET_LLVM_MODEL]
                    [--target-llvm-mfloat-abi TARGET_LLVM_MFLOAT_ABI]
                    [--target-llvm-mcpu TARGET_LLVM_MCPU]
                    [--target-llvm-device TARGET_LLVM_DEVICE]
                    [--target-llvm-runtime TARGET_LLVM_RUNTIME]
                    [--target-llvm-fast-math-arcp TARGET_LLVM_FAST_MATH_ARCP]
                    [--target-llvm-fast-math-reassoc TARGET_LLVM_FAST_MATH_REASSOC]
                    [--target-llvm-mabi TARGET_LLVM_MABI]
                    [--target-llvm-keys TARGET_LLVM_KEYS]
                    [--target-llvm-fast-math-nnan TARGET_LLVM_FAST_MATH_NNAN]
                    [--target-hybrid-from_device TARGET_HYBRID_FROM_DEVICE]
                    [--target-hybrid-libs TARGET_HYBRID_LIBS]
                    [--target-hybrid-model TARGET_HYBRID_MODEL]
                    [--target-hybrid-system-lib TARGET_HYBRID_SYSTEM_LIB]
                    [--target-hybrid-tag TARGET_HYBRID_TAG]
                    [--target-hybrid-device TARGET_HYBRID_DEVICE]
                    [--target-hybrid-keys TARGET_HYBRID_KEYS]
                    [--target-aocl-from_device TARGET_AOCL_FROM_DEVICE]
                    [--target-aocl-libs TARGET_AOCL_LIBS]
                    [--target-aocl-model TARGET_AOCL_MODEL]
                    [--target-aocl-system-lib TARGET_AOCL_SYSTEM_LIB]
                    [--target-aocl-tag TARGET_AOCL_TAG]
                    [--target-aocl-device TARGET_AOCL_DEVICE]
                    [--target-aocl-keys TARGET_AOCL_KEYS]
                    [--target-nvptx-max_num_threads TARGET_NVPTX_MAX_NUM_THREADS]
                    [--target-nvptx-thread_warp_size TARGET_NVPTX_THREAD_WARP_SIZE]
                    [--target-nvptx-from_device TARGET_NVPTX_FROM_DEVICE]
                    [--target-nvptx-libs TARGET_NVPTX_LIBS]
                    [--target-nvptx-model TARGET_NVPTX_MODEL]
                    [--target-nvptx-system-lib TARGET_NVPTX_SYSTEM_LIB]
                    [--target-nvptx-mtriple TARGET_NVPTX_MTRIPLE]
                    [--target-nvptx-tag TARGET_NVPTX_TAG]
                    [--target-nvptx-mcpu TARGET_NVPTX_MCPU]
                    [--target-nvptx-device TARGET_NVPTX_DEVICE]
                    [--target-nvptx-keys TARGET_NVPTX_KEYS]
                    [--target-opencl-max_num_threads TARGET_OPENCL_MAX_NUM_THREADS]
                    [--target-opencl-thread_warp_size TARGET_OPENCL_THREAD_WARP_SIZE]
                    [--target-opencl-from_device TARGET_OPENCL_FROM_DEVICE]
                    [--target-opencl-libs TARGET_OPENCL_LIBS]
                    [--target-opencl-model TARGET_OPENCL_MODEL]
                    [--target-opencl-system-lib TARGET_OPENCL_SYSTEM_LIB]
                    [--target-opencl-tag TARGET_OPENCL_TAG]
                    [--target-opencl-device TARGET_OPENCL_DEVICE]
                    [--target-opencl-keys TARGET_OPENCL_KEYS]
                    [--target-metal-max_num_threads TARGET_METAL_MAX_NUM_THREADS]
                    [--target-metal-thread_warp_size TARGET_METAL_THREAD_WARP_SIZE]
                    [--target-metal-from_device TARGET_METAL_FROM_DEVICE]
                    [--target-metal-libs TARGET_METAL_LIBS]
                    [--target-metal-keys TARGET_METAL_KEYS]
                    [--target-metal-model TARGET_METAL_MODEL]
                    [--target-metal-system-lib TARGET_METAL_SYSTEM_LIB]
                    [--target-metal-tag TARGET_METAL_TAG]
                    [--target-metal-device TARGET_METAL_DEVICE]
                    [--target-metal-max_function_args TARGET_METAL_MAX_FUNCTION_ARGS]
                    [--target-webgpu-max_num_threads TARGET_WEBGPU_MAX_NUM_THREADS]
                    [--target-webgpu-from_device TARGET_WEBGPU_FROM_DEVICE]
                    [--target-webgpu-libs TARGET_WEBGPU_LIBS]
                    [--target-webgpu-model TARGET_WEBGPU_MODEL]
                    [--target-webgpu-system-lib TARGET_WEBGPU_SYSTEM_LIB]
                    [--target-webgpu-tag TARGET_WEBGPU_TAG]
                    [--target-webgpu-device TARGET_WEBGPU_DEVICE]
                    [--target-webgpu-keys TARGET_WEBGPU_KEYS]
                    [--target-rocm-max_num_threads TARGET_ROCM_MAX_NUM_THREADS]
                    [--target-rocm-thread_warp_size TARGET_ROCM_THREAD_WARP_SIZE]
                    [--target-rocm-from_device TARGET_ROCM_FROM_DEVICE]
                    [--target-rocm-libs TARGET_ROCM_LIBS]
                    [--target-rocm-mattr TARGET_ROCM_MATTR]
                    [--target-rocm-max_shared_memory_per_block TARGET_ROCM_MAX_SHARED_MEMORY_PER_BLOCK]
                    [--target-rocm-model TARGET_ROCM_MODEL]
                    [--target-rocm-system-lib TARGET_ROCM_SYSTEM_LIB]
                    [--target-rocm-mtriple TARGET_ROCM_MTRIPLE]
                    [--target-rocm-tag TARGET_ROCM_TAG]
                    [--target-rocm-device TARGET_ROCM_DEVICE]
                    [--target-rocm-mcpu TARGET_ROCM_MCPU]
                    [--target-rocm-max_threads_per_block TARGET_ROCM_MAX_THREADS_PER_BLOCK]
                    [--target-rocm-keys TARGET_ROCM_KEYS]
                    [--target-vulkan-max_num_threads TARGET_VULKAN_MAX_NUM_THREADS]
                    [--target-vulkan-thread_warp_size TARGET_VULKAN_THREAD_WARP_SIZE]
                    [--target-vulkan-from_device TARGET_VULKAN_FROM_DEVICE]
                    [--target-vulkan-max_per_stage_descriptor_storage_buffer TARGET_VULKAN_MAX_PER_STAGE_DESCRIPTOR_STORAGE_BUFFER]
                    [--target-vulkan-driver_version TARGET_VULKAN_DRIVER_VERSION]
                    [--target-vulkan-supports_16bit_buffer TARGET_VULKAN_SUPPORTS_16BIT_BUFFER]
                    [--target-vulkan-max_block_size_z TARGET_VULKAN_MAX_BLOCK_SIZE_Z]
                    [--target-vulkan-libs TARGET_VULKAN_LIBS]
                    [--target-vulkan-supports_dedicated_allocation TARGET_VULKAN_SUPPORTS_DEDICATED_ALLOCATION]
                    [--target-vulkan-supported_subgroup_operations TARGET_VULKAN_SUPPORTED_SUBGROUP_OPERATIONS]
                    [--target-vulkan-mattr TARGET_VULKAN_MATTR]
                    [--target-vulkan-max_storage_buffer_range TARGET_VULKAN_MAX_STORAGE_BUFFER_RANGE]
                    [--target-vulkan-max_push_constants_size TARGET_VULKAN_MAX_PUSH_CONSTANTS_SIZE]
                    [--target-vulkan-supports_push_descriptor TARGET_VULKAN_SUPPORTS_PUSH_DESCRIPTOR]
                    [--target-vulkan-supports_int64 TARGET_VULKAN_SUPPORTS_INT64]
                    [--target-vulkan-supports_float32 TARGET_VULKAN_SUPPORTS_FLOAT32]
                    [--target-vulkan-model TARGET_VULKAN_MODEL]
                    [--target-vulkan-max_block_size_x TARGET_VULKAN_MAX_BLOCK_SIZE_X]
                    [--target-vulkan-system-lib TARGET_VULKAN_SYSTEM_LIB]
                    [--target-vulkan-max_block_size_y TARGET_VULKAN_MAX_BLOCK_SIZE_Y]
                    [--target-vulkan-tag TARGET_VULKAN_TAG]
                    [--target-vulkan-supports_int8 TARGET_VULKAN_SUPPORTS_INT8]
                    [--target-vulkan-max_spirv_version TARGET_VULKAN_MAX_SPIRV_VERSION]
                    [--target-vulkan-vulkan_api_version TARGET_VULKAN_VULKAN_API_VERSION]
                    [--target-vulkan-supports_8bit_buffer TARGET_VULKAN_SUPPORTS_8BIT_BUFFER]
                    [--target-vulkan-device_type TARGET_VULKAN_DEVICE_TYPE]
                    [--target-vulkan-supports_int32 TARGET_VULKAN_SUPPORTS_INT32]
                    [--target-vulkan-device TARGET_VULKAN_DEVICE]
                    [--target-vulkan-max_threads_per_block TARGET_VULKAN_MAX_THREADS_PER_BLOCK]
                    [--target-vulkan-max_uniform_buffer_range TARGET_VULKAN_MAX_UNIFORM_BUFFER_RANGE]
                    [--target-vulkan-driver_name TARGET_VULKAN_DRIVER_NAME]
                    [--target-vulkan-supports_integer_dot_product TARGET_VULKAN_SUPPORTS_INTEGER_DOT_PRODUCT]
                    [--target-vulkan-supports_storage_buffer_storage_class TARGET_VULKAN_SUPPORTS_STORAGE_BUFFER_STORAGE_CLASS]
                    [--target-vulkan-supports_float16 TARGET_VULKAN_SUPPORTS_FLOAT16]
                    [--target-vulkan-device_name TARGET_VULKAN_DEVICE_NAME]
                    [--target-vulkan-supports_float64 TARGET_VULKAN_SUPPORTS_FLOAT64]
                    [--target-vulkan-keys TARGET_VULKAN_KEYS]
                    [--target-vulkan-max_shared_memory_per_block TARGET_VULKAN_MAX_SHARED_MEMORY_PER_BLOCK]
                    [--target-vulkan-supports_int16 TARGET_VULKAN_SUPPORTS_INT16]
                    [--target-cuda-max_num_threads TARGET_CUDA_MAX_NUM_THREADS]
                    [--target-cuda-thread_warp_size TARGET_CUDA_THREAD_WARP_SIZE]
                    [--target-cuda-from_device TARGET_CUDA_FROM_DEVICE]
                    [--target-cuda-arch TARGET_CUDA_ARCH]
                    [--target-cuda-libs TARGET_CUDA_LIBS]
                    [--target-cuda-max_shared_memory_per_block TARGET_CUDA_MAX_SHARED_MEMORY_PER_BLOCK]
                    [--target-cuda-model TARGET_CUDA_MODEL]
                    [--target-cuda-system-lib TARGET_CUDA_SYSTEM_LIB]
                    [--target-cuda-tag TARGET_CUDA_TAG]
                    [--target-cuda-device TARGET_CUDA_DEVICE]
                    [--target-cuda-mcpu TARGET_CUDA_MCPU]
                    [--target-cuda-max_threads_per_block TARGET_CUDA_MAX_THREADS_PER_BLOCK]
                    [--target-cuda-registers_per_block TARGET_CUDA_REGISTERS_PER_BLOCK]
                    [--target-cuda-keys TARGET_CUDA_KEYS]
                    [--target-sdaccel-from_device TARGET_SDACCEL_FROM_DEVICE]
                    [--target-sdaccel-libs TARGET_SDACCEL_LIBS]
                    [--target-sdaccel-model TARGET_SDACCEL_MODEL]
                    [--target-sdaccel-system-lib TARGET_SDACCEL_SYSTEM_LIB]
                    [--target-sdaccel-tag TARGET_SDACCEL_TAG]
                    [--target-sdaccel-device TARGET_SDACCEL_DEVICE]
                    [--target-sdaccel-keys TARGET_SDACCEL_KEYS]
                    [--target-composite-from_device TARGET_COMPOSITE_FROM_DEVICE]
                    [--target-composite-libs TARGET_COMPOSITE_LIBS]
                    [--target-composite-devices TARGET_COMPOSITE_DEVICES]
                    [--target-composite-model TARGET_COMPOSITE_MODEL]
                    [--target-composite-tag TARGET_COMPOSITE_TAG]
                    [--target-composite-device TARGET_COMPOSITE_DEVICE]
                    [--target-composite-keys TARGET_COMPOSITE_KEYS]
                    [--target-stackvm-from_device TARGET_STACKVM_FROM_DEVICE]
                    [--target-stackvm-libs TARGET_STACKVM_LIBS]
                    [--target-stackvm-model TARGET_STACKVM_MODEL]
                    [--target-stackvm-system-lib TARGET_STACKVM_SYSTEM_LIB]
                    [--target-stackvm-tag TARGET_STACKVM_TAG]
                    [--target-stackvm-device TARGET_STACKVM_DEVICE]
                    [--target-stackvm-keys TARGET_STACKVM_KEYS]
                    [--target-aocl_sw_emu-from_device TARGET_AOCL_SW_EMU_FROM_DEVICE]
                    [--target-aocl_sw_emu-libs TARGET_AOCL_SW_EMU_LIBS]
                    [--target-aocl_sw_emu-model TARGET_AOCL_SW_EMU_MODEL]
                    [--target-aocl_sw_emu-system-lib TARGET_AOCL_SW_EMU_SYSTEM_LIB]
                    [--target-aocl_sw_emu-tag TARGET_AOCL_SW_EMU_TAG]
                    [--target-aocl_sw_emu-device TARGET_AOCL_SW_EMU_DEVICE]
                    [--target-aocl_sw_emu-keys TARGET_AOCL_SW_EMU_KEYS]
                    [--target-c-unpacked-api TARGET_C_UNPACKED_API]
                    [--target-c-from_device TARGET_C_FROM_DEVICE]
                    [--target-c-libs TARGET_C_LIBS]
                    [--target-c-constants-byte-alignment TARGET_C_CONSTANTS_BYTE_ALIGNMENT]
                    [--target-c-executor TARGET_C_EXECUTOR]
                    [--target-c-link-params TARGET_C_LINK_PARAMS]
                    [--target-c-model TARGET_C_MODEL]
                    [--target-c-workspace-byte-alignment TARGET_C_WORKSPACE_BYTE_ALIGNMENT]
                    [--target-c-system-lib TARGET_C_SYSTEM_LIB]
                    [--target-c-tag TARGET_C_TAG]
                    [--target-c-interface-api TARGET_C_INTERFACE_API]
                    [--target-c-mcpu TARGET_C_MCPU]
                    [--target-c-device TARGET_C_DEVICE]
                    [--target-c-runtime TARGET_C_RUNTIME]
                    [--target-c-keys TARGET_C_KEYS]
                    [--target-c-march TARGET_C_MARCH]
                    [--target-hexagon-from_device TARGET_HEXAGON_FROM_DEVICE]
                    [--target-hexagon-libs TARGET_HEXAGON_LIBS]
                    [--target-hexagon-mattr TARGET_HEXAGON_MATTR]
                    [--target-hexagon-model TARGET_HEXAGON_MODEL]
                    [--target-hexagon-llvm-options TARGET_HEXAGON_LLVM_OPTIONS]
                    [--target-hexagon-mtriple TARGET_HEXAGON_MTRIPLE]
                    [--target-hexagon-system-lib TARGET_HEXAGON_SYSTEM_LIB]
                    [--target-hexagon-mcpu TARGET_HEXAGON_MCPU]
                    [--target-hexagon-device TARGET_HEXAGON_DEVICE]
                    [--target-hexagon-tag TARGET_HEXAGON_TAG]
                    [--target-hexagon-link-params TARGET_HEXAGON_LINK_PARAMS]
                    [--target-hexagon-keys TARGET_HEXAGON_KEYS]
                    [--tuning-records PATH] [--executor EXECUTOR]
                    [--executor-graph-link-params EXECUTOR_GRAPH_LINK_PARAMS]
                    [--executor-aot-workspace-byte-alignment EXECUTOR_AOT_WORKSPACE_BYTE_ALIGNMENT]
                    [--executor-aot-unpacked-api EXECUTOR_AOT_UNPACKED_API]
                    [--executor-aot-interface-api EXECUTOR_AOT_INTERFACE_API]
                    [--executor-aot-link-params EXECUTOR_AOT_LINK_PARAMS]
                    [--runtime RUNTIME]
                    [--runtime-cpp-system-lib RUNTIME_CPP_SYSTEM_LIB]
                    [--runtime-crt-system-lib RUNTIME_CRT_SYSTEM_LIB] [-v]
                    [-O [0-3]] [--input-shapes INPUT_SHAPES]
                    [--disabled-pass DISABLED_PASS]
                    [--module-name MODULE_NAME]
                    FILE

positional arguments:
  FILE                  path to the input model file.

options:
  -h, --help            show this help message and exit
  --cross-compiler CROSS_COMPILER
                        the cross compiler to generate target libraries, e.g.
                        &#39;aarch64-linux-gnu-gcc&#39;.
  --cross-compiler-options CROSS_COMPILER_OPTIONS
                        the cross compiler options to generate target
                        libraries, e.g. &#39;-mfpu=neon-vfpv4&#39;.
  --desired-layout {NCHW,NHWC}
                        change the data layout of the whole graph.
  --dump-code FORMAT    comma separated list of formats to export the input
                        model, e.g. &#39;asm,ll,relay&#39;.
  --model-format {keras,onnx,pb,tflite,pytorch,paddle}
                        specify input model format.
  -o OUTPUT, --output OUTPUT
                        output the compiled module to a specified archive.
                        Defaults to &#39;module.tar&#39;.
  -f {so,mlf}, --output-format {so,mlf}
                        output format. Use &#39;so&#39; for shared object or &#39;mlf&#39; for
                        Model Library Format (only for microTVM targets).
                        Defaults to &#39;so&#39;.
  --pass-config name=value
                        configurations to be used at compile time. This option
                        can be provided multiple times, each one to set one
                        configuration value, e.g. &#39;--pass-config
                        relay.backend.use_auto_scheduler=0&#39;, e.g. &#39;--pass-
                        config
                        tir.add_lower_pass=opt_level1,pass1,opt_level2,pass2&#39;.
  --target TARGET       compilation target as plain string, inline JSON or
                        path to a JSON file
  --tuning-records PATH
                        path to an auto-tuning log file by AutoTVM. If not
                        presented, the fallback/tophub configs will be used.
  --executor EXECUTOR   Executor to compile the model with
  --runtime RUNTIME     Runtime to compile the model with
  -v, --verbose         increase verbosity.
  -O [0-3], --opt-level [0-3]
                        specify which optimization level to use. Defaults to
                        &#39;3&#39;.
  --input-shapes INPUT_SHAPES
                        specify non-generic shapes for model to run, format is
                        &quot;input_name:[dim1,dim2,...,dimn]
                        input_name2:[dim1,dim2]&quot;.
  --disabled-pass DISABLED_PASS
                        disable specific passes, comma-separated list of pass
                        names.
  --module-name MODULE_NAME
                        The output module name. Defaults to &#39;default&#39;.

target example_target_hook:
  --target-example_target_hook-from_device TARGET_EXAMPLE_TARGET_HOOK_FROM_DEVICE
                        target example_target_hook from_device
  --target-example_target_hook-libs TARGET_EXAMPLE_TARGET_HOOK_LIBS
                        target example_target_hook libs options
  --target-example_target_hook-model TARGET_EXAMPLE_TARGET_HOOK_MODEL
                        target example_target_hook model string
  --target-example_target_hook-tag TARGET_EXAMPLE_TARGET_HOOK_TAG
                        target example_target_hook tag string
  --target-example_target_hook-device TARGET_EXAMPLE_TARGET_HOOK_DEVICE
                        target example_target_hook device string
  --target-example_target_hook-keys TARGET_EXAMPLE_TARGET_HOOK_KEYS
                        target example_target_hook keys options

target ext_dev:
  --target-ext_dev-from_device TARGET_EXT_DEV_FROM_DEVICE
                        target ext_dev from_device
  --target-ext_dev-libs TARGET_EXT_DEV_LIBS
                        target ext_dev libs options
  --target-ext_dev-model TARGET_EXT_DEV_MODEL
                        target ext_dev model string
  --target-ext_dev-system-lib TARGET_EXT_DEV_SYSTEM_LIB
                        target ext_dev system-lib
  --target-ext_dev-tag TARGET_EXT_DEV_TAG
                        target ext_dev tag string
  --target-ext_dev-device TARGET_EXT_DEV_DEVICE
                        target ext_dev device string
  --target-ext_dev-keys TARGET_EXT_DEV_KEYS
                        target ext_dev keys options

target llvm:
  --target-llvm-fast-math TARGET_LLVM_FAST_MATH
                        target llvm fast-math
  --target-llvm-opt-level TARGET_LLVM_OPT_LEVEL
                        target llvm opt-level
  --target-llvm-unpacked-api TARGET_LLVM_UNPACKED_API
                        target llvm unpacked-api
  --target-llvm-from_device TARGET_LLVM_FROM_DEVICE
                        target llvm from_device
  --target-llvm-fast-math-ninf TARGET_LLVM_FAST_MATH_NINF
                        target llvm fast-math-ninf
  --target-llvm-mattr TARGET_LLVM_MATTR
                        target llvm mattr options
  --target-llvm-num-cores TARGET_LLVM_NUM_CORES
                        target llvm num-cores
  --target-llvm-libs TARGET_LLVM_LIBS
                        target llvm libs options
  --target-llvm-fast-math-nsz TARGET_LLVM_FAST_MATH_NSZ
                        target llvm fast-math-nsz
  --target-llvm-link-params TARGET_LLVM_LINK_PARAMS
                        target llvm link-params
  --target-llvm-interface-api TARGET_LLVM_INTERFACE_API
                        target llvm interface-api string
  --target-llvm-fast-math-contract TARGET_LLVM_FAST_MATH_CONTRACT
                        target llvm fast-math-contract
  --target-llvm-system-lib TARGET_LLVM_SYSTEM_LIB
                        target llvm system-lib
  --target-llvm-tag TARGET_LLVM_TAG
                        target llvm tag string
  --target-llvm-mtriple TARGET_LLVM_MTRIPLE
                        target llvm mtriple string
  --target-llvm-model TARGET_LLVM_MODEL
                        target llvm model string
  --target-llvm-mfloat-abi TARGET_LLVM_MFLOAT_ABI
                        target llvm mfloat-abi string
  --target-llvm-mcpu TARGET_LLVM_MCPU
                        target llvm mcpu string
  --target-llvm-device TARGET_LLVM_DEVICE
                        target llvm device string
  --target-llvm-runtime TARGET_LLVM_RUNTIME
                        target llvm runtime string
  --target-llvm-fast-math-arcp TARGET_LLVM_FAST_MATH_ARCP
                        target llvm fast-math-arcp
  --target-llvm-fast-math-reassoc TARGET_LLVM_FAST_MATH_REASSOC
                        target llvm fast-math-reassoc
  --target-llvm-mabi TARGET_LLVM_MABI
                        target llvm mabi string
  --target-llvm-keys TARGET_LLVM_KEYS
                        target llvm keys options
  --target-llvm-fast-math-nnan TARGET_LLVM_FAST_MATH_NNAN
                        target llvm fast-math-nnan

target hybrid:
  --target-hybrid-from_device TARGET_HYBRID_FROM_DEVICE
                        target hybrid from_device
  --target-hybrid-libs TARGET_HYBRID_LIBS
                        target hybrid libs options
  --target-hybrid-model TARGET_HYBRID_MODEL
                        target hybrid model string
  --target-hybrid-system-lib TARGET_HYBRID_SYSTEM_LIB
                        target hybrid system-lib
  --target-hybrid-tag TARGET_HYBRID_TAG
                        target hybrid tag string
  --target-hybrid-device TARGET_HYBRID_DEVICE
                        target hybrid device string
  --target-hybrid-keys TARGET_HYBRID_KEYS
                        target hybrid keys options

target aocl:
  --target-aocl-from_device TARGET_AOCL_FROM_DEVICE
                        target aocl from_device
  --target-aocl-libs TARGET_AOCL_LIBS
                        target aocl libs options
  --target-aocl-model TARGET_AOCL_MODEL
                        target aocl model string
  --target-aocl-system-lib TARGET_AOCL_SYSTEM_LIB
                        target aocl system-lib
  --target-aocl-tag TARGET_AOCL_TAG
                        target aocl tag string
  --target-aocl-device TARGET_AOCL_DEVICE
                        target aocl device string
  --target-aocl-keys TARGET_AOCL_KEYS
                        target aocl keys options

target nvptx:
  --target-nvptx-max_num_threads TARGET_NVPTX_MAX_NUM_THREADS
                        target nvptx max_num_threads
  --target-nvptx-thread_warp_size TARGET_NVPTX_THREAD_WARP_SIZE
                        target nvptx thread_warp_size
  --target-nvptx-from_device TARGET_NVPTX_FROM_DEVICE
                        target nvptx from_device
  --target-nvptx-libs TARGET_NVPTX_LIBS
                        target nvptx libs options
  --target-nvptx-model TARGET_NVPTX_MODEL
                        target nvptx model string
  --target-nvptx-system-lib TARGET_NVPTX_SYSTEM_LIB
                        target nvptx system-lib
  --target-nvptx-mtriple TARGET_NVPTX_MTRIPLE
                        target nvptx mtriple string
  --target-nvptx-tag TARGET_NVPTX_TAG
                        target nvptx tag string
  --target-nvptx-mcpu TARGET_NVPTX_MCPU
                        target nvptx mcpu string
  --target-nvptx-device TARGET_NVPTX_DEVICE
                        target nvptx device string
  --target-nvptx-keys TARGET_NVPTX_KEYS
                        target nvptx keys options

target opencl:
  --target-opencl-max_num_threads TARGET_OPENCL_MAX_NUM_THREADS
                        target opencl max_num_threads
  --target-opencl-thread_warp_size TARGET_OPENCL_THREAD_WARP_SIZE
                        target opencl thread_warp_size
  --target-opencl-from_device TARGET_OPENCL_FROM_DEVICE
                        target opencl from_device
  --target-opencl-libs TARGET_OPENCL_LIBS
                        target opencl libs options
  --target-opencl-model TARGET_OPENCL_MODEL
                        target opencl model string
  --target-opencl-system-lib TARGET_OPENCL_SYSTEM_LIB
                        target opencl system-lib
  --target-opencl-tag TARGET_OPENCL_TAG
                        target opencl tag string
  --target-opencl-device TARGET_OPENCL_DEVICE
                        target opencl device string
  --target-opencl-keys TARGET_OPENCL_KEYS
                        target opencl keys options

target metal:
  --target-metal-max_num_threads TARGET_METAL_MAX_NUM_THREADS
                        target metal max_num_threads
  --target-metal-thread_warp_size TARGET_METAL_THREAD_WARP_SIZE
                        target metal thread_warp_size
  --target-metal-from_device TARGET_METAL_FROM_DEVICE
                        target metal from_device
  --target-metal-libs TARGET_METAL_LIBS
                        target metal libs options
  --target-metal-keys TARGET_METAL_KEYS
                        target metal keys options
  --target-metal-model TARGET_METAL_MODEL
                        target metal model string
  --target-metal-system-lib TARGET_METAL_SYSTEM_LIB
                        target metal system-lib
  --target-metal-tag TARGET_METAL_TAG
                        target metal tag string
  --target-metal-device TARGET_METAL_DEVICE
                        target metal device string
  --target-metal-max_function_args TARGET_METAL_MAX_FUNCTION_ARGS
                        target metal max_function_args

target webgpu:
  --target-webgpu-max_num_threads TARGET_WEBGPU_MAX_NUM_THREADS
                        target webgpu max_num_threads
  --target-webgpu-from_device TARGET_WEBGPU_FROM_DEVICE
                        target webgpu from_device
  --target-webgpu-libs TARGET_WEBGPU_LIBS
                        target webgpu libs options
  --target-webgpu-model TARGET_WEBGPU_MODEL
                        target webgpu model string
  --target-webgpu-system-lib TARGET_WEBGPU_SYSTEM_LIB
                        target webgpu system-lib
  --target-webgpu-tag TARGET_WEBGPU_TAG
                        target webgpu tag string
  --target-webgpu-device TARGET_WEBGPU_DEVICE
                        target webgpu device string
  --target-webgpu-keys TARGET_WEBGPU_KEYS
                        target webgpu keys options

target rocm:
  --target-rocm-max_num_threads TARGET_ROCM_MAX_NUM_THREADS
                        target rocm max_num_threads
  --target-rocm-thread_warp_size TARGET_ROCM_THREAD_WARP_SIZE
                        target rocm thread_warp_size
  --target-rocm-from_device TARGET_ROCM_FROM_DEVICE
                        target rocm from_device
  --target-rocm-libs TARGET_ROCM_LIBS
                        target rocm libs options
  --target-rocm-mattr TARGET_ROCM_MATTR
                        target rocm mattr options
  --target-rocm-max_shared_memory_per_block TARGET_ROCM_MAX_SHARED_MEMORY_PER_BLOCK
                        target rocm max_shared_memory_per_block
  --target-rocm-model TARGET_ROCM_MODEL
                        target rocm model string
  --target-rocm-system-lib TARGET_ROCM_SYSTEM_LIB
                        target rocm system-lib
  --target-rocm-mtriple TARGET_ROCM_MTRIPLE
                        target rocm mtriple string
  --target-rocm-tag TARGET_ROCM_TAG
                        target rocm tag string
  --target-rocm-device TARGET_ROCM_DEVICE
                        target rocm device string
  --target-rocm-mcpu TARGET_ROCM_MCPU
                        target rocm mcpu string
  --target-rocm-max_threads_per_block TARGET_ROCM_MAX_THREADS_PER_BLOCK
                        target rocm max_threads_per_block
  --target-rocm-keys TARGET_ROCM_KEYS
                        target rocm keys options

target vulkan:
  --target-vulkan-max_num_threads TARGET_VULKAN_MAX_NUM_THREADS
                        target vulkan max_num_threads
  --target-vulkan-thread_warp_size TARGET_VULKAN_THREAD_WARP_SIZE
                        target vulkan thread_warp_size
  --target-vulkan-from_device TARGET_VULKAN_FROM_DEVICE
                        target vulkan from_device
  --target-vulkan-max_per_stage_descriptor_storage_buffer TARGET_VULKAN_MAX_PER_STAGE_DESCRIPTOR_STORAGE_BUFFER
                        target vulkan max_per_stage_descriptor_storage_buffer
  --target-vulkan-driver_version TARGET_VULKAN_DRIVER_VERSION
                        target vulkan driver_version
  --target-vulkan-supports_16bit_buffer TARGET_VULKAN_SUPPORTS_16BIT_BUFFER
                        target vulkan supports_16bit_buffer
  --target-vulkan-max_block_size_z TARGET_VULKAN_MAX_BLOCK_SIZE_Z
                        target vulkan max_block_size_z
  --target-vulkan-libs TARGET_VULKAN_LIBS
                        target vulkan libs options
  --target-vulkan-supports_dedicated_allocation TARGET_VULKAN_SUPPORTS_DEDICATED_ALLOCATION
                        target vulkan supports_dedicated_allocation
  --target-vulkan-supported_subgroup_operations TARGET_VULKAN_SUPPORTED_SUBGROUP_OPERATIONS
                        target vulkan supported_subgroup_operations
  --target-vulkan-mattr TARGET_VULKAN_MATTR
                        target vulkan mattr options
  --target-vulkan-max_storage_buffer_range TARGET_VULKAN_MAX_STORAGE_BUFFER_RANGE
                        target vulkan max_storage_buffer_range
  --target-vulkan-max_push_constants_size TARGET_VULKAN_MAX_PUSH_CONSTANTS_SIZE
                        target vulkan max_push_constants_size
  --target-vulkan-supports_push_descriptor TARGET_VULKAN_SUPPORTS_PUSH_DESCRIPTOR
                        target vulkan supports_push_descriptor
  --target-vulkan-supports_int64 TARGET_VULKAN_SUPPORTS_INT64
                        target vulkan supports_int64
  --target-vulkan-supports_float32 TARGET_VULKAN_SUPPORTS_FLOAT32
                        target vulkan supports_float32
  --target-vulkan-model TARGET_VULKAN_MODEL
                        target vulkan model string
  --target-vulkan-max_block_size_x TARGET_VULKAN_MAX_BLOCK_SIZE_X
                        target vulkan max_block_size_x
  --target-vulkan-system-lib TARGET_VULKAN_SYSTEM_LIB
                        target vulkan system-lib
  --target-vulkan-max_block_size_y TARGET_VULKAN_MAX_BLOCK_SIZE_Y
                        target vulkan max_block_size_y
  --target-vulkan-tag TARGET_VULKAN_TAG
                        target vulkan tag string
  --target-vulkan-supports_int8 TARGET_VULKAN_SUPPORTS_INT8
                        target vulkan supports_int8
  --target-vulkan-max_spirv_version TARGET_VULKAN_MAX_SPIRV_VERSION
                        target vulkan max_spirv_version
  --target-vulkan-vulkan_api_version TARGET_VULKAN_VULKAN_API_VERSION
                        target vulkan vulkan_api_version
  --target-vulkan-supports_8bit_buffer TARGET_VULKAN_SUPPORTS_8BIT_BUFFER
                        target vulkan supports_8bit_buffer
  --target-vulkan-device_type TARGET_VULKAN_DEVICE_TYPE
                        target vulkan device_type string
  --target-vulkan-supports_int32 TARGET_VULKAN_SUPPORTS_INT32
                        target vulkan supports_int32
  --target-vulkan-device TARGET_VULKAN_DEVICE
                        target vulkan device string
  --target-vulkan-max_threads_per_block TARGET_VULKAN_MAX_THREADS_PER_BLOCK
                        target vulkan max_threads_per_block
  --target-vulkan-max_uniform_buffer_range TARGET_VULKAN_MAX_UNIFORM_BUFFER_RANGE
                        target vulkan max_uniform_buffer_range
  --target-vulkan-driver_name TARGET_VULKAN_DRIVER_NAME
                        target vulkan driver_name string
  --target-vulkan-supports_integer_dot_product TARGET_VULKAN_SUPPORTS_INTEGER_DOT_PRODUCT
                        target vulkan supports_integer_dot_product
  --target-vulkan-supports_storage_buffer_storage_class TARGET_VULKAN_SUPPORTS_STORAGE_BUFFER_STORAGE_CLASS
                        target vulkan supports_storage_buffer_storage_class
  --target-vulkan-supports_float16 TARGET_VULKAN_SUPPORTS_FLOAT16
                        target vulkan supports_float16
  --target-vulkan-device_name TARGET_VULKAN_DEVICE_NAME
                        target vulkan device_name string
  --target-vulkan-supports_float64 TARGET_VULKAN_SUPPORTS_FLOAT64
                        target vulkan supports_float64
  --target-vulkan-keys TARGET_VULKAN_KEYS
                        target vulkan keys options
  --target-vulkan-max_shared_memory_per_block TARGET_VULKAN_MAX_SHARED_MEMORY_PER_BLOCK
                        target vulkan max_shared_memory_per_block
  --target-vulkan-supports_int16 TARGET_VULKAN_SUPPORTS_INT16
                        target vulkan supports_int16

target cuda:
  --target-cuda-max_num_threads TARGET_CUDA_MAX_NUM_THREADS
                        target cuda max_num_threads
  --target-cuda-thread_warp_size TARGET_CUDA_THREAD_WARP_SIZE
                        target cuda thread_warp_size
  --target-cuda-from_device TARGET_CUDA_FROM_DEVICE
                        target cuda from_device
  --target-cuda-arch TARGET_CUDA_ARCH
                        target cuda arch string
  --target-cuda-libs TARGET_CUDA_LIBS
                        target cuda libs options
  --target-cuda-max_shared_memory_per_block TARGET_CUDA_MAX_SHARED_MEMORY_PER_BLOCK
                        target cuda max_shared_memory_per_block
  --target-cuda-model TARGET_CUDA_MODEL
                        target cuda model string
  --target-cuda-system-lib TARGET_CUDA_SYSTEM_LIB
                        target cuda system-lib
  --target-cuda-tag TARGET_CUDA_TAG
                        target cuda tag string
  --target-cuda-device TARGET_CUDA_DEVICE
                        target cuda device string
  --target-cuda-mcpu TARGET_CUDA_MCPU
                        target cuda mcpu string
  --target-cuda-max_threads_per_block TARGET_CUDA_MAX_THREADS_PER_BLOCK
                        target cuda max_threads_per_block
  --target-cuda-registers_per_block TARGET_CUDA_REGISTERS_PER_BLOCK
                        target cuda registers_per_block
  --target-cuda-keys TARGET_CUDA_KEYS
                        target cuda keys options

target sdaccel:
  --target-sdaccel-from_device TARGET_SDACCEL_FROM_DEVICE
                        target sdaccel from_device
  --target-sdaccel-libs TARGET_SDACCEL_LIBS
                        target sdaccel libs options
  --target-sdaccel-model TARGET_SDACCEL_MODEL
                        target sdaccel model string
  --target-sdaccel-system-lib TARGET_SDACCEL_SYSTEM_LIB
                        target sdaccel system-lib
  --target-sdaccel-tag TARGET_SDACCEL_TAG
                        target sdaccel tag string
  --target-sdaccel-device TARGET_SDACCEL_DEVICE
                        target sdaccel device string
  --target-sdaccel-keys TARGET_SDACCEL_KEYS
                        target sdaccel keys options

target composite:
  --target-composite-from_device TARGET_COMPOSITE_FROM_DEVICE
                        target composite from_device
  --target-composite-libs TARGET_COMPOSITE_LIBS
                        target composite libs options
  --target-composite-devices TARGET_COMPOSITE_DEVICES
                        target composite devices options
  --target-composite-model TARGET_COMPOSITE_MODEL
                        target composite model string
  --target-composite-tag TARGET_COMPOSITE_TAG
                        target composite tag string
  --target-composite-device TARGET_COMPOSITE_DEVICE
                        target composite device string
  --target-composite-keys TARGET_COMPOSITE_KEYS
                        target composite keys options

target stackvm:
  --target-stackvm-from_device TARGET_STACKVM_FROM_DEVICE
                        target stackvm from_device
  --target-stackvm-libs TARGET_STACKVM_LIBS
                        target stackvm libs options
  --target-stackvm-model TARGET_STACKVM_MODEL
                        target stackvm model string
  --target-stackvm-system-lib TARGET_STACKVM_SYSTEM_LIB
                        target stackvm system-lib
  --target-stackvm-tag TARGET_STACKVM_TAG
                        target stackvm tag string
  --target-stackvm-device TARGET_STACKVM_DEVICE
                        target stackvm device string
  --target-stackvm-keys TARGET_STACKVM_KEYS
                        target stackvm keys options

target aocl_sw_emu:
  --target-aocl_sw_emu-from_device TARGET_AOCL_SW_EMU_FROM_DEVICE
                        target aocl_sw_emu from_device
  --target-aocl_sw_emu-libs TARGET_AOCL_SW_EMU_LIBS
                        target aocl_sw_emu libs options
  --target-aocl_sw_emu-model TARGET_AOCL_SW_EMU_MODEL
                        target aocl_sw_emu model string
  --target-aocl_sw_emu-system-lib TARGET_AOCL_SW_EMU_SYSTEM_LIB
                        target aocl_sw_emu system-lib
  --target-aocl_sw_emu-tag TARGET_AOCL_SW_EMU_TAG
                        target aocl_sw_emu tag string
  --target-aocl_sw_emu-device TARGET_AOCL_SW_EMU_DEVICE
                        target aocl_sw_emu device string
  --target-aocl_sw_emu-keys TARGET_AOCL_SW_EMU_KEYS
                        target aocl_sw_emu keys options

target c:
  --target-c-unpacked-api TARGET_C_UNPACKED_API
                        target c unpacked-api
  --target-c-from_device TARGET_C_FROM_DEVICE
                        target c from_device
  --target-c-libs TARGET_C_LIBS
                        target c libs options
  --target-c-constants-byte-alignment TARGET_C_CONSTANTS_BYTE_ALIGNMENT
                        target c constants-byte-alignment
  --target-c-executor TARGET_C_EXECUTOR
                        target c executor string
  --target-c-link-params TARGET_C_LINK_PARAMS
                        target c link-params
  --target-c-model TARGET_C_MODEL
                        target c model string
  --target-c-workspace-byte-alignment TARGET_C_WORKSPACE_BYTE_ALIGNMENT
                        target c workspace-byte-alignment
  --target-c-system-lib TARGET_C_SYSTEM_LIB
                        target c system-lib
  --target-c-tag TARGET_C_TAG
                        target c tag string
  --target-c-interface-api TARGET_C_INTERFACE_API
                        target c interface-api string
  --target-c-mcpu TARGET_C_MCPU
                        target c mcpu string
  --target-c-device TARGET_C_DEVICE
                        target c device string
  --target-c-runtime TARGET_C_RUNTIME
                        target c runtime string
  --target-c-keys TARGET_C_KEYS
                        target c keys options
  --target-c-march TARGET_C_MARCH
                        target c march string

target hexagon:
  --target-hexagon-from_device TARGET_HEXAGON_FROM_DEVICE
                        target hexagon from_device
  --target-hexagon-libs TARGET_HEXAGON_LIBS
                        target hexagon libs options
  --target-hexagon-mattr TARGET_HEXAGON_MATTR
                        target hexagon mattr options
  --target-hexagon-model TARGET_HEXAGON_MODEL
                        target hexagon model string
  --target-hexagon-llvm-options TARGET_HEXAGON_LLVM_OPTIONS
                        target hexagon llvm-options options
  --target-hexagon-mtriple TARGET_HEXAGON_MTRIPLE
                        target hexagon mtriple string
  --target-hexagon-system-lib TARGET_HEXAGON_SYSTEM_LIB
                        target hexagon system-lib
  --target-hexagon-mcpu TARGET_HEXAGON_MCPU
                        target hexagon mcpu string
  --target-hexagon-device TARGET_HEXAGON_DEVICE
                        target hexagon device string
  --target-hexagon-tag TARGET_HEXAGON_TAG
                        target hexagon tag string
  --target-hexagon-link-params TARGET_HEXAGON_LINK_PARAMS
                        target hexagon link-params
  --target-hexagon-keys TARGET_HEXAGON_KEYS
                        target hexagon keys options

executor graph:
  --executor-graph-link-params EXECUTOR_GRAPH_LINK_PARAMS
                        Executor graph link-params

executor aot:
  --executor-aot-workspace-byte-alignment EXECUTOR_AOT_WORKSPACE_BYTE_ALIGNMENT
                        Executor aot workspace-byte-alignment
  --executor-aot-unpacked-api EXECUTOR_AOT_UNPACKED_API
                        Executor aot unpacked-api
  --executor-aot-interface-api EXECUTOR_AOT_INTERFACE_API
                        Executor aot interface-api string
  --executor-aot-link-params EXECUTOR_AOT_LINK_PARAMS
                        Executor aot link-params

runtime cpp:
  --runtime-cpp-system-lib RUNTIME_CPP_SYSTEM_LIB
                        Runtime cpp system-lib

runtime crt:
  --runtime-crt-system-lib RUNTIME_CRT_SYSTEM_LIB
                        Runtime crt system-lib
</pre></div>
</div>
</div>
</div>
<div class="admonition-tvm-onnx admonition">
<p class="admonition-title">为 TVM 添加 ONNX 支持</p>
<p>TVM 依赖于你系统中的 ONNX python 库。你可以使用 <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">--user</span> <span class="pre">onnx</span> <span class="pre">onnxoptimizer</span></code> 命令来安装 ONNX。如果你有 root 权限并且想全局安装 ONNX，你可以去掉 <code class="docutils literal notranslate"><span class="pre">--user</span></code> 选项。对 <code class="docutils literal notranslate"><span class="pre">onnxoptimizer</span></code> 的依赖是可选的，仅用于 <code class="docutils literal notranslate"><span class="pre">onnx&gt;=1.9</span></code>。</p>
</div>
</section>
<section id="onnx-tvm">
<h2>将 ONNX 模型编译到 TVM 运行时中<a class="headerlink" href="#onnx-tvm" title="永久链接至标题">#</a></h2>
<p>一旦下载了 ResNet-50 模型，下一步就是对其进行编译。为了达到这个目的，将使用 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">compile</span></code>。从编译过程中得到的输出是模型的 TAR 包，它被编译成目标平台的动态库。可以使用 TVM 运行时在目标设备上运行该模型。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># 这可能需要几分钟的时间，取决于你的机器
!python -m tvm.driver.tvmc compile --target &quot;llvm&quot; \
    --output resnet50-v2-7-tvm.tar \
        ../../_models/resnet50-v2-7.onnx
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
</pre></div>
</div>
</div>
</div>
<p>查看 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">compile</span></code> 在 module 中创建的文件：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
mkdir model
tar -xvf resnet50-v2-7-tvm.tar -C model
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mod.so
mod.json
mod.params
</pre></div>
</div>
</div>
</div>
<p>列出了三个文件：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mod.so</span></code> 是模型，表示为 C++ 库，可以被 TVM 运行时加载。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mod.json</span></code> 是 TVM Relay 计算图的文本表示。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mod.params</span></code> 是包含预训练模型参数的文件。</p></li>
</ul>
<p>该 module 可以被你的应用程序直接加载，而 model 可以通过 TVM 运行时 API 运行。</p>
<div class="admonition-target admonition">
<p class="admonition-title">定义正确的 target</p>
<p>指定正确的目标（选项 <code class="docutils literal notranslate"><span class="pre">--target</span></code>）可以对编译后的模块的性能产生巨大的影响，因为它可以利用目标上可用的硬件特性。</p>
<p>欲了解更多信息，请参考 <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_x86.html#tune-relay-x86"><span class="std std-ref">为 x86 CPU 自动调优卷积网络</span></a>。建议确定你运行的是哪种 CPU，以及可选的功能，并适当地设置目标。</p>
</div>
</section>
<section id="id3">
<h2>用 TVMC 从编译的模块中运行模型<a class="headerlink" href="#id3" title="永久链接至标题">#</a></h2>
<p>已经将模型编译到模块，可以使用 TVM 运行时来进行预测。</p>
<p>TVMC 内置了 TVM 运行时，允许你运行编译的 TVM 模型。为了使用 TVMC 来运行模型并进行预测，需要两样东西：</p>
<ul class="simple">
<li><p>编译后的模块，我们刚刚生成出来。</p></li>
<li><p>对模型的有效输入，以进行预测。</p></li>
</ul>
<p>当涉及到预期的张量形状、格式和数据类型时，每个模型都很特别。出于这个原因，大多数模型需要一些预处理和后处理，以确保输入是有效的，并解释输出结果。TVMC 对输入和输出数据都采用了 NumPy 的 <code class="docutils literal notranslate"><span class="pre">.npz</span></code> 格式。这是得到良好支持的 NumPy 格式，可以将多个数组序列化为文件。</p>
<p>作为本教程的输入，将使用一只猫的图像，但你可以自由地用你选择的任何图像来代替这个图像。</p>
<section id="id4">
<h3>输入预处理<a class="headerlink" href="#id4" title="永久链接至标题">#</a></h3>
<p>对于 ResNet-50 v2 模型，预期输入是 ImageNet 格式的。下面是为 ResNet-50 v2 预处理图像的脚本例子。</p>
<p>你将需要安装支持的 Python 图像库的版本。你可以使用 <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">--user</span> <span class="pre">pillow</span></code> 来满足脚本的这个要求。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!python ./preprocess.py</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">img_url</span> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/model-server/inputs/kitten.jpg&quot;</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="s2">&quot;imagenet_cat.png&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="c1"># Resize it to 224x224</span>
<span class="n">resized_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">resized_image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="c1"># ONNX expects NCHW input, so convert the array</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img_data</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Normalize according to ImageNet</span>
<span class="n">imagenet_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span>
<span class="n">imagenet_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="n">norm_img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">img_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">img_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
      <span class="n">norm_img_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">/</span> <span class="mi">255</span> <span class="o">-</span> <span class="n">imagenet_mean</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">imagenet_stddev</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="c1"># Add batch dimension</span>
<span class="n">img_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">norm_img_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Save to .npz (outputs imagenet_cat.npz)</span>
<span class="n">np</span><span class="o">.</span><span class="n">savez</span><span class="p">(</span><span class="s2">&quot;imagenet_cat&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">img_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h3>运行已编译的模块<a class="headerlink" href="#id5" title="永久链接至标题">#</a></h3>
<p>有了模型和输入数据，现在可以运行 TVMC 来做预测：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc run \
    --inputs imagenet_cat.npz \
    --output predictions.npz \
    resnet50-v2-7-tvm.tar
</pre></div>
</div>
</div>
</div>
<p>回顾一下， <code class="docutils literal notranslate"><span class="pre">.tar</span></code> 模型文件包括 C++ 库，对 Relay 模型的描述，以及模型的参数。TVMC 包括 TVM 运行时，它可以加载模型并根据输入进行预测。当运行上述命令时，TVMC 会输出新文件，<code class="docutils literal notranslate"><span class="pre">predictions.npz</span></code>，其中包含 NumPy 格式的模型输出张量。</p>
<p>在这个例子中，在用于编译的同一台机器上运行该模型。在某些情况下，可能想通过 RPC Tracker 远程运行它。要阅读更多关于这些选项的信息，请查看：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m tvm.driver.tvmc run --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: tvmc run [-h] [--device {cpu,cuda,cl,metal,vulkan,rocm,micro}]
                [--fill-mode {zeros,ones,random}] [-i INPUTS] [-o OUTPUTS]
                [--print-time] [--print-top N] [--profile] [--end-to-end]
                [--repeat N] [--number N] [--rpc-key RPC_KEY]
                [--rpc-tracker RPC_TRACKER] [--list-options]
                PATH

positional arguments:
  PATH                  path to the compiled module file or to the project
                        directory if &#39;--device micro&#39; is selected.

optional arguments:
  -h, --help            show this help message and exit
  --device {cpu,cuda,cl,metal,vulkan,rocm,micro}
                        target device to run the compiled module. Defaults to
                        &#39;cpu&#39;
  --fill-mode {zeros,ones,random}
                        fill all input tensors with values. In case
                        --inputs/-i is provided, they will take precedence
                        over --fill-mode. Any remaining inputs will be filled
                        using the chosen fill mode. Defaults to &#39;random&#39;
  -i INPUTS, --inputs INPUTS
                        path to the .npz input file
  -o OUTPUTS, --outputs OUTPUTS
                        path to the .npz output file
  --print-time          record and print the execution time(s). (non-micro
                        devices only)
  --print-top N         print the top n values and indices of the output
                        tensor
  --profile             generate profiling data from the runtime execution.
                        Using --profile requires the Graph Executor Debug
                        enabled on TVM. Profiling may also have an impact on
                        inference time, making it take longer to be generated.
                        (non-micro devices only)
  --end-to-end          Measure data transfers as well as model execution.
                        This can provide a more realistic performance
                        measurement in many cases.
  --repeat N            run the model n times. Defaults to &#39;1&#39;
  --number N            repeat the run n times. Defaults to &#39;1&#39;
  --rpc-key RPC_KEY     the RPC tracker key of the target device. (non-micro
                        devices only)
  --rpc-tracker RPC_TRACKER
                        hostname (required) and port (optional, defaults to
                        9090) of the RPC tracker, e.g. &#39;192.168.0.100:9999&#39;.
                        (non-micro devices only)
  --list-options        show all run options and option choices when &#39;--device
                        micro&#39; is selected. (micro devices only)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h3>输出后处理<a class="headerlink" href="#id6" title="永久链接至标题">#</a></h3>
<p>如前所述，每个模型都会有自己的特定方式来提供输出张量。</p>
<p>需要运行一些后处理，利用为模型提供的查找表，将 ResNet-50 v2 的输出渲染成人类可读的形式。</p>
<p>下面的脚本显示了后处理的例子，从编译的模块的输出中提取标签。</p>
<p>运行这个脚本应该产生以下输出：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!python ./postprocess.py</span>
<span class="kn">import</span> <span class="nn">os.path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>

<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>

<span class="c1"># Download a list of labels</span>
<span class="n">labels_url</span> <span class="o">=</span> <span class="s2">&quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;</span>
<span class="n">labels_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">labels_url</span><span class="p">,</span> <span class="s2">&quot;synset.txt&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">labels_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>

<span class="n">output_file</span> <span class="o">=</span> <span class="s2">&quot;predictions.npz&quot;</span>

<span class="c1"># Open the output and read the output tensor</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_file</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">output_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;output_0&quot;</span><span class="p">])</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="n">ranks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;class=&#39;</span><span class="si">%s</span><span class="s2">&#39; with probability=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.621104
class=&#39;n02123159 tiger cat&#39; with probability=0.356378
class=&#39;n02124075 Egyptian cat&#39; with probability=0.019712
class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001215
class=&#39;n04040759 radiator&#39; with probability=0.000262
</pre></div>
</div>
</div>
</div>
<p>试着用其他图像替换猫的图像，看看 ResNet 模型会做出什么样的预测。</p>
</section>
</section>
<section id="resnet">
<h2>自动调优 ResNet 模型<a class="headerlink" href="#resnet" title="永久链接至标题">#</a></h2>
<p>之前的模型是为了在 TVM 运行时工作而编译的，但不包括任何特定平台的优化。在本节中，将展示如何使用 TVMC 建立针对你工作平台的优化模型。</p>
<p>在某些情况下，当使用编译模块运行推理时，可能无法获得预期的性能。在这种情况下，可以利用自动调优器，为模型找到更好的配置，获得性能的提升。TVM 中的调优是指对模型进行优化以在给定目标上更快地运行的过程。这与训练或微调不同，因为它不影响模型的准确性，而只影响运行时的性能。作为调优过程的一部分，TVM 将尝试运行许多不同的运算器实现变体，以观察哪些算子表现最佳。这些运行的结果被存储在调优记录文件中，这最终是 <code class="docutils literal notranslate"><span class="pre">tune</span></code> 子命令的输出。</p>
<p>在最简单的形式下，调优要求你提供三样东西：</p>
<ul class="simple">
<li><p>你打算在这个模型上运行的设备的目标规格</p></li>
<li><p>输出文件的路径，调优记录将被保存在该文件中</p></li>
<li><p>最后是要调优的模型的路径。</p></li>
</ul>
<p>默认搜索算法需要 <code class="docutils literal notranslate"><span class="pre">xgboost</span></code>，请参阅下面关于优化搜索算法的详细信息：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install xgboost cloudpickle
</pre></div>
</div>
<p>下面的例子展示了这一做法的实际效果：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc tune --target &quot;llvm&quot; \
    --output resnet50-v2-7-autotuner_records.json \
        ../../_models/resnet50-v2-7.onnx
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/media/pc/data/4tb/lxw/anaconda3/envs/mx39/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
[Task  1/25]  Current/Best:  139.87/ 252.51 GFLOPS | Progress: (40/40) | 20.88 s Done.
[Task  2/25]  Current/Best:   42.44/ 183.76 GFLOPS | Progress: (40/40) | 11.12 s Done.
[Task  3/25]  Current/Best:  176.21/ 215.65 GFLOPS | Progress: (40/40) | 11.55 s Done.
[Task  4/25]  Current/Best:  113.94/ 160.83 GFLOPS | Progress: (40/40) | 13.36 s Done.
[Task  5/25]  Current/Best:  120.38/ 164.05 GFLOPS | Progress: (40/40) | 12.15 s Done.
[Task  6/25]  Current/Best:  103.44/ 188.69 GFLOPS | Progress: (40/40) | 12.60 s Done.
[Task  7/25]  Current/Best:  137.09/ 204.00 GFLOPS | Progress: (40/40) | 11.36 s Done.
[Task  8/25]  Current/Best:   99.24/ 195.34 GFLOPS | Progress: (40/40) | 18.87 s Done.
[Task  9/25]  Current/Best:   70.21/ 189.30 GFLOPS | Progress: (40/40) | 19.84 s Done.
[Task 10/25]  Current/Best:  139.57/ 150.27 GFLOPS | Progress: (40/40) | 11.81 s Done.
[Task 11/25]  Current/Best:  136.51/ 192.55 GFLOPS | Progress: (40/40) | 11.38 s Done.
[Task 12/25]  Current/Best:  127.62/ 216.62 GFLOPS | Progress: (40/40) | 15.05 s Done.
[Task 13/25]  Current/Best:   76.30/ 237.37 GFLOPS | Progress: (40/40) | 12.29 s Done.
[Task 14/25]  Current/Best:   67.69/ 197.50 GFLOPS | Progress: (40/40) | 17.04 s Done.
[Task 16/25]  Current/Best:   57.91/ 200.78 GFLOPS | Progress: (40/40) | 12.76 s Done.
[Task 17/25]  Current/Best:  172.88/ 267.60 GFLOPS | Progress: (40/40) | 12.21 s Done.
[Task 18/25]  Current/Best:  164.30/ 195.15 GFLOPS | Progress: (40/40) | 18.82 s Done.
[Task 19/25]  Current/Best:  122.30/ 209.99 GFLOPS | Progress: (40/40) | 14.50 s Done.
[Task 22/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/40) | 0.00 s s Done.
 Done.
 Done.
[Task 22/25]  Current/Best:   69.31/ 177.25 GFLOPS | Progress: (40/40) | 12.39 s Done.
[Task 23/25]  Current/Best:   92.92/ 185.29 GFLOPS | Progress: (40/40) | 13.99 s Done.
[Task 25/25]  Current/Best:   18.40/  84.62 GFLOPS | Progress: (40/40) | 20.26 s Done.
 Done.
</pre></div>
</div>
</div>
</div>
<p>在这个例子中，如果你为 <code class="docutils literal notranslate"><span class="pre">--target</span></code> 标志指出更具体的目标，你会看到更好的结果。</p>
<p>TVMC 将对模型的参数空间进行搜索，尝试不同的运算符配置，并选择在你的平台上运行最快的一个。尽管这是基于 CPU 和模型操作的指导性搜索，但仍可能需要几个小时来完成搜索。这个搜索的输出将被保存到 <code class="docutils literal notranslate"><span class="pre">resnet50-v2-7-autotuner_records.json</span></code> 文件中，以后将被用来编译优化的模型。</p>
<div class="admonition- admonition">
<p class="admonition-title">定义调优搜索算法</p>
<p>默认情况下，这种搜索是使用 <code class="docutils literal notranslate"><span class="pre">XGBoost</span> <span class="pre">Grid</span></code> 算法引导的。根据你的模型的复杂性和可利用的时间，你可能想选择不同的算法。完整的列表可以通过查阅：</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m tvm.driver.tvmc tune --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: tvmc tune [-h] [--early-stopping EARLY_STOPPING]
                 [--min-repeat-ms MIN_REPEAT_MS]
                 [--model-format {keras,onnx,pb,tflite,pytorch,paddle}]
                 [--number NUMBER] -o OUTPUT [--parallel PARALLEL]
                 [--repeat REPEAT] [--rpc-key RPC_KEY]
                 [--rpc-tracker RPC_TRACKER] [--target TARGET]
                 [--target-example_target_hook-from_device TARGET_EXAMPLE_TARGET_HOOK_FROM_DEVICE]
                 [--target-example_target_hook-libs TARGET_EXAMPLE_TARGET_HOOK_LIBS]
                 [--target-example_target_hook-model TARGET_EXAMPLE_TARGET_HOOK_MODEL]
                 [--target-example_target_hook-tag TARGET_EXAMPLE_TARGET_HOOK_TAG]
                 [--target-example_target_hook-device TARGET_EXAMPLE_TARGET_HOOK_DEVICE]
                 [--target-example_target_hook-keys TARGET_EXAMPLE_TARGET_HOOK_KEYS]
                 [--target-ext_dev-from_device TARGET_EXT_DEV_FROM_DEVICE]
                 [--target-ext_dev-libs TARGET_EXT_DEV_LIBS]
                 [--target-ext_dev-model TARGET_EXT_DEV_MODEL]
                 [--target-ext_dev-system-lib TARGET_EXT_DEV_SYSTEM_LIB]
                 [--target-ext_dev-tag TARGET_EXT_DEV_TAG]
                 [--target-ext_dev-device TARGET_EXT_DEV_DEVICE]
                 [--target-ext_dev-keys TARGET_EXT_DEV_KEYS]
                 [--target-llvm-fast-math TARGET_LLVM_FAST_MATH]
                 [--target-llvm-opt-level TARGET_LLVM_OPT_LEVEL]
                 [--target-llvm-unpacked-api TARGET_LLVM_UNPACKED_API]
                 [--target-llvm-from_device TARGET_LLVM_FROM_DEVICE]
                 [--target-llvm-fast-math-ninf TARGET_LLVM_FAST_MATH_NINF]
                 [--target-llvm-mattr TARGET_LLVM_MATTR]
                 [--target-llvm-num-cores TARGET_LLVM_NUM_CORES]
                 [--target-llvm-libs TARGET_LLVM_LIBS]
                 [--target-llvm-fast-math-nsz TARGET_LLVM_FAST_MATH_NSZ]
                 [--target-llvm-link-params TARGET_LLVM_LINK_PARAMS]
                 [--target-llvm-interface-api TARGET_LLVM_INTERFACE_API]
                 [--target-llvm-fast-math-contract TARGET_LLVM_FAST_MATH_CONTRACT]
                 [--target-llvm-system-lib TARGET_LLVM_SYSTEM_LIB]
                 [--target-llvm-tag TARGET_LLVM_TAG]
                 [--target-llvm-mtriple TARGET_LLVM_MTRIPLE]
                 [--target-llvm-model TARGET_LLVM_MODEL]
                 [--target-llvm-mfloat-abi TARGET_LLVM_MFLOAT_ABI]
                 [--target-llvm-mcpu TARGET_LLVM_MCPU]
                 [--target-llvm-device TARGET_LLVM_DEVICE]
                 [--target-llvm-runtime TARGET_LLVM_RUNTIME]
                 [--target-llvm-fast-math-arcp TARGET_LLVM_FAST_MATH_ARCP]
                 [--target-llvm-fast-math-reassoc TARGET_LLVM_FAST_MATH_REASSOC]
                 [--target-llvm-mabi TARGET_LLVM_MABI]
                 [--target-llvm-keys TARGET_LLVM_KEYS]
                 [--target-llvm-fast-math-nnan TARGET_LLVM_FAST_MATH_NNAN]
                 [--target-hybrid-from_device TARGET_HYBRID_FROM_DEVICE]
                 [--target-hybrid-libs TARGET_HYBRID_LIBS]
                 [--target-hybrid-model TARGET_HYBRID_MODEL]
                 [--target-hybrid-system-lib TARGET_HYBRID_SYSTEM_LIB]
                 [--target-hybrid-tag TARGET_HYBRID_TAG]
                 [--target-hybrid-device TARGET_HYBRID_DEVICE]
                 [--target-hybrid-keys TARGET_HYBRID_KEYS]
                 [--target-aocl-from_device TARGET_AOCL_FROM_DEVICE]
                 [--target-aocl-libs TARGET_AOCL_LIBS]
                 [--target-aocl-model TARGET_AOCL_MODEL]
                 [--target-aocl-system-lib TARGET_AOCL_SYSTEM_LIB]
                 [--target-aocl-tag TARGET_AOCL_TAG]
                 [--target-aocl-device TARGET_AOCL_DEVICE]
                 [--target-aocl-keys TARGET_AOCL_KEYS]
                 [--target-nvptx-max_num_threads TARGET_NVPTX_MAX_NUM_THREADS]
                 [--target-nvptx-thread_warp_size TARGET_NVPTX_THREAD_WARP_SIZE]
                 [--target-nvptx-from_device TARGET_NVPTX_FROM_DEVICE]
                 [--target-nvptx-libs TARGET_NVPTX_LIBS]
                 [--target-nvptx-model TARGET_NVPTX_MODEL]
                 [--target-nvptx-system-lib TARGET_NVPTX_SYSTEM_LIB]
                 [--target-nvptx-mtriple TARGET_NVPTX_MTRIPLE]
                 [--target-nvptx-tag TARGET_NVPTX_TAG]
                 [--target-nvptx-mcpu TARGET_NVPTX_MCPU]
                 [--target-nvptx-device TARGET_NVPTX_DEVICE]
                 [--target-nvptx-keys TARGET_NVPTX_KEYS]
                 [--target-opencl-max_num_threads TARGET_OPENCL_MAX_NUM_THREADS]
                 [--target-opencl-thread_warp_size TARGET_OPENCL_THREAD_WARP_SIZE]
                 [--target-opencl-from_device TARGET_OPENCL_FROM_DEVICE]
                 [--target-opencl-libs TARGET_OPENCL_LIBS]
                 [--target-opencl-model TARGET_OPENCL_MODEL]
                 [--target-opencl-system-lib TARGET_OPENCL_SYSTEM_LIB]
                 [--target-opencl-tag TARGET_OPENCL_TAG]
                 [--target-opencl-device TARGET_OPENCL_DEVICE]
                 [--target-opencl-keys TARGET_OPENCL_KEYS]
                 [--target-metal-max_num_threads TARGET_METAL_MAX_NUM_THREADS]
                 [--target-metal-thread_warp_size TARGET_METAL_THREAD_WARP_SIZE]
                 [--target-metal-from_device TARGET_METAL_FROM_DEVICE]
                 [--target-metal-libs TARGET_METAL_LIBS]
                 [--target-metal-keys TARGET_METAL_KEYS]
                 [--target-metal-model TARGET_METAL_MODEL]
                 [--target-metal-system-lib TARGET_METAL_SYSTEM_LIB]
                 [--target-metal-tag TARGET_METAL_TAG]
                 [--target-metal-device TARGET_METAL_DEVICE]
                 [--target-metal-max_function_args TARGET_METAL_MAX_FUNCTION_ARGS]
                 [--target-webgpu-max_num_threads TARGET_WEBGPU_MAX_NUM_THREADS]
                 [--target-webgpu-from_device TARGET_WEBGPU_FROM_DEVICE]
                 [--target-webgpu-libs TARGET_WEBGPU_LIBS]
                 [--target-webgpu-model TARGET_WEBGPU_MODEL]
                 [--target-webgpu-system-lib TARGET_WEBGPU_SYSTEM_LIB]
                 [--target-webgpu-tag TARGET_WEBGPU_TAG]
                 [--target-webgpu-device TARGET_WEBGPU_DEVICE]
                 [--target-webgpu-keys TARGET_WEBGPU_KEYS]
                 [--target-rocm-max_num_threads TARGET_ROCM_MAX_NUM_THREADS]
                 [--target-rocm-thread_warp_size TARGET_ROCM_THREAD_WARP_SIZE]
                 [--target-rocm-from_device TARGET_ROCM_FROM_DEVICE]
                 [--target-rocm-libs TARGET_ROCM_LIBS]
                 [--target-rocm-mattr TARGET_ROCM_MATTR]
                 [--target-rocm-max_shared_memory_per_block TARGET_ROCM_MAX_SHARED_MEMORY_PER_BLOCK]
                 [--target-rocm-model TARGET_ROCM_MODEL]
                 [--target-rocm-system-lib TARGET_ROCM_SYSTEM_LIB]
                 [--target-rocm-mtriple TARGET_ROCM_MTRIPLE]
                 [--target-rocm-tag TARGET_ROCM_TAG]
                 [--target-rocm-device TARGET_ROCM_DEVICE]
                 [--target-rocm-mcpu TARGET_ROCM_MCPU]
                 [--target-rocm-max_threads_per_block TARGET_ROCM_MAX_THREADS_PER_BLOCK]
                 [--target-rocm-keys TARGET_ROCM_KEYS]
                 [--target-vulkan-max_num_threads TARGET_VULKAN_MAX_NUM_THREADS]
                 [--target-vulkan-thread_warp_size TARGET_VULKAN_THREAD_WARP_SIZE]
                 [--target-vulkan-from_device TARGET_VULKAN_FROM_DEVICE]
                 [--target-vulkan-max_per_stage_descriptor_storage_buffer TARGET_VULKAN_MAX_PER_STAGE_DESCRIPTOR_STORAGE_BUFFER]
                 [--target-vulkan-driver_version TARGET_VULKAN_DRIVER_VERSION]
                 [--target-vulkan-supports_16bit_buffer TARGET_VULKAN_SUPPORTS_16BIT_BUFFER]
                 [--target-vulkan-max_block_size_z TARGET_VULKAN_MAX_BLOCK_SIZE_Z]
                 [--target-vulkan-libs TARGET_VULKAN_LIBS]
                 [--target-vulkan-supports_dedicated_allocation TARGET_VULKAN_SUPPORTS_DEDICATED_ALLOCATION]
                 [--target-vulkan-supported_subgroup_operations TARGET_VULKAN_SUPPORTED_SUBGROUP_OPERATIONS]
                 [--target-vulkan-mattr TARGET_VULKAN_MATTR]
                 [--target-vulkan-max_storage_buffer_range TARGET_VULKAN_MAX_STORAGE_BUFFER_RANGE]
                 [--target-vulkan-max_push_constants_size TARGET_VULKAN_MAX_PUSH_CONSTANTS_SIZE]
                 [--target-vulkan-supports_push_descriptor TARGET_VULKAN_SUPPORTS_PUSH_DESCRIPTOR]
                 [--target-vulkan-supports_int64 TARGET_VULKAN_SUPPORTS_INT64]
                 [--target-vulkan-supports_float32 TARGET_VULKAN_SUPPORTS_FLOAT32]
                 [--target-vulkan-model TARGET_VULKAN_MODEL]
                 [--target-vulkan-max_block_size_x TARGET_VULKAN_MAX_BLOCK_SIZE_X]
                 [--target-vulkan-system-lib TARGET_VULKAN_SYSTEM_LIB]
                 [--target-vulkan-max_block_size_y TARGET_VULKAN_MAX_BLOCK_SIZE_Y]
                 [--target-vulkan-tag TARGET_VULKAN_TAG]
                 [--target-vulkan-supports_int8 TARGET_VULKAN_SUPPORTS_INT8]
                 [--target-vulkan-max_spirv_version TARGET_VULKAN_MAX_SPIRV_VERSION]
                 [--target-vulkan-vulkan_api_version TARGET_VULKAN_VULKAN_API_VERSION]
                 [--target-vulkan-supports_8bit_buffer TARGET_VULKAN_SUPPORTS_8BIT_BUFFER]
                 [--target-vulkan-device_type TARGET_VULKAN_DEVICE_TYPE]
                 [--target-vulkan-supports_int32 TARGET_VULKAN_SUPPORTS_INT32]
                 [--target-vulkan-device TARGET_VULKAN_DEVICE]
                 [--target-vulkan-max_threads_per_block TARGET_VULKAN_MAX_THREADS_PER_BLOCK]
                 [--target-vulkan-max_uniform_buffer_range TARGET_VULKAN_MAX_UNIFORM_BUFFER_RANGE]
                 [--target-vulkan-driver_name TARGET_VULKAN_DRIVER_NAME]
                 [--target-vulkan-supports_integer_dot_product TARGET_VULKAN_SUPPORTS_INTEGER_DOT_PRODUCT]
                 [--target-vulkan-supports_storage_buffer_storage_class TARGET_VULKAN_SUPPORTS_STORAGE_BUFFER_STORAGE_CLASS]
                 [--target-vulkan-supports_float16 TARGET_VULKAN_SUPPORTS_FLOAT16]
                 [--target-vulkan-device_name TARGET_VULKAN_DEVICE_NAME]
                 [--target-vulkan-supports_float64 TARGET_VULKAN_SUPPORTS_FLOAT64]
                 [--target-vulkan-keys TARGET_VULKAN_KEYS]
                 [--target-vulkan-max_shared_memory_per_block TARGET_VULKAN_MAX_SHARED_MEMORY_PER_BLOCK]
                 [--target-vulkan-supports_int16 TARGET_VULKAN_SUPPORTS_INT16]
                 [--target-cuda-max_num_threads TARGET_CUDA_MAX_NUM_THREADS]
                 [--target-cuda-thread_warp_size TARGET_CUDA_THREAD_WARP_SIZE]
                 [--target-cuda-from_device TARGET_CUDA_FROM_DEVICE]
                 [--target-cuda-arch TARGET_CUDA_ARCH]
                 [--target-cuda-libs TARGET_CUDA_LIBS]
                 [--target-cuda-max_shared_memory_per_block TARGET_CUDA_MAX_SHARED_MEMORY_PER_BLOCK]
                 [--target-cuda-model TARGET_CUDA_MODEL]
                 [--target-cuda-system-lib TARGET_CUDA_SYSTEM_LIB]
                 [--target-cuda-tag TARGET_CUDA_TAG]
                 [--target-cuda-device TARGET_CUDA_DEVICE]
                 [--target-cuda-mcpu TARGET_CUDA_MCPU]
                 [--target-cuda-max_threads_per_block TARGET_CUDA_MAX_THREADS_PER_BLOCK]
                 [--target-cuda-registers_per_block TARGET_CUDA_REGISTERS_PER_BLOCK]
                 [--target-cuda-keys TARGET_CUDA_KEYS]
                 [--target-sdaccel-from_device TARGET_SDACCEL_FROM_DEVICE]
                 [--target-sdaccel-libs TARGET_SDACCEL_LIBS]
                 [--target-sdaccel-model TARGET_SDACCEL_MODEL]
                 [--target-sdaccel-system-lib TARGET_SDACCEL_SYSTEM_LIB]
                 [--target-sdaccel-tag TARGET_SDACCEL_TAG]
                 [--target-sdaccel-device TARGET_SDACCEL_DEVICE]
                 [--target-sdaccel-keys TARGET_SDACCEL_KEYS]
                 [--target-composite-from_device TARGET_COMPOSITE_FROM_DEVICE]
                 [--target-composite-libs TARGET_COMPOSITE_LIBS]
                 [--target-composite-devices TARGET_COMPOSITE_DEVICES]
                 [--target-composite-model TARGET_COMPOSITE_MODEL]
                 [--target-composite-tag TARGET_COMPOSITE_TAG]
                 [--target-composite-device TARGET_COMPOSITE_DEVICE]
                 [--target-composite-keys TARGET_COMPOSITE_KEYS]
                 [--target-stackvm-from_device TARGET_STACKVM_FROM_DEVICE]
                 [--target-stackvm-libs TARGET_STACKVM_LIBS]
                 [--target-stackvm-model TARGET_STACKVM_MODEL]
                 [--target-stackvm-system-lib TARGET_STACKVM_SYSTEM_LIB]
                 [--target-stackvm-tag TARGET_STACKVM_TAG]
                 [--target-stackvm-device TARGET_STACKVM_DEVICE]
                 [--target-stackvm-keys TARGET_STACKVM_KEYS]
                 [--target-aocl_sw_emu-from_device TARGET_AOCL_SW_EMU_FROM_DEVICE]
                 [--target-aocl_sw_emu-libs TARGET_AOCL_SW_EMU_LIBS]
                 [--target-aocl_sw_emu-model TARGET_AOCL_SW_EMU_MODEL]
                 [--target-aocl_sw_emu-system-lib TARGET_AOCL_SW_EMU_SYSTEM_LIB]
                 [--target-aocl_sw_emu-tag TARGET_AOCL_SW_EMU_TAG]
                 [--target-aocl_sw_emu-device TARGET_AOCL_SW_EMU_DEVICE]
                 [--target-aocl_sw_emu-keys TARGET_AOCL_SW_EMU_KEYS]
                 [--target-c-unpacked-api TARGET_C_UNPACKED_API]
                 [--target-c-from_device TARGET_C_FROM_DEVICE]
                 [--target-c-libs TARGET_C_LIBS]
                 [--target-c-constants-byte-alignment TARGET_C_CONSTANTS_BYTE_ALIGNMENT]
                 [--target-c-executor TARGET_C_EXECUTOR]
                 [--target-c-link-params TARGET_C_LINK_PARAMS]
                 [--target-c-model TARGET_C_MODEL]
                 [--target-c-workspace-byte-alignment TARGET_C_WORKSPACE_BYTE_ALIGNMENT]
                 [--target-c-system-lib TARGET_C_SYSTEM_LIB]
                 [--target-c-tag TARGET_C_TAG]
                 [--target-c-interface-api TARGET_C_INTERFACE_API]
                 [--target-c-mcpu TARGET_C_MCPU]
                 [--target-c-device TARGET_C_DEVICE]
                 [--target-c-runtime TARGET_C_RUNTIME]
                 [--target-c-keys TARGET_C_KEYS]
                 [--target-c-march TARGET_C_MARCH]
                 [--target-hexagon-from_device TARGET_HEXAGON_FROM_DEVICE]
                 [--target-hexagon-libs TARGET_HEXAGON_LIBS]
                 [--target-hexagon-mattr TARGET_HEXAGON_MATTR]
                 [--target-hexagon-model TARGET_HEXAGON_MODEL]
                 [--target-hexagon-llvm-options TARGET_HEXAGON_LLVM_OPTIONS]
                 [--target-hexagon-mtriple TARGET_HEXAGON_MTRIPLE]
                 [--target-hexagon-system-lib TARGET_HEXAGON_SYSTEM_LIB]
                 [--target-hexagon-mcpu TARGET_HEXAGON_MCPU]
                 [--target-hexagon-device TARGET_HEXAGON_DEVICE]
                 [--target-hexagon-tag TARGET_HEXAGON_TAG]
                 [--target-hexagon-link-params TARGET_HEXAGON_LINK_PARAMS]
                 [--target-hexagon-keys TARGET_HEXAGON_KEYS]
                 [--target-host TARGET_HOST] [--timeout TIMEOUT]
                 [--trials TRIALS] [--tuning-records PATH]
                 [--desired-layout {NCHW,NHWC}] [--enable-autoscheduler]
                 [--cache-line-bytes CACHE_LINE_BYTES] [--num-cores NUM_CORES]
                 [--vector-unit-bytes VECTOR_UNIT_BYTES]
                 [--max-shared-memory-per-block MAX_SHARED_MEMORY_PER_BLOCK]
                 [--max-local-memory-per-block MAX_LOCAL_MEMORY_PER_BLOCK]
                 [--max-threads-per-block MAX_THREADS_PER_BLOCK]
                 [--max-vthread-extent MAX_VTHREAD_EXTENT]
                 [--warp-size WARP_SIZE] [--include-simple-tasks]
                 [--log-estimated-latency]
                 [--tuner {ga,gridsearch,random,xgb,xgb_knob,xgb-rank}]
                 [--input-shapes INPUT_SHAPES]
                 FILE

positional arguments:
  FILE                  path to the input model file

optional arguments:
  -h, --help            show this help message and exit
  --early-stopping EARLY_STOPPING
                        minimum number of trials before early stopping
  --min-repeat-ms MIN_REPEAT_MS
                        minimum time to run each trial, in milliseconds.
                        Defaults to 0 on x86 and 1000 on all other targets
  --model-format {keras,onnx,pb,tflite,pytorch,paddle}
                        specify input model format
  --number NUMBER       number of runs a single repeat is made of. The final
                        number of tuning executions is: (1 + number * repeat)
  -o OUTPUT, --output OUTPUT
                        output file to store the tuning records for the tuning
                        process
  --parallel PARALLEL   the maximum number of parallel devices to use when
                        tuning
  --repeat REPEAT       how many times to repeat each measurement
  --rpc-key RPC_KEY     the RPC tracker key of the target device. Required
                        when --rpc-tracker is provided.
  --rpc-tracker RPC_TRACKER
                        hostname (required) and port (optional, defaults to
                        9090) of the RPC tracker, e.g. &#39;192.168.0.100:9999&#39;
  --target TARGET       compilation target as plain string, inline JSON or
                        path to a JSON file
  --target-host TARGET_HOST
                        the host compilation target, defaults to None
  --timeout TIMEOUT     compilation timeout, in seconds
  --trials TRIALS       the maximum number of tuning trials to perform
  --tuning-records PATH
                        path to an auto-tuning log file by AutoTVM.
  --desired-layout {NCHW,NHWC}
                        change the data layout of the whole graph
  --enable-autoscheduler
                        enable tuning the graph through the AutoScheduler
                        tuner
  --input-shapes INPUT_SHAPES
                        specify non-generic shapes for model to run, format is
                        &quot;input_name:[dim1,dim2,...,dimn]
                        input_name2:[dim1,dim2]&quot;

target example_target_hook:
  --target-example_target_hook-from_device TARGET_EXAMPLE_TARGET_HOOK_FROM_DEVICE
                        target example_target_hook from_device
  --target-example_target_hook-libs TARGET_EXAMPLE_TARGET_HOOK_LIBS
                        target example_target_hook libs options
  --target-example_target_hook-model TARGET_EXAMPLE_TARGET_HOOK_MODEL
                        target example_target_hook model string
  --target-example_target_hook-tag TARGET_EXAMPLE_TARGET_HOOK_TAG
                        target example_target_hook tag string
  --target-example_target_hook-device TARGET_EXAMPLE_TARGET_HOOK_DEVICE
                        target example_target_hook device string
  --target-example_target_hook-keys TARGET_EXAMPLE_TARGET_HOOK_KEYS
                        target example_target_hook keys options

target ext_dev:
  --target-ext_dev-from_device TARGET_EXT_DEV_FROM_DEVICE
                        target ext_dev from_device
  --target-ext_dev-libs TARGET_EXT_DEV_LIBS
                        target ext_dev libs options
  --target-ext_dev-model TARGET_EXT_DEV_MODEL
                        target ext_dev model string
  --target-ext_dev-system-lib TARGET_EXT_DEV_SYSTEM_LIB
                        target ext_dev system-lib
  --target-ext_dev-tag TARGET_EXT_DEV_TAG
                        target ext_dev tag string
  --target-ext_dev-device TARGET_EXT_DEV_DEVICE
                        target ext_dev device string
  --target-ext_dev-keys TARGET_EXT_DEV_KEYS
                        target ext_dev keys options

target llvm:
  --target-llvm-fast-math TARGET_LLVM_FAST_MATH
                        target llvm fast-math
  --target-llvm-opt-level TARGET_LLVM_OPT_LEVEL
                        target llvm opt-level
  --target-llvm-unpacked-api TARGET_LLVM_UNPACKED_API
                        target llvm unpacked-api
  --target-llvm-from_device TARGET_LLVM_FROM_DEVICE
                        target llvm from_device
  --target-llvm-fast-math-ninf TARGET_LLVM_FAST_MATH_NINF
                        target llvm fast-math-ninf
  --target-llvm-mattr TARGET_LLVM_MATTR
                        target llvm mattr options
  --target-llvm-num-cores TARGET_LLVM_NUM_CORES
                        target llvm num-cores
  --target-llvm-libs TARGET_LLVM_LIBS
                        target llvm libs options
  --target-llvm-fast-math-nsz TARGET_LLVM_FAST_MATH_NSZ
                        target llvm fast-math-nsz
  --target-llvm-link-params TARGET_LLVM_LINK_PARAMS
                        target llvm link-params
  --target-llvm-interface-api TARGET_LLVM_INTERFACE_API
                        target llvm interface-api string
  --target-llvm-fast-math-contract TARGET_LLVM_FAST_MATH_CONTRACT
                        target llvm fast-math-contract
  --target-llvm-system-lib TARGET_LLVM_SYSTEM_LIB
                        target llvm system-lib
  --target-llvm-tag TARGET_LLVM_TAG
                        target llvm tag string
  --target-llvm-mtriple TARGET_LLVM_MTRIPLE
                        target llvm mtriple string
  --target-llvm-model TARGET_LLVM_MODEL
                        target llvm model string
  --target-llvm-mfloat-abi TARGET_LLVM_MFLOAT_ABI
                        target llvm mfloat-abi string
  --target-llvm-mcpu TARGET_LLVM_MCPU
                        target llvm mcpu string
  --target-llvm-device TARGET_LLVM_DEVICE
                        target llvm device string
  --target-llvm-runtime TARGET_LLVM_RUNTIME
                        target llvm runtime string
  --target-llvm-fast-math-arcp TARGET_LLVM_FAST_MATH_ARCP
                        target llvm fast-math-arcp
  --target-llvm-fast-math-reassoc TARGET_LLVM_FAST_MATH_REASSOC
                        target llvm fast-math-reassoc
  --target-llvm-mabi TARGET_LLVM_MABI
                        target llvm mabi string
  --target-llvm-keys TARGET_LLVM_KEYS
                        target llvm keys options
  --target-llvm-fast-math-nnan TARGET_LLVM_FAST_MATH_NNAN
                        target llvm fast-math-nnan

target hybrid:
  --target-hybrid-from_device TARGET_HYBRID_FROM_DEVICE
                        target hybrid from_device
  --target-hybrid-libs TARGET_HYBRID_LIBS
                        target hybrid libs options
  --target-hybrid-model TARGET_HYBRID_MODEL
                        target hybrid model string
  --target-hybrid-system-lib TARGET_HYBRID_SYSTEM_LIB
                        target hybrid system-lib
  --target-hybrid-tag TARGET_HYBRID_TAG
                        target hybrid tag string
  --target-hybrid-device TARGET_HYBRID_DEVICE
                        target hybrid device string
  --target-hybrid-keys TARGET_HYBRID_KEYS
                        target hybrid keys options

target aocl:
  --target-aocl-from_device TARGET_AOCL_FROM_DEVICE
                        target aocl from_device
  --target-aocl-libs TARGET_AOCL_LIBS
                        target aocl libs options
  --target-aocl-model TARGET_AOCL_MODEL
                        target aocl model string
  --target-aocl-system-lib TARGET_AOCL_SYSTEM_LIB
                        target aocl system-lib
  --target-aocl-tag TARGET_AOCL_TAG
                        target aocl tag string
  --target-aocl-device TARGET_AOCL_DEVICE
                        target aocl device string
  --target-aocl-keys TARGET_AOCL_KEYS
                        target aocl keys options

target nvptx:
  --target-nvptx-max_num_threads TARGET_NVPTX_MAX_NUM_THREADS
                        target nvptx max_num_threads
  --target-nvptx-thread_warp_size TARGET_NVPTX_THREAD_WARP_SIZE
                        target nvptx thread_warp_size
  --target-nvptx-from_device TARGET_NVPTX_FROM_DEVICE
                        target nvptx from_device
  --target-nvptx-libs TARGET_NVPTX_LIBS
                        target nvptx libs options
  --target-nvptx-model TARGET_NVPTX_MODEL
                        target nvptx model string
  --target-nvptx-system-lib TARGET_NVPTX_SYSTEM_LIB
                        target nvptx system-lib
  --target-nvptx-mtriple TARGET_NVPTX_MTRIPLE
                        target nvptx mtriple string
  --target-nvptx-tag TARGET_NVPTX_TAG
                        target nvptx tag string
  --target-nvptx-mcpu TARGET_NVPTX_MCPU
                        target nvptx mcpu string
  --target-nvptx-device TARGET_NVPTX_DEVICE
                        target nvptx device string
  --target-nvptx-keys TARGET_NVPTX_KEYS
                        target nvptx keys options

target opencl:
  --target-opencl-max_num_threads TARGET_OPENCL_MAX_NUM_THREADS
                        target opencl max_num_threads
  --target-opencl-thread_warp_size TARGET_OPENCL_THREAD_WARP_SIZE
                        target opencl thread_warp_size
  --target-opencl-from_device TARGET_OPENCL_FROM_DEVICE
                        target opencl from_device
  --target-opencl-libs TARGET_OPENCL_LIBS
                        target opencl libs options
  --target-opencl-model TARGET_OPENCL_MODEL
                        target opencl model string
  --target-opencl-system-lib TARGET_OPENCL_SYSTEM_LIB
                        target opencl system-lib
  --target-opencl-tag TARGET_OPENCL_TAG
                        target opencl tag string
  --target-opencl-device TARGET_OPENCL_DEVICE
                        target opencl device string
  --target-opencl-keys TARGET_OPENCL_KEYS
                        target opencl keys options

target metal:
  --target-metal-max_num_threads TARGET_METAL_MAX_NUM_THREADS
                        target metal max_num_threads
  --target-metal-thread_warp_size TARGET_METAL_THREAD_WARP_SIZE
                        target metal thread_warp_size
  --target-metal-from_device TARGET_METAL_FROM_DEVICE
                        target metal from_device
  --target-metal-libs TARGET_METAL_LIBS
                        target metal libs options
  --target-metal-keys TARGET_METAL_KEYS
                        target metal keys options
  --target-metal-model TARGET_METAL_MODEL
                        target metal model string
  --target-metal-system-lib TARGET_METAL_SYSTEM_LIB
                        target metal system-lib
  --target-metal-tag TARGET_METAL_TAG
                        target metal tag string
  --target-metal-device TARGET_METAL_DEVICE
                        target metal device string
  --target-metal-max_function_args TARGET_METAL_MAX_FUNCTION_ARGS
                        target metal max_function_args

target webgpu:
  --target-webgpu-max_num_threads TARGET_WEBGPU_MAX_NUM_THREADS
                        target webgpu max_num_threads
  --target-webgpu-from_device TARGET_WEBGPU_FROM_DEVICE
                        target webgpu from_device
  --target-webgpu-libs TARGET_WEBGPU_LIBS
                        target webgpu libs options
  --target-webgpu-model TARGET_WEBGPU_MODEL
                        target webgpu model string
  --target-webgpu-system-lib TARGET_WEBGPU_SYSTEM_LIB
                        target webgpu system-lib
  --target-webgpu-tag TARGET_WEBGPU_TAG
                        target webgpu tag string
  --target-webgpu-device TARGET_WEBGPU_DEVICE
                        target webgpu device string
  --target-webgpu-keys TARGET_WEBGPU_KEYS
                        target webgpu keys options

target rocm:
  --target-rocm-max_num_threads TARGET_ROCM_MAX_NUM_THREADS
                        target rocm max_num_threads
  --target-rocm-thread_warp_size TARGET_ROCM_THREAD_WARP_SIZE
                        target rocm thread_warp_size
  --target-rocm-from_device TARGET_ROCM_FROM_DEVICE
                        target rocm from_device
  --target-rocm-libs TARGET_ROCM_LIBS
                        target rocm libs options
  --target-rocm-mattr TARGET_ROCM_MATTR
                        target rocm mattr options
  --target-rocm-max_shared_memory_per_block TARGET_ROCM_MAX_SHARED_MEMORY_PER_BLOCK
                        target rocm max_shared_memory_per_block
  --target-rocm-model TARGET_ROCM_MODEL
                        target rocm model string
  --target-rocm-system-lib TARGET_ROCM_SYSTEM_LIB
                        target rocm system-lib
  --target-rocm-mtriple TARGET_ROCM_MTRIPLE
                        target rocm mtriple string
  --target-rocm-tag TARGET_ROCM_TAG
                        target rocm tag string
  --target-rocm-device TARGET_ROCM_DEVICE
                        target rocm device string
  --target-rocm-mcpu TARGET_ROCM_MCPU
                        target rocm mcpu string
  --target-rocm-max_threads_per_block TARGET_ROCM_MAX_THREADS_PER_BLOCK
                        target rocm max_threads_per_block
  --target-rocm-keys TARGET_ROCM_KEYS
                        target rocm keys options

target vulkan:
  --target-vulkan-max_num_threads TARGET_VULKAN_MAX_NUM_THREADS
                        target vulkan max_num_threads
  --target-vulkan-thread_warp_size TARGET_VULKAN_THREAD_WARP_SIZE
                        target vulkan thread_warp_size
  --target-vulkan-from_device TARGET_VULKAN_FROM_DEVICE
                        target vulkan from_device
  --target-vulkan-max_per_stage_descriptor_storage_buffer TARGET_VULKAN_MAX_PER_STAGE_DESCRIPTOR_STORAGE_BUFFER
                        target vulkan max_per_stage_descriptor_storage_buffer
  --target-vulkan-driver_version TARGET_VULKAN_DRIVER_VERSION
                        target vulkan driver_version
  --target-vulkan-supports_16bit_buffer TARGET_VULKAN_SUPPORTS_16BIT_BUFFER
                        target vulkan supports_16bit_buffer
  --target-vulkan-max_block_size_z TARGET_VULKAN_MAX_BLOCK_SIZE_Z
                        target vulkan max_block_size_z
  --target-vulkan-libs TARGET_VULKAN_LIBS
                        target vulkan libs options
  --target-vulkan-supports_dedicated_allocation TARGET_VULKAN_SUPPORTS_DEDICATED_ALLOCATION
                        target vulkan supports_dedicated_allocation
  --target-vulkan-supported_subgroup_operations TARGET_VULKAN_SUPPORTED_SUBGROUP_OPERATIONS
                        target vulkan supported_subgroup_operations
  --target-vulkan-mattr TARGET_VULKAN_MATTR
                        target vulkan mattr options
  --target-vulkan-max_storage_buffer_range TARGET_VULKAN_MAX_STORAGE_BUFFER_RANGE
                        target vulkan max_storage_buffer_range
  --target-vulkan-max_push_constants_size TARGET_VULKAN_MAX_PUSH_CONSTANTS_SIZE
                        target vulkan max_push_constants_size
  --target-vulkan-supports_push_descriptor TARGET_VULKAN_SUPPORTS_PUSH_DESCRIPTOR
                        target vulkan supports_push_descriptor
  --target-vulkan-supports_int64 TARGET_VULKAN_SUPPORTS_INT64
                        target vulkan supports_int64
  --target-vulkan-supports_float32 TARGET_VULKAN_SUPPORTS_FLOAT32
                        target vulkan supports_float32
  --target-vulkan-model TARGET_VULKAN_MODEL
                        target vulkan model string
  --target-vulkan-max_block_size_x TARGET_VULKAN_MAX_BLOCK_SIZE_X
                        target vulkan max_block_size_x
  --target-vulkan-system-lib TARGET_VULKAN_SYSTEM_LIB
                        target vulkan system-lib
  --target-vulkan-max_block_size_y TARGET_VULKAN_MAX_BLOCK_SIZE_Y
                        target vulkan max_block_size_y
  --target-vulkan-tag TARGET_VULKAN_TAG
                        target vulkan tag string
  --target-vulkan-supports_int8 TARGET_VULKAN_SUPPORTS_INT8
                        target vulkan supports_int8
  --target-vulkan-max_spirv_version TARGET_VULKAN_MAX_SPIRV_VERSION
                        target vulkan max_spirv_version
  --target-vulkan-vulkan_api_version TARGET_VULKAN_VULKAN_API_VERSION
                        target vulkan vulkan_api_version
  --target-vulkan-supports_8bit_buffer TARGET_VULKAN_SUPPORTS_8BIT_BUFFER
                        target vulkan supports_8bit_buffer
  --target-vulkan-device_type TARGET_VULKAN_DEVICE_TYPE
                        target vulkan device_type string
  --target-vulkan-supports_int32 TARGET_VULKAN_SUPPORTS_INT32
                        target vulkan supports_int32
  --target-vulkan-device TARGET_VULKAN_DEVICE
                        target vulkan device string
  --target-vulkan-max_threads_per_block TARGET_VULKAN_MAX_THREADS_PER_BLOCK
                        target vulkan max_threads_per_block
  --target-vulkan-max_uniform_buffer_range TARGET_VULKAN_MAX_UNIFORM_BUFFER_RANGE
                        target vulkan max_uniform_buffer_range
  --target-vulkan-driver_name TARGET_VULKAN_DRIVER_NAME
                        target vulkan driver_name string
  --target-vulkan-supports_integer_dot_product TARGET_VULKAN_SUPPORTS_INTEGER_DOT_PRODUCT
                        target vulkan supports_integer_dot_product
  --target-vulkan-supports_storage_buffer_storage_class TARGET_VULKAN_SUPPORTS_STORAGE_BUFFER_STORAGE_CLASS
                        target vulkan supports_storage_buffer_storage_class
  --target-vulkan-supports_float16 TARGET_VULKAN_SUPPORTS_FLOAT16
                        target vulkan supports_float16
  --target-vulkan-device_name TARGET_VULKAN_DEVICE_NAME
                        target vulkan device_name string
  --target-vulkan-supports_float64 TARGET_VULKAN_SUPPORTS_FLOAT64
                        target vulkan supports_float64
  --target-vulkan-keys TARGET_VULKAN_KEYS
                        target vulkan keys options
  --target-vulkan-max_shared_memory_per_block TARGET_VULKAN_MAX_SHARED_MEMORY_PER_BLOCK
                        target vulkan max_shared_memory_per_block
  --target-vulkan-supports_int16 TARGET_VULKAN_SUPPORTS_INT16
                        target vulkan supports_int16

target cuda:
  --target-cuda-max_num_threads TARGET_CUDA_MAX_NUM_THREADS
                        target cuda max_num_threads
  --target-cuda-thread_warp_size TARGET_CUDA_THREAD_WARP_SIZE
                        target cuda thread_warp_size
  --target-cuda-from_device TARGET_CUDA_FROM_DEVICE
                        target cuda from_device
  --target-cuda-arch TARGET_CUDA_ARCH
                        target cuda arch string
  --target-cuda-libs TARGET_CUDA_LIBS
                        target cuda libs options
  --target-cuda-max_shared_memory_per_block TARGET_CUDA_MAX_SHARED_MEMORY_PER_BLOCK
                        target cuda max_shared_memory_per_block
  --target-cuda-model TARGET_CUDA_MODEL
                        target cuda model string
  --target-cuda-system-lib TARGET_CUDA_SYSTEM_LIB
                        target cuda system-lib
  --target-cuda-tag TARGET_CUDA_TAG
                        target cuda tag string
  --target-cuda-device TARGET_CUDA_DEVICE
                        target cuda device string
  --target-cuda-mcpu TARGET_CUDA_MCPU
                        target cuda mcpu string
  --target-cuda-max_threads_per_block TARGET_CUDA_MAX_THREADS_PER_BLOCK
                        target cuda max_threads_per_block
  --target-cuda-registers_per_block TARGET_CUDA_REGISTERS_PER_BLOCK
                        target cuda registers_per_block
  --target-cuda-keys TARGET_CUDA_KEYS
                        target cuda keys options

target sdaccel:
  --target-sdaccel-from_device TARGET_SDACCEL_FROM_DEVICE
                        target sdaccel from_device
  --target-sdaccel-libs TARGET_SDACCEL_LIBS
                        target sdaccel libs options
  --target-sdaccel-model TARGET_SDACCEL_MODEL
                        target sdaccel model string
  --target-sdaccel-system-lib TARGET_SDACCEL_SYSTEM_LIB
                        target sdaccel system-lib
  --target-sdaccel-tag TARGET_SDACCEL_TAG
                        target sdaccel tag string
  --target-sdaccel-device TARGET_SDACCEL_DEVICE
                        target sdaccel device string
  --target-sdaccel-keys TARGET_SDACCEL_KEYS
                        target sdaccel keys options

target composite:
  --target-composite-from_device TARGET_COMPOSITE_FROM_DEVICE
                        target composite from_device
  --target-composite-libs TARGET_COMPOSITE_LIBS
                        target composite libs options
  --target-composite-devices TARGET_COMPOSITE_DEVICES
                        target composite devices options
  --target-composite-model TARGET_COMPOSITE_MODEL
                        target composite model string
  --target-composite-tag TARGET_COMPOSITE_TAG
                        target composite tag string
  --target-composite-device TARGET_COMPOSITE_DEVICE
                        target composite device string
  --target-composite-keys TARGET_COMPOSITE_KEYS
                        target composite keys options

target stackvm:
  --target-stackvm-from_device TARGET_STACKVM_FROM_DEVICE
                        target stackvm from_device
  --target-stackvm-libs TARGET_STACKVM_LIBS
                        target stackvm libs options
  --target-stackvm-model TARGET_STACKVM_MODEL
                        target stackvm model string
  --target-stackvm-system-lib TARGET_STACKVM_SYSTEM_LIB
                        target stackvm system-lib
  --target-stackvm-tag TARGET_STACKVM_TAG
                        target stackvm tag string
  --target-stackvm-device TARGET_STACKVM_DEVICE
                        target stackvm device string
  --target-stackvm-keys TARGET_STACKVM_KEYS
                        target stackvm keys options

target aocl_sw_emu:
  --target-aocl_sw_emu-from_device TARGET_AOCL_SW_EMU_FROM_DEVICE
                        target aocl_sw_emu from_device
  --target-aocl_sw_emu-libs TARGET_AOCL_SW_EMU_LIBS
                        target aocl_sw_emu libs options
  --target-aocl_sw_emu-model TARGET_AOCL_SW_EMU_MODEL
                        target aocl_sw_emu model string
  --target-aocl_sw_emu-system-lib TARGET_AOCL_SW_EMU_SYSTEM_LIB
                        target aocl_sw_emu system-lib
  --target-aocl_sw_emu-tag TARGET_AOCL_SW_EMU_TAG
                        target aocl_sw_emu tag string
  --target-aocl_sw_emu-device TARGET_AOCL_SW_EMU_DEVICE
                        target aocl_sw_emu device string
  --target-aocl_sw_emu-keys TARGET_AOCL_SW_EMU_KEYS
                        target aocl_sw_emu keys options

target c:
  --target-c-unpacked-api TARGET_C_UNPACKED_API
                        target c unpacked-api
  --target-c-from_device TARGET_C_FROM_DEVICE
                        target c from_device
  --target-c-libs TARGET_C_LIBS
                        target c libs options
  --target-c-constants-byte-alignment TARGET_C_CONSTANTS_BYTE_ALIGNMENT
                        target c constants-byte-alignment
  --target-c-executor TARGET_C_EXECUTOR
                        target c executor string
  --target-c-link-params TARGET_C_LINK_PARAMS
                        target c link-params
  --target-c-model TARGET_C_MODEL
                        target c model string
  --target-c-workspace-byte-alignment TARGET_C_WORKSPACE_BYTE_ALIGNMENT
                        target c workspace-byte-alignment
  --target-c-system-lib TARGET_C_SYSTEM_LIB
                        target c system-lib
  --target-c-tag TARGET_C_TAG
                        target c tag string
  --target-c-interface-api TARGET_C_INTERFACE_API
                        target c interface-api string
  --target-c-mcpu TARGET_C_MCPU
                        target c mcpu string
  --target-c-device TARGET_C_DEVICE
                        target c device string
  --target-c-runtime TARGET_C_RUNTIME
                        target c runtime string
  --target-c-keys TARGET_C_KEYS
                        target c keys options
  --target-c-march TARGET_C_MARCH
                        target c march string

target hexagon:
  --target-hexagon-from_device TARGET_HEXAGON_FROM_DEVICE
                        target hexagon from_device
  --target-hexagon-libs TARGET_HEXAGON_LIBS
                        target hexagon libs options
  --target-hexagon-mattr TARGET_HEXAGON_MATTR
                        target hexagon mattr options
  --target-hexagon-model TARGET_HEXAGON_MODEL
                        target hexagon model string
  --target-hexagon-llvm-options TARGET_HEXAGON_LLVM_OPTIONS
                        target hexagon llvm-options options
  --target-hexagon-mtriple TARGET_HEXAGON_MTRIPLE
                        target hexagon mtriple string
  --target-hexagon-system-lib TARGET_HEXAGON_SYSTEM_LIB
                        target hexagon system-lib
  --target-hexagon-mcpu TARGET_HEXAGON_MCPU
                        target hexagon mcpu string
  --target-hexagon-device TARGET_HEXAGON_DEVICE
                        target hexagon device string
  --target-hexagon-tag TARGET_HEXAGON_TAG
                        target hexagon tag string
  --target-hexagon-link-params TARGET_HEXAGON_LINK_PARAMS
                        target hexagon link-params
  --target-hexagon-keys TARGET_HEXAGON_KEYS
                        target hexagon keys options

AutoScheduler options:
  AutoScheduler options, used when --enable-autoscheduler is provided

  --cache-line-bytes CACHE_LINE_BYTES
                        the size of cache line in bytes. If not specified, it
                        will be autoset for the current machine.
  --num-cores NUM_CORES
                        the number of device cores. If not specified, it will
                        be autoset for the current machine.
  --vector-unit-bytes VECTOR_UNIT_BYTES
                        the width of vector units in bytes. If not specified,
                        it will be autoset for the current machine.
  --max-shared-memory-per-block MAX_SHARED_MEMORY_PER_BLOCK
                        the max shared memory per block in bytes. If not
                        specified, it will be autoset for the current machine.
  --max-local-memory-per-block MAX_LOCAL_MEMORY_PER_BLOCK
                        the max local memory per block in bytes. If not
                        specified, it will be autoset for the current machine.
  --max-threads-per-block MAX_THREADS_PER_BLOCK
                        the max number of threads per block. If not specified,
                        it will be autoset for the current machine.
  --max-vthread-extent MAX_VTHREAD_EXTENT
                        the max vthread extent. If not specified, it will be
                        autoset for the current machine.
  --warp-size WARP_SIZE
                        the thread numbers of a warp. If not specified, it
                        will be autoset for the current machine.
  --include-simple-tasks
                        whether to extract simple tasks that do not include
                        complicated ops
  --log-estimated-latency
                        whether to log the estimated latency to the file after
                        tuning a task

AutoTVM options:
  AutoTVM options, used when the AutoScheduler is not enabled

  --tuner {ga,gridsearch,random,xgb,xgb_knob,xgb-rank}
                        type of tuner to use when tuning with autotvm.
</pre></div>
</div>
</div>
</div>
<p>对于消费级 Skylake CPU 来说，输出结果将是这样的：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc tune \
    --target &quot;llvm -mcpu=broadwell&quot; \
        --output resnet50-v2-7-autotuner_records.json \
            ../../_models/resnet50-v2-7.onnx
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/media/pc/data/4tb/lxw/anaconda3/envs/mx39/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
[Task  1/25]  Current/Best:  135.54/ 444.49 GFLOPS | Progress: (40/40) | 16.09 s Done.
[Task  2/25]  Current/Best:   91.39/ 426.70 GFLOPS | Progress: (40/40) | 10.33 s Done.
[Task  3/25]  Current/Best:  147.25/ 516.21 GFLOPS | Progress: (40/40) | 11.55 s Done.
[Task  4/25]  Current/Best:  561.81/ 561.81 GFLOPS | Progress: (40/40) | 12.99 s Done.
[Task  5/25]  Current/Best:  182.70/ 570.25 GFLOPS | Progress: (40/40) | 11.12 s Done.
[Task  6/25]  Current/Best:   79.82/ 459.29 GFLOPS | Progress: (40/40) | 12.03 s Done.
[Task  7/25]  Current/Best:  152.79/ 300.64 GFLOPS | Progress: (40/40) | 11.16 s Done.
[Task  8/25]  Current/Best:  155.29/ 310.77 GFLOPS | Progress: (40/40) | 14.68 s Done.
[Task  9/25]  Current/Best:  126.56/ 561.24 GFLOPS | Progress: (40/40) | 13.93 s Done.
[Task 10/25]  Current/Best:   41.68/ 517.18 GFLOPS | Progress: (40/40) | 10.91 s Done.
[Task 11/25]  Current/Best:  311.13/ 528.67 GFLOPS | Progress: (40/40) | 10.89 s Done.
[Task 12/25]  Current/Best:  265.13/ 525.74 GFLOPS | Progress: (40/40) | 11.19 s Done.
[Task 13/25]  Current/Best:  107.09/ 426.10 GFLOPS | Progress: (40/40) | 11.29 s Done.
[Task 14/25]  Current/Best:  119.32/ 373.60 GFLOPS | Progress: (40/40) | 12.38 s Done.
[Task 15/25]  Current/Best:  101.58/ 439.72 GFLOPS | Progress: (40/40) | 14.41 s Done.
[Task 16/25]  Current/Best:  177.78/ 427.98 GFLOPS | Progress: (40/40) | 10.23 s Done.
[Task 17/25]  Current/Best:   72.04/ 349.15 GFLOPS | Progress: (40/40) | 11.50 s Done.
[Task 18/25]  Current/Best:  124.41/ 500.93 GFLOPS | Progress: (40/40) | 12.07 s Done.
[Task 19/25]  Current/Best:  243.37/ 371.27 GFLOPS | Progress: (40/40) | 12.88 s Done.
[Task 20/25]  Current/Best:  137.63/ 343.57 GFLOPS | Progress: (40/40) | 21.29 s Done.
[Task 21/25]  Current/Best:   59.02/ 330.98 GFLOPS | Progress: (40/40) | 12.88 s Done.
[Task 22/25]  Current/Best:  273.71/ 457.41 GFLOPS | Progress: (40/40) | 11.04 s Done.
[Task 23/25]  Current/Best:  166.89/ 430.39 GFLOPS | Progress: (40/40) | 13.46 s Done.
[Task 25/25]  Current/Best:   28.01/  59.42 GFLOPS | Progress: (40/40) | 20.24 s Done.
 Done.
</pre></div>
</div>
</div>
</div>
<p>调谐会话可能需要很长的时间，所以 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">tune</span></code> 提供了许多选项来定制你的调谐过程，在重复次数方面（例如 <code class="docutils literal notranslate"><span class="pre">--repeat</span></code> 和 <code class="docutils literal notranslate"><span class="pre">--number</span></code>），要使用的调谐算法等等。</p>
</section>
<section id="id7">
<h2>用调优数据编译优化后的模型<a class="headerlink" href="#id7" title="永久链接至标题">#</a></h2>
<p>作为上述调谐过程的输出，获得了存储在 <code class="docutils literal notranslate"><span class="pre">resnet50-v2-7-autotuner_records.json</span></code> 的调谐记录。这个文件可以有两种使用方式：</p>
<ul class="simple">
<li><p>作为进一步调谐的输入（通过 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">tune</span> <span class="pre">--tuning-records</span></code>）。</p></li>
<li><p>作为对编译器的输入</p></li>
</ul>
<p>编译器将使用这些结果来为你指定的目标上的模型生成高性能代码。要做到这一点，可以使用 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">compile</span> <span class="pre">--tuning-records</span></code>。</p>
<p>获得更多信息：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m tvm.driver.tvmc compile --help
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: tvmc compile [-h] [--cross-compiler CROSS_COMPILER]
                    [--cross-compiler-options CROSS_COMPILER_OPTIONS]
                    [--desired-layout {NCHW,NHWC}] [--dump-code FORMAT]
                    [--model-format {keras,onnx,pb,tflite,pytorch,paddle}]
                    [-o OUTPUT] [-f {so,mlf}] [--pass-config name=value]
                    [--target TARGET]
                    [--target-example_target_hook-from_device TARGET_EXAMPLE_TARGET_HOOK_FROM_DEVICE]
                    [--target-example_target_hook-libs TARGET_EXAMPLE_TARGET_HOOK_LIBS]
                    [--target-example_target_hook-model TARGET_EXAMPLE_TARGET_HOOK_MODEL]
                    [--target-example_target_hook-tag TARGET_EXAMPLE_TARGET_HOOK_TAG]
                    [--target-example_target_hook-device TARGET_EXAMPLE_TARGET_HOOK_DEVICE]
                    [--target-example_target_hook-keys TARGET_EXAMPLE_TARGET_HOOK_KEYS]
                    [--target-ext_dev-from_device TARGET_EXT_DEV_FROM_DEVICE]
                    [--target-ext_dev-libs TARGET_EXT_DEV_LIBS]
                    [--target-ext_dev-model TARGET_EXT_DEV_MODEL]
                    [--target-ext_dev-system-lib TARGET_EXT_DEV_SYSTEM_LIB]
                    [--target-ext_dev-tag TARGET_EXT_DEV_TAG]
                    [--target-ext_dev-device TARGET_EXT_DEV_DEVICE]
                    [--target-ext_dev-keys TARGET_EXT_DEV_KEYS]
                    [--target-llvm-fast-math TARGET_LLVM_FAST_MATH]
                    [--target-llvm-opt-level TARGET_LLVM_OPT_LEVEL]
                    [--target-llvm-unpacked-api TARGET_LLVM_UNPACKED_API]
                    [--target-llvm-from_device TARGET_LLVM_FROM_DEVICE]
                    [--target-llvm-fast-math-ninf TARGET_LLVM_FAST_MATH_NINF]
                    [--target-llvm-mattr TARGET_LLVM_MATTR]
                    [--target-llvm-num-cores TARGET_LLVM_NUM_CORES]
                    [--target-llvm-libs TARGET_LLVM_LIBS]
                    [--target-llvm-fast-math-nsz TARGET_LLVM_FAST_MATH_NSZ]
                    [--target-llvm-link-params TARGET_LLVM_LINK_PARAMS]
                    [--target-llvm-interface-api TARGET_LLVM_INTERFACE_API]
                    [--target-llvm-fast-math-contract TARGET_LLVM_FAST_MATH_CONTRACT]
                    [--target-llvm-system-lib TARGET_LLVM_SYSTEM_LIB]
                    [--target-llvm-tag TARGET_LLVM_TAG]
                    [--target-llvm-mtriple TARGET_LLVM_MTRIPLE]
                    [--target-llvm-model TARGET_LLVM_MODEL]
                    [--target-llvm-mfloat-abi TARGET_LLVM_MFLOAT_ABI]
                    [--target-llvm-mcpu TARGET_LLVM_MCPU]
                    [--target-llvm-device TARGET_LLVM_DEVICE]
                    [--target-llvm-runtime TARGET_LLVM_RUNTIME]
                    [--target-llvm-fast-math-arcp TARGET_LLVM_FAST_MATH_ARCP]
                    [--target-llvm-fast-math-reassoc TARGET_LLVM_FAST_MATH_REASSOC]
                    [--target-llvm-mabi TARGET_LLVM_MABI]
                    [--target-llvm-keys TARGET_LLVM_KEYS]
                    [--target-llvm-fast-math-nnan TARGET_LLVM_FAST_MATH_NNAN]
                    [--target-hybrid-from_device TARGET_HYBRID_FROM_DEVICE]
                    [--target-hybrid-libs TARGET_HYBRID_LIBS]
                    [--target-hybrid-model TARGET_HYBRID_MODEL]
                    [--target-hybrid-system-lib TARGET_HYBRID_SYSTEM_LIB]
                    [--target-hybrid-tag TARGET_HYBRID_TAG]
                    [--target-hybrid-device TARGET_HYBRID_DEVICE]
                    [--target-hybrid-keys TARGET_HYBRID_KEYS]
                    [--target-aocl-from_device TARGET_AOCL_FROM_DEVICE]
                    [--target-aocl-libs TARGET_AOCL_LIBS]
                    [--target-aocl-model TARGET_AOCL_MODEL]
                    [--target-aocl-system-lib TARGET_AOCL_SYSTEM_LIB]
                    [--target-aocl-tag TARGET_AOCL_TAG]
                    [--target-aocl-device TARGET_AOCL_DEVICE]
                    [--target-aocl-keys TARGET_AOCL_KEYS]
                    [--target-nvptx-max_num_threads TARGET_NVPTX_MAX_NUM_THREADS]
                    [--target-nvptx-thread_warp_size TARGET_NVPTX_THREAD_WARP_SIZE]
                    [--target-nvptx-from_device TARGET_NVPTX_FROM_DEVICE]
                    [--target-nvptx-libs TARGET_NVPTX_LIBS]
                    [--target-nvptx-model TARGET_NVPTX_MODEL]
                    [--target-nvptx-system-lib TARGET_NVPTX_SYSTEM_LIB]
                    [--target-nvptx-mtriple TARGET_NVPTX_MTRIPLE]
                    [--target-nvptx-tag TARGET_NVPTX_TAG]
                    [--target-nvptx-mcpu TARGET_NVPTX_MCPU]
                    [--target-nvptx-device TARGET_NVPTX_DEVICE]
                    [--target-nvptx-keys TARGET_NVPTX_KEYS]
                    [--target-opencl-max_num_threads TARGET_OPENCL_MAX_NUM_THREADS]
                    [--target-opencl-thread_warp_size TARGET_OPENCL_THREAD_WARP_SIZE]
                    [--target-opencl-from_device TARGET_OPENCL_FROM_DEVICE]
                    [--target-opencl-libs TARGET_OPENCL_LIBS]
                    [--target-opencl-model TARGET_OPENCL_MODEL]
                    [--target-opencl-system-lib TARGET_OPENCL_SYSTEM_LIB]
                    [--target-opencl-tag TARGET_OPENCL_TAG]
                    [--target-opencl-device TARGET_OPENCL_DEVICE]
                    [--target-opencl-keys TARGET_OPENCL_KEYS]
                    [--target-metal-max_num_threads TARGET_METAL_MAX_NUM_THREADS]
                    [--target-metal-thread_warp_size TARGET_METAL_THREAD_WARP_SIZE]
                    [--target-metal-from_device TARGET_METAL_FROM_DEVICE]
                    [--target-metal-libs TARGET_METAL_LIBS]
                    [--target-metal-keys TARGET_METAL_KEYS]
                    [--target-metal-model TARGET_METAL_MODEL]
                    [--target-metal-system-lib TARGET_METAL_SYSTEM_LIB]
                    [--target-metal-tag TARGET_METAL_TAG]
                    [--target-metal-device TARGET_METAL_DEVICE]
                    [--target-metal-max_function_args TARGET_METAL_MAX_FUNCTION_ARGS]
                    [--target-webgpu-max_num_threads TARGET_WEBGPU_MAX_NUM_THREADS]
                    [--target-webgpu-from_device TARGET_WEBGPU_FROM_DEVICE]
                    [--target-webgpu-libs TARGET_WEBGPU_LIBS]
                    [--target-webgpu-model TARGET_WEBGPU_MODEL]
                    [--target-webgpu-system-lib TARGET_WEBGPU_SYSTEM_LIB]
                    [--target-webgpu-tag TARGET_WEBGPU_TAG]
                    [--target-webgpu-device TARGET_WEBGPU_DEVICE]
                    [--target-webgpu-keys TARGET_WEBGPU_KEYS]
                    [--target-rocm-max_num_threads TARGET_ROCM_MAX_NUM_THREADS]
                    [--target-rocm-thread_warp_size TARGET_ROCM_THREAD_WARP_SIZE]
                    [--target-rocm-from_device TARGET_ROCM_FROM_DEVICE]
                    [--target-rocm-libs TARGET_ROCM_LIBS]
                    [--target-rocm-mattr TARGET_ROCM_MATTR]
                    [--target-rocm-max_shared_memory_per_block TARGET_ROCM_MAX_SHARED_MEMORY_PER_BLOCK]
                    [--target-rocm-model TARGET_ROCM_MODEL]
                    [--target-rocm-system-lib TARGET_ROCM_SYSTEM_LIB]
                    [--target-rocm-mtriple TARGET_ROCM_MTRIPLE]
                    [--target-rocm-tag TARGET_ROCM_TAG]
                    [--target-rocm-device TARGET_ROCM_DEVICE]
                    [--target-rocm-mcpu TARGET_ROCM_MCPU]
                    [--target-rocm-max_threads_per_block TARGET_ROCM_MAX_THREADS_PER_BLOCK]
                    [--target-rocm-keys TARGET_ROCM_KEYS]
                    [--target-vulkan-max_num_threads TARGET_VULKAN_MAX_NUM_THREADS]
                    [--target-vulkan-thread_warp_size TARGET_VULKAN_THREAD_WARP_SIZE]
                    [--target-vulkan-from_device TARGET_VULKAN_FROM_DEVICE]
                    [--target-vulkan-max_per_stage_descriptor_storage_buffer TARGET_VULKAN_MAX_PER_STAGE_DESCRIPTOR_STORAGE_BUFFER]
                    [--target-vulkan-driver_version TARGET_VULKAN_DRIVER_VERSION]
                    [--target-vulkan-supports_16bit_buffer TARGET_VULKAN_SUPPORTS_16BIT_BUFFER]
                    [--target-vulkan-max_block_size_z TARGET_VULKAN_MAX_BLOCK_SIZE_Z]
                    [--target-vulkan-libs TARGET_VULKAN_LIBS]
                    [--target-vulkan-supports_dedicated_allocation TARGET_VULKAN_SUPPORTS_DEDICATED_ALLOCATION]
                    [--target-vulkan-supported_subgroup_operations TARGET_VULKAN_SUPPORTED_SUBGROUP_OPERATIONS]
                    [--target-vulkan-mattr TARGET_VULKAN_MATTR]
                    [--target-vulkan-max_storage_buffer_range TARGET_VULKAN_MAX_STORAGE_BUFFER_RANGE]
                    [--target-vulkan-max_push_constants_size TARGET_VULKAN_MAX_PUSH_CONSTANTS_SIZE]
                    [--target-vulkan-supports_push_descriptor TARGET_VULKAN_SUPPORTS_PUSH_DESCRIPTOR]
                    [--target-vulkan-supports_int64 TARGET_VULKAN_SUPPORTS_INT64]
                    [--target-vulkan-supports_float32 TARGET_VULKAN_SUPPORTS_FLOAT32]
                    [--target-vulkan-model TARGET_VULKAN_MODEL]
                    [--target-vulkan-max_block_size_x TARGET_VULKAN_MAX_BLOCK_SIZE_X]
                    [--target-vulkan-system-lib TARGET_VULKAN_SYSTEM_LIB]
                    [--target-vulkan-max_block_size_y TARGET_VULKAN_MAX_BLOCK_SIZE_Y]
                    [--target-vulkan-tag TARGET_VULKAN_TAG]
                    [--target-vulkan-supports_int8 TARGET_VULKAN_SUPPORTS_INT8]
                    [--target-vulkan-max_spirv_version TARGET_VULKAN_MAX_SPIRV_VERSION]
                    [--target-vulkan-vulkan_api_version TARGET_VULKAN_VULKAN_API_VERSION]
                    [--target-vulkan-supports_8bit_buffer TARGET_VULKAN_SUPPORTS_8BIT_BUFFER]
                    [--target-vulkan-device_type TARGET_VULKAN_DEVICE_TYPE]
                    [--target-vulkan-supports_int32 TARGET_VULKAN_SUPPORTS_INT32]
                    [--target-vulkan-device TARGET_VULKAN_DEVICE]
                    [--target-vulkan-max_threads_per_block TARGET_VULKAN_MAX_THREADS_PER_BLOCK]
                    [--target-vulkan-max_uniform_buffer_range TARGET_VULKAN_MAX_UNIFORM_BUFFER_RANGE]
                    [--target-vulkan-driver_name TARGET_VULKAN_DRIVER_NAME]
                    [--target-vulkan-supports_integer_dot_product TARGET_VULKAN_SUPPORTS_INTEGER_DOT_PRODUCT]
                    [--target-vulkan-supports_storage_buffer_storage_class TARGET_VULKAN_SUPPORTS_STORAGE_BUFFER_STORAGE_CLASS]
                    [--target-vulkan-supports_float16 TARGET_VULKAN_SUPPORTS_FLOAT16]
                    [--target-vulkan-device_name TARGET_VULKAN_DEVICE_NAME]
                    [--target-vulkan-supports_float64 TARGET_VULKAN_SUPPORTS_FLOAT64]
                    [--target-vulkan-keys TARGET_VULKAN_KEYS]
                    [--target-vulkan-max_shared_memory_per_block TARGET_VULKAN_MAX_SHARED_MEMORY_PER_BLOCK]
                    [--target-vulkan-supports_int16 TARGET_VULKAN_SUPPORTS_INT16]
                    [--target-cuda-max_num_threads TARGET_CUDA_MAX_NUM_THREADS]
                    [--target-cuda-thread_warp_size TARGET_CUDA_THREAD_WARP_SIZE]
                    [--target-cuda-from_device TARGET_CUDA_FROM_DEVICE]
                    [--target-cuda-arch TARGET_CUDA_ARCH]
                    [--target-cuda-libs TARGET_CUDA_LIBS]
                    [--target-cuda-max_shared_memory_per_block TARGET_CUDA_MAX_SHARED_MEMORY_PER_BLOCK]
                    [--target-cuda-model TARGET_CUDA_MODEL]
                    [--target-cuda-system-lib TARGET_CUDA_SYSTEM_LIB]
                    [--target-cuda-tag TARGET_CUDA_TAG]
                    [--target-cuda-device TARGET_CUDA_DEVICE]
                    [--target-cuda-mcpu TARGET_CUDA_MCPU]
                    [--target-cuda-max_threads_per_block TARGET_CUDA_MAX_THREADS_PER_BLOCK]
                    [--target-cuda-registers_per_block TARGET_CUDA_REGISTERS_PER_BLOCK]
                    [--target-cuda-keys TARGET_CUDA_KEYS]
                    [--target-sdaccel-from_device TARGET_SDACCEL_FROM_DEVICE]
                    [--target-sdaccel-libs TARGET_SDACCEL_LIBS]
                    [--target-sdaccel-model TARGET_SDACCEL_MODEL]
                    [--target-sdaccel-system-lib TARGET_SDACCEL_SYSTEM_LIB]
                    [--target-sdaccel-tag TARGET_SDACCEL_TAG]
                    [--target-sdaccel-device TARGET_SDACCEL_DEVICE]
                    [--target-sdaccel-keys TARGET_SDACCEL_KEYS]
                    [--target-composite-from_device TARGET_COMPOSITE_FROM_DEVICE]
                    [--target-composite-libs TARGET_COMPOSITE_LIBS]
                    [--target-composite-devices TARGET_COMPOSITE_DEVICES]
                    [--target-composite-model TARGET_COMPOSITE_MODEL]
                    [--target-composite-tag TARGET_COMPOSITE_TAG]
                    [--target-composite-device TARGET_COMPOSITE_DEVICE]
                    [--target-composite-keys TARGET_COMPOSITE_KEYS]
                    [--target-stackvm-from_device TARGET_STACKVM_FROM_DEVICE]
                    [--target-stackvm-libs TARGET_STACKVM_LIBS]
                    [--target-stackvm-model TARGET_STACKVM_MODEL]
                    [--target-stackvm-system-lib TARGET_STACKVM_SYSTEM_LIB]
                    [--target-stackvm-tag TARGET_STACKVM_TAG]
                    [--target-stackvm-device TARGET_STACKVM_DEVICE]
                    [--target-stackvm-keys TARGET_STACKVM_KEYS]
                    [--target-aocl_sw_emu-from_device TARGET_AOCL_SW_EMU_FROM_DEVICE]
                    [--target-aocl_sw_emu-libs TARGET_AOCL_SW_EMU_LIBS]
                    [--target-aocl_sw_emu-model TARGET_AOCL_SW_EMU_MODEL]
                    [--target-aocl_sw_emu-system-lib TARGET_AOCL_SW_EMU_SYSTEM_LIB]
                    [--target-aocl_sw_emu-tag TARGET_AOCL_SW_EMU_TAG]
                    [--target-aocl_sw_emu-device TARGET_AOCL_SW_EMU_DEVICE]
                    [--target-aocl_sw_emu-keys TARGET_AOCL_SW_EMU_KEYS]
                    [--target-c-unpacked-api TARGET_C_UNPACKED_API]
                    [--target-c-from_device TARGET_C_FROM_DEVICE]
                    [--target-c-libs TARGET_C_LIBS]
                    [--target-c-constants-byte-alignment TARGET_C_CONSTANTS_BYTE_ALIGNMENT]
                    [--target-c-executor TARGET_C_EXECUTOR]
                    [--target-c-link-params TARGET_C_LINK_PARAMS]
                    [--target-c-model TARGET_C_MODEL]
                    [--target-c-workspace-byte-alignment TARGET_C_WORKSPACE_BYTE_ALIGNMENT]
                    [--target-c-system-lib TARGET_C_SYSTEM_LIB]
                    [--target-c-tag TARGET_C_TAG]
                    [--target-c-interface-api TARGET_C_INTERFACE_API]
                    [--target-c-mcpu TARGET_C_MCPU]
                    [--target-c-device TARGET_C_DEVICE]
                    [--target-c-runtime TARGET_C_RUNTIME]
                    [--target-c-keys TARGET_C_KEYS]
                    [--target-c-march TARGET_C_MARCH]
                    [--target-hexagon-from_device TARGET_HEXAGON_FROM_DEVICE]
                    [--target-hexagon-libs TARGET_HEXAGON_LIBS]
                    [--target-hexagon-mattr TARGET_HEXAGON_MATTR]
                    [--target-hexagon-model TARGET_HEXAGON_MODEL]
                    [--target-hexagon-llvm-options TARGET_HEXAGON_LLVM_OPTIONS]
                    [--target-hexagon-mtriple TARGET_HEXAGON_MTRIPLE]
                    [--target-hexagon-system-lib TARGET_HEXAGON_SYSTEM_LIB]
                    [--target-hexagon-mcpu TARGET_HEXAGON_MCPU]
                    [--target-hexagon-device TARGET_HEXAGON_DEVICE]
                    [--target-hexagon-tag TARGET_HEXAGON_TAG]
                    [--target-hexagon-link-params TARGET_HEXAGON_LINK_PARAMS]
                    [--target-hexagon-keys TARGET_HEXAGON_KEYS]
                    [--tuning-records PATH] [--executor EXECUTOR]
                    [--executor-graph-link-params EXECUTOR_GRAPH_LINK_PARAMS]
                    [--executor-aot-workspace-byte-alignment EXECUTOR_AOT_WORKSPACE_BYTE_ALIGNMENT]
                    [--executor-aot-unpacked-api EXECUTOR_AOT_UNPACKED_API]
                    [--executor-aot-interface-api EXECUTOR_AOT_INTERFACE_API]
                    [--executor-aot-link-params EXECUTOR_AOT_LINK_PARAMS]
                    [--runtime RUNTIME]
                    [--runtime-cpp-system-lib RUNTIME_CPP_SYSTEM_LIB]
                    [--runtime-crt-system-lib RUNTIME_CRT_SYSTEM_LIB] [-v]
                    [-O [0-3]] [--input-shapes INPUT_SHAPES]
                    [--disabled-pass DISABLED_PASS]
                    [--module-name MODULE_NAME]
                    FILE

positional arguments:
  FILE                  path to the input model file.

optional arguments:
  -h, --help            show this help message and exit
  --cross-compiler CROSS_COMPILER
                        the cross compiler to generate target libraries, e.g.
                        &#39;aarch64-linux-gnu-gcc&#39;.
  --cross-compiler-options CROSS_COMPILER_OPTIONS
                        the cross compiler options to generate target
                        libraries, e.g. &#39;-mfpu=neon-vfpv4&#39;.
  --desired-layout {NCHW,NHWC}
                        change the data layout of the whole graph.
  --dump-code FORMAT    comma separated list of formats to export the input
                        model, e.g. &#39;asm,ll,relay&#39;.
  --model-format {keras,onnx,pb,tflite,pytorch,paddle}
                        specify input model format.
  -o OUTPUT, --output OUTPUT
                        output the compiled module to a specified archive.
                        Defaults to &#39;module.tar&#39;.
  -f {so,mlf}, --output-format {so,mlf}
                        output format. Use &#39;so&#39; for shared object or &#39;mlf&#39; for
                        Model Library Format (only for microTVM targets).
                        Defaults to &#39;so&#39;.
  --pass-config name=value
                        configurations to be used at compile time. This option
                        can be provided multiple times, each one to set one
                        configuration value, e.g. &#39;--pass-config
                        relay.backend.use_auto_scheduler=0&#39;, e.g. &#39;--pass-
                        config
                        tir.add_lower_pass=opt_level1,pass1,opt_level2,pass2&#39;.
  --target TARGET       compilation target as plain string, inline JSON or
                        path to a JSON file
  --tuning-records PATH
                        path to an auto-tuning log file by AutoTVM. If not
                        presented, the fallback/tophub configs will be used.
  --executor EXECUTOR   Executor to compile the model with
  --runtime RUNTIME     Runtime to compile the model with
  -v, --verbose         increase verbosity.
  -O [0-3], --opt-level [0-3]
                        specify which optimization level to use. Defaults to
                        &#39;3&#39;.
  --input-shapes INPUT_SHAPES
                        specify non-generic shapes for model to run, format is
                        &quot;input_name:[dim1,dim2,...,dimn]
                        input_name2:[dim1,dim2]&quot;.
  --disabled-pass DISABLED_PASS
                        disable specific passes, comma-separated list of pass
                        names.
  --module-name MODULE_NAME
                        The output module name. Defaults to &#39;default&#39;.

target example_target_hook:
  --target-example_target_hook-from_device TARGET_EXAMPLE_TARGET_HOOK_FROM_DEVICE
                        target example_target_hook from_device
  --target-example_target_hook-libs TARGET_EXAMPLE_TARGET_HOOK_LIBS
                        target example_target_hook libs options
  --target-example_target_hook-model TARGET_EXAMPLE_TARGET_HOOK_MODEL
                        target example_target_hook model string
  --target-example_target_hook-tag TARGET_EXAMPLE_TARGET_HOOK_TAG
                        target example_target_hook tag string
  --target-example_target_hook-device TARGET_EXAMPLE_TARGET_HOOK_DEVICE
                        target example_target_hook device string
  --target-example_target_hook-keys TARGET_EXAMPLE_TARGET_HOOK_KEYS
                        target example_target_hook keys options

target ext_dev:
  --target-ext_dev-from_device TARGET_EXT_DEV_FROM_DEVICE
                        target ext_dev from_device
  --target-ext_dev-libs TARGET_EXT_DEV_LIBS
                        target ext_dev libs options
  --target-ext_dev-model TARGET_EXT_DEV_MODEL
                        target ext_dev model string
  --target-ext_dev-system-lib TARGET_EXT_DEV_SYSTEM_LIB
                        target ext_dev system-lib
  --target-ext_dev-tag TARGET_EXT_DEV_TAG
                        target ext_dev tag string
  --target-ext_dev-device TARGET_EXT_DEV_DEVICE
                        target ext_dev device string
  --target-ext_dev-keys TARGET_EXT_DEV_KEYS
                        target ext_dev keys options

target llvm:
  --target-llvm-fast-math TARGET_LLVM_FAST_MATH
                        target llvm fast-math
  --target-llvm-opt-level TARGET_LLVM_OPT_LEVEL
                        target llvm opt-level
  --target-llvm-unpacked-api TARGET_LLVM_UNPACKED_API
                        target llvm unpacked-api
  --target-llvm-from_device TARGET_LLVM_FROM_DEVICE
                        target llvm from_device
  --target-llvm-fast-math-ninf TARGET_LLVM_FAST_MATH_NINF
                        target llvm fast-math-ninf
  --target-llvm-mattr TARGET_LLVM_MATTR
                        target llvm mattr options
  --target-llvm-num-cores TARGET_LLVM_NUM_CORES
                        target llvm num-cores
  --target-llvm-libs TARGET_LLVM_LIBS
                        target llvm libs options
  --target-llvm-fast-math-nsz TARGET_LLVM_FAST_MATH_NSZ
                        target llvm fast-math-nsz
  --target-llvm-link-params TARGET_LLVM_LINK_PARAMS
                        target llvm link-params
  --target-llvm-interface-api TARGET_LLVM_INTERFACE_API
                        target llvm interface-api string
  --target-llvm-fast-math-contract TARGET_LLVM_FAST_MATH_CONTRACT
                        target llvm fast-math-contract
  --target-llvm-system-lib TARGET_LLVM_SYSTEM_LIB
                        target llvm system-lib
  --target-llvm-tag TARGET_LLVM_TAG
                        target llvm tag string
  --target-llvm-mtriple TARGET_LLVM_MTRIPLE
                        target llvm mtriple string
  --target-llvm-model TARGET_LLVM_MODEL
                        target llvm model string
  --target-llvm-mfloat-abi TARGET_LLVM_MFLOAT_ABI
                        target llvm mfloat-abi string
  --target-llvm-mcpu TARGET_LLVM_MCPU
                        target llvm mcpu string
  --target-llvm-device TARGET_LLVM_DEVICE
                        target llvm device string
  --target-llvm-runtime TARGET_LLVM_RUNTIME
                        target llvm runtime string
  --target-llvm-fast-math-arcp TARGET_LLVM_FAST_MATH_ARCP
                        target llvm fast-math-arcp
  --target-llvm-fast-math-reassoc TARGET_LLVM_FAST_MATH_REASSOC
                        target llvm fast-math-reassoc
  --target-llvm-mabi TARGET_LLVM_MABI
                        target llvm mabi string
  --target-llvm-keys TARGET_LLVM_KEYS
                        target llvm keys options
  --target-llvm-fast-math-nnan TARGET_LLVM_FAST_MATH_NNAN
                        target llvm fast-math-nnan

target hybrid:
  --target-hybrid-from_device TARGET_HYBRID_FROM_DEVICE
                        target hybrid from_device
  --target-hybrid-libs TARGET_HYBRID_LIBS
                        target hybrid libs options
  --target-hybrid-model TARGET_HYBRID_MODEL
                        target hybrid model string
  --target-hybrid-system-lib TARGET_HYBRID_SYSTEM_LIB
                        target hybrid system-lib
  --target-hybrid-tag TARGET_HYBRID_TAG
                        target hybrid tag string
  --target-hybrid-device TARGET_HYBRID_DEVICE
                        target hybrid device string
  --target-hybrid-keys TARGET_HYBRID_KEYS
                        target hybrid keys options

target aocl:
  --target-aocl-from_device TARGET_AOCL_FROM_DEVICE
                        target aocl from_device
  --target-aocl-libs TARGET_AOCL_LIBS
                        target aocl libs options
  --target-aocl-model TARGET_AOCL_MODEL
                        target aocl model string
  --target-aocl-system-lib TARGET_AOCL_SYSTEM_LIB
                        target aocl system-lib
  --target-aocl-tag TARGET_AOCL_TAG
                        target aocl tag string
  --target-aocl-device TARGET_AOCL_DEVICE
                        target aocl device string
  --target-aocl-keys TARGET_AOCL_KEYS
                        target aocl keys options

target nvptx:
  --target-nvptx-max_num_threads TARGET_NVPTX_MAX_NUM_THREADS
                        target nvptx max_num_threads
  --target-nvptx-thread_warp_size TARGET_NVPTX_THREAD_WARP_SIZE
                        target nvptx thread_warp_size
  --target-nvptx-from_device TARGET_NVPTX_FROM_DEVICE
                        target nvptx from_device
  --target-nvptx-libs TARGET_NVPTX_LIBS
                        target nvptx libs options
  --target-nvptx-model TARGET_NVPTX_MODEL
                        target nvptx model string
  --target-nvptx-system-lib TARGET_NVPTX_SYSTEM_LIB
                        target nvptx system-lib
  --target-nvptx-mtriple TARGET_NVPTX_MTRIPLE
                        target nvptx mtriple string
  --target-nvptx-tag TARGET_NVPTX_TAG
                        target nvptx tag string
  --target-nvptx-mcpu TARGET_NVPTX_MCPU
                        target nvptx mcpu string
  --target-nvptx-device TARGET_NVPTX_DEVICE
                        target nvptx device string
  --target-nvptx-keys TARGET_NVPTX_KEYS
                        target nvptx keys options

target opencl:
  --target-opencl-max_num_threads TARGET_OPENCL_MAX_NUM_THREADS
                        target opencl max_num_threads
  --target-opencl-thread_warp_size TARGET_OPENCL_THREAD_WARP_SIZE
                        target opencl thread_warp_size
  --target-opencl-from_device TARGET_OPENCL_FROM_DEVICE
                        target opencl from_device
  --target-opencl-libs TARGET_OPENCL_LIBS
                        target opencl libs options
  --target-opencl-model TARGET_OPENCL_MODEL
                        target opencl model string
  --target-opencl-system-lib TARGET_OPENCL_SYSTEM_LIB
                        target opencl system-lib
  --target-opencl-tag TARGET_OPENCL_TAG
                        target opencl tag string
  --target-opencl-device TARGET_OPENCL_DEVICE
                        target opencl device string
  --target-opencl-keys TARGET_OPENCL_KEYS
                        target opencl keys options

target metal:
  --target-metal-max_num_threads TARGET_METAL_MAX_NUM_THREADS
                        target metal max_num_threads
  --target-metal-thread_warp_size TARGET_METAL_THREAD_WARP_SIZE
                        target metal thread_warp_size
  --target-metal-from_device TARGET_METAL_FROM_DEVICE
                        target metal from_device
  --target-metal-libs TARGET_METAL_LIBS
                        target metal libs options
  --target-metal-keys TARGET_METAL_KEYS
                        target metal keys options
  --target-metal-model TARGET_METAL_MODEL
                        target metal model string
  --target-metal-system-lib TARGET_METAL_SYSTEM_LIB
                        target metal system-lib
  --target-metal-tag TARGET_METAL_TAG
                        target metal tag string
  --target-metal-device TARGET_METAL_DEVICE
                        target metal device string
  --target-metal-max_function_args TARGET_METAL_MAX_FUNCTION_ARGS
                        target metal max_function_args

target webgpu:
  --target-webgpu-max_num_threads TARGET_WEBGPU_MAX_NUM_THREADS
                        target webgpu max_num_threads
  --target-webgpu-from_device TARGET_WEBGPU_FROM_DEVICE
                        target webgpu from_device
  --target-webgpu-libs TARGET_WEBGPU_LIBS
                        target webgpu libs options
  --target-webgpu-model TARGET_WEBGPU_MODEL
                        target webgpu model string
  --target-webgpu-system-lib TARGET_WEBGPU_SYSTEM_LIB
                        target webgpu system-lib
  --target-webgpu-tag TARGET_WEBGPU_TAG
                        target webgpu tag string
  --target-webgpu-device TARGET_WEBGPU_DEVICE
                        target webgpu device string
  --target-webgpu-keys TARGET_WEBGPU_KEYS
                        target webgpu keys options

target rocm:
  --target-rocm-max_num_threads TARGET_ROCM_MAX_NUM_THREADS
                        target rocm max_num_threads
  --target-rocm-thread_warp_size TARGET_ROCM_THREAD_WARP_SIZE
                        target rocm thread_warp_size
  --target-rocm-from_device TARGET_ROCM_FROM_DEVICE
                        target rocm from_device
  --target-rocm-libs TARGET_ROCM_LIBS
                        target rocm libs options
  --target-rocm-mattr TARGET_ROCM_MATTR
                        target rocm mattr options
  --target-rocm-max_shared_memory_per_block TARGET_ROCM_MAX_SHARED_MEMORY_PER_BLOCK
                        target rocm max_shared_memory_per_block
  --target-rocm-model TARGET_ROCM_MODEL
                        target rocm model string
  --target-rocm-system-lib TARGET_ROCM_SYSTEM_LIB
                        target rocm system-lib
  --target-rocm-mtriple TARGET_ROCM_MTRIPLE
                        target rocm mtriple string
  --target-rocm-tag TARGET_ROCM_TAG
                        target rocm tag string
  --target-rocm-device TARGET_ROCM_DEVICE
                        target rocm device string
  --target-rocm-mcpu TARGET_ROCM_MCPU
                        target rocm mcpu string
  --target-rocm-max_threads_per_block TARGET_ROCM_MAX_THREADS_PER_BLOCK
                        target rocm max_threads_per_block
  --target-rocm-keys TARGET_ROCM_KEYS
                        target rocm keys options

target vulkan:
  --target-vulkan-max_num_threads TARGET_VULKAN_MAX_NUM_THREADS
                        target vulkan max_num_threads
  --target-vulkan-thread_warp_size TARGET_VULKAN_THREAD_WARP_SIZE
                        target vulkan thread_warp_size
  --target-vulkan-from_device TARGET_VULKAN_FROM_DEVICE
                        target vulkan from_device
  --target-vulkan-max_per_stage_descriptor_storage_buffer TARGET_VULKAN_MAX_PER_STAGE_DESCRIPTOR_STORAGE_BUFFER
                        target vulkan max_per_stage_descriptor_storage_buffer
  --target-vulkan-driver_version TARGET_VULKAN_DRIVER_VERSION
                        target vulkan driver_version
  --target-vulkan-supports_16bit_buffer TARGET_VULKAN_SUPPORTS_16BIT_BUFFER
                        target vulkan supports_16bit_buffer
  --target-vulkan-max_block_size_z TARGET_VULKAN_MAX_BLOCK_SIZE_Z
                        target vulkan max_block_size_z
  --target-vulkan-libs TARGET_VULKAN_LIBS
                        target vulkan libs options
  --target-vulkan-supports_dedicated_allocation TARGET_VULKAN_SUPPORTS_DEDICATED_ALLOCATION
                        target vulkan supports_dedicated_allocation
  --target-vulkan-supported_subgroup_operations TARGET_VULKAN_SUPPORTED_SUBGROUP_OPERATIONS
                        target vulkan supported_subgroup_operations
  --target-vulkan-mattr TARGET_VULKAN_MATTR
                        target vulkan mattr options
  --target-vulkan-max_storage_buffer_range TARGET_VULKAN_MAX_STORAGE_BUFFER_RANGE
                        target vulkan max_storage_buffer_range
  --target-vulkan-max_push_constants_size TARGET_VULKAN_MAX_PUSH_CONSTANTS_SIZE
                        target vulkan max_push_constants_size
  --target-vulkan-supports_push_descriptor TARGET_VULKAN_SUPPORTS_PUSH_DESCRIPTOR
                        target vulkan supports_push_descriptor
  --target-vulkan-supports_int64 TARGET_VULKAN_SUPPORTS_INT64
                        target vulkan supports_int64
  --target-vulkan-supports_float32 TARGET_VULKAN_SUPPORTS_FLOAT32
                        target vulkan supports_float32
  --target-vulkan-model TARGET_VULKAN_MODEL
                        target vulkan model string
  --target-vulkan-max_block_size_x TARGET_VULKAN_MAX_BLOCK_SIZE_X
                        target vulkan max_block_size_x
  --target-vulkan-system-lib TARGET_VULKAN_SYSTEM_LIB
                        target vulkan system-lib
  --target-vulkan-max_block_size_y TARGET_VULKAN_MAX_BLOCK_SIZE_Y
                        target vulkan max_block_size_y
  --target-vulkan-tag TARGET_VULKAN_TAG
                        target vulkan tag string
  --target-vulkan-supports_int8 TARGET_VULKAN_SUPPORTS_INT8
                        target vulkan supports_int8
  --target-vulkan-max_spirv_version TARGET_VULKAN_MAX_SPIRV_VERSION
                        target vulkan max_spirv_version
  --target-vulkan-vulkan_api_version TARGET_VULKAN_VULKAN_API_VERSION
                        target vulkan vulkan_api_version
  --target-vulkan-supports_8bit_buffer TARGET_VULKAN_SUPPORTS_8BIT_BUFFER
                        target vulkan supports_8bit_buffer
  --target-vulkan-device_type TARGET_VULKAN_DEVICE_TYPE
                        target vulkan device_type string
  --target-vulkan-supports_int32 TARGET_VULKAN_SUPPORTS_INT32
                        target vulkan supports_int32
  --target-vulkan-device TARGET_VULKAN_DEVICE
                        target vulkan device string
  --target-vulkan-max_threads_per_block TARGET_VULKAN_MAX_THREADS_PER_BLOCK
                        target vulkan max_threads_per_block
  --target-vulkan-max_uniform_buffer_range TARGET_VULKAN_MAX_UNIFORM_BUFFER_RANGE
                        target vulkan max_uniform_buffer_range
  --target-vulkan-driver_name TARGET_VULKAN_DRIVER_NAME
                        target vulkan driver_name string
  --target-vulkan-supports_integer_dot_product TARGET_VULKAN_SUPPORTS_INTEGER_DOT_PRODUCT
                        target vulkan supports_integer_dot_product
  --target-vulkan-supports_storage_buffer_storage_class TARGET_VULKAN_SUPPORTS_STORAGE_BUFFER_STORAGE_CLASS
                        target vulkan supports_storage_buffer_storage_class
  --target-vulkan-supports_float16 TARGET_VULKAN_SUPPORTS_FLOAT16
                        target vulkan supports_float16
  --target-vulkan-device_name TARGET_VULKAN_DEVICE_NAME
                        target vulkan device_name string
  --target-vulkan-supports_float64 TARGET_VULKAN_SUPPORTS_FLOAT64
                        target vulkan supports_float64
  --target-vulkan-keys TARGET_VULKAN_KEYS
                        target vulkan keys options
  --target-vulkan-max_shared_memory_per_block TARGET_VULKAN_MAX_SHARED_MEMORY_PER_BLOCK
                        target vulkan max_shared_memory_per_block
  --target-vulkan-supports_int16 TARGET_VULKAN_SUPPORTS_INT16
                        target vulkan supports_int16

target cuda:
  --target-cuda-max_num_threads TARGET_CUDA_MAX_NUM_THREADS
                        target cuda max_num_threads
  --target-cuda-thread_warp_size TARGET_CUDA_THREAD_WARP_SIZE
                        target cuda thread_warp_size
  --target-cuda-from_device TARGET_CUDA_FROM_DEVICE
                        target cuda from_device
  --target-cuda-arch TARGET_CUDA_ARCH
                        target cuda arch string
  --target-cuda-libs TARGET_CUDA_LIBS
                        target cuda libs options
  --target-cuda-max_shared_memory_per_block TARGET_CUDA_MAX_SHARED_MEMORY_PER_BLOCK
                        target cuda max_shared_memory_per_block
  --target-cuda-model TARGET_CUDA_MODEL
                        target cuda model string
  --target-cuda-system-lib TARGET_CUDA_SYSTEM_LIB
                        target cuda system-lib
  --target-cuda-tag TARGET_CUDA_TAG
                        target cuda tag string
  --target-cuda-device TARGET_CUDA_DEVICE
                        target cuda device string
  --target-cuda-mcpu TARGET_CUDA_MCPU
                        target cuda mcpu string
  --target-cuda-max_threads_per_block TARGET_CUDA_MAX_THREADS_PER_BLOCK
                        target cuda max_threads_per_block
  --target-cuda-registers_per_block TARGET_CUDA_REGISTERS_PER_BLOCK
                        target cuda registers_per_block
  --target-cuda-keys TARGET_CUDA_KEYS
                        target cuda keys options

target sdaccel:
  --target-sdaccel-from_device TARGET_SDACCEL_FROM_DEVICE
                        target sdaccel from_device
  --target-sdaccel-libs TARGET_SDACCEL_LIBS
                        target sdaccel libs options
  --target-sdaccel-model TARGET_SDACCEL_MODEL
                        target sdaccel model string
  --target-sdaccel-system-lib TARGET_SDACCEL_SYSTEM_LIB
                        target sdaccel system-lib
  --target-sdaccel-tag TARGET_SDACCEL_TAG
                        target sdaccel tag string
  --target-sdaccel-device TARGET_SDACCEL_DEVICE
                        target sdaccel device string
  --target-sdaccel-keys TARGET_SDACCEL_KEYS
                        target sdaccel keys options

target composite:
  --target-composite-from_device TARGET_COMPOSITE_FROM_DEVICE
                        target composite from_device
  --target-composite-libs TARGET_COMPOSITE_LIBS
                        target composite libs options
  --target-composite-devices TARGET_COMPOSITE_DEVICES
                        target composite devices options
  --target-composite-model TARGET_COMPOSITE_MODEL
                        target composite model string
  --target-composite-tag TARGET_COMPOSITE_TAG
                        target composite tag string
  --target-composite-device TARGET_COMPOSITE_DEVICE
                        target composite device string
  --target-composite-keys TARGET_COMPOSITE_KEYS
                        target composite keys options

target stackvm:
  --target-stackvm-from_device TARGET_STACKVM_FROM_DEVICE
                        target stackvm from_device
  --target-stackvm-libs TARGET_STACKVM_LIBS
                        target stackvm libs options
  --target-stackvm-model TARGET_STACKVM_MODEL
                        target stackvm model string
  --target-stackvm-system-lib TARGET_STACKVM_SYSTEM_LIB
                        target stackvm system-lib
  --target-stackvm-tag TARGET_STACKVM_TAG
                        target stackvm tag string
  --target-stackvm-device TARGET_STACKVM_DEVICE
                        target stackvm device string
  --target-stackvm-keys TARGET_STACKVM_KEYS
                        target stackvm keys options

target aocl_sw_emu:
  --target-aocl_sw_emu-from_device TARGET_AOCL_SW_EMU_FROM_DEVICE
                        target aocl_sw_emu from_device
  --target-aocl_sw_emu-libs TARGET_AOCL_SW_EMU_LIBS
                        target aocl_sw_emu libs options
  --target-aocl_sw_emu-model TARGET_AOCL_SW_EMU_MODEL
                        target aocl_sw_emu model string
  --target-aocl_sw_emu-system-lib TARGET_AOCL_SW_EMU_SYSTEM_LIB
                        target aocl_sw_emu system-lib
  --target-aocl_sw_emu-tag TARGET_AOCL_SW_EMU_TAG
                        target aocl_sw_emu tag string
  --target-aocl_sw_emu-device TARGET_AOCL_SW_EMU_DEVICE
                        target aocl_sw_emu device string
  --target-aocl_sw_emu-keys TARGET_AOCL_SW_EMU_KEYS
                        target aocl_sw_emu keys options

target c:
  --target-c-unpacked-api TARGET_C_UNPACKED_API
                        target c unpacked-api
  --target-c-from_device TARGET_C_FROM_DEVICE
                        target c from_device
  --target-c-libs TARGET_C_LIBS
                        target c libs options
  --target-c-constants-byte-alignment TARGET_C_CONSTANTS_BYTE_ALIGNMENT
                        target c constants-byte-alignment
  --target-c-executor TARGET_C_EXECUTOR
                        target c executor string
  --target-c-link-params TARGET_C_LINK_PARAMS
                        target c link-params
  --target-c-model TARGET_C_MODEL
                        target c model string
  --target-c-workspace-byte-alignment TARGET_C_WORKSPACE_BYTE_ALIGNMENT
                        target c workspace-byte-alignment
  --target-c-system-lib TARGET_C_SYSTEM_LIB
                        target c system-lib
  --target-c-tag TARGET_C_TAG
                        target c tag string
  --target-c-interface-api TARGET_C_INTERFACE_API
                        target c interface-api string
  --target-c-mcpu TARGET_C_MCPU
                        target c mcpu string
  --target-c-device TARGET_C_DEVICE
                        target c device string
  --target-c-runtime TARGET_C_RUNTIME
                        target c runtime string
  --target-c-keys TARGET_C_KEYS
                        target c keys options
  --target-c-march TARGET_C_MARCH
                        target c march string

target hexagon:
  --target-hexagon-from_device TARGET_HEXAGON_FROM_DEVICE
                        target hexagon from_device
  --target-hexagon-libs TARGET_HEXAGON_LIBS
                        target hexagon libs options
  --target-hexagon-mattr TARGET_HEXAGON_MATTR
                        target hexagon mattr options
  --target-hexagon-model TARGET_HEXAGON_MODEL
                        target hexagon model string
  --target-hexagon-llvm-options TARGET_HEXAGON_LLVM_OPTIONS
                        target hexagon llvm-options options
  --target-hexagon-mtriple TARGET_HEXAGON_MTRIPLE
                        target hexagon mtriple string
  --target-hexagon-system-lib TARGET_HEXAGON_SYSTEM_LIB
                        target hexagon system-lib
  --target-hexagon-mcpu TARGET_HEXAGON_MCPU
                        target hexagon mcpu string
  --target-hexagon-device TARGET_HEXAGON_DEVICE
                        target hexagon device string
  --target-hexagon-tag TARGET_HEXAGON_TAG
                        target hexagon tag string
  --target-hexagon-link-params TARGET_HEXAGON_LINK_PARAMS
                        target hexagon link-params
  --target-hexagon-keys TARGET_HEXAGON_KEYS
                        target hexagon keys options

executor graph:
  --executor-graph-link-params EXECUTOR_GRAPH_LINK_PARAMS
                        Executor graph link-params

executor aot:
  --executor-aot-workspace-byte-alignment EXECUTOR_AOT_WORKSPACE_BYTE_ALIGNMENT
                        Executor aot workspace-byte-alignment
  --executor-aot-unpacked-api EXECUTOR_AOT_UNPACKED_API
                        Executor aot unpacked-api
  --executor-aot-interface-api EXECUTOR_AOT_INTERFACE_API
                        Executor aot interface-api string
  --executor-aot-link-params EXECUTOR_AOT_LINK_PARAMS
                        Executor aot link-params

runtime cpp:
  --runtime-cpp-system-lib RUNTIME_CPP_SYSTEM_LIB
                        Runtime cpp system-lib

runtime crt:
  --runtime-crt-system-lib RUNTIME_CRT_SYSTEM_LIB
                        Runtime crt system-lib
</pre></div>
</div>
</div>
</div>
<p>现在，模型的调谐数据已经收集完毕，可以使用优化的算子重新编译模型，以加快计算速度。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc compile \
    --target &quot;llvm&quot; \
        --tuning-records resnet50-v2-7-autotuner_records.json  \
            --output resnet50-v2-7-tvm_autotuned.tar \
                ../../_models/resnet50-v2-7.onnx
</pre></div>
</div>
</div>
</div>
<p>验证优化后的模型是否运行并产生相同的结果：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc run \
    --inputs imagenet_cat.npz \
        --output predictions.npz \
            resnet50-v2-7-tvm_autotuned.tar

!python postprocess.py
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class=&#39;n02123045 tabby, tabby cat&#39; with probability=0.621104
class=&#39;n02123159 tiger cat&#39; with probability=0.356378
class=&#39;n02124075 Egyptian cat&#39; with probability=0.019712
class=&#39;n02129604 tiger, Panthera tigris&#39; with probability=0.001215
class=&#39;n04040759 radiator&#39; with probability=0.000262
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h2>比较已调谐和未调谐的模型<a class="headerlink" href="#id8" title="永久链接至标题">#</a></h2>
<p>TVMC 提供了在模型之间进行基本性能基准测试的工具。你可以指定重复次数，并且 TVMC 报告模型的运行时间（与运行时间的启动无关）。可以粗略了解调谐对模型性能的改善程度。例如，在测试的英特尔 i7 系统上，看到调谐后的模型比未调谐的模型运行快  <span class="math notranslate nohighlight">\(47\%\)</span>。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc run \
    --inputs imagenet_cat.npz \
        --output predictions.npz  \
            --print-time \
                --repeat 100 \
                    resnet50-v2-7-tvm_autotuned.tar
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Execution time summary:
 mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  
  41.2506      40.8879      54.4469      36.7249       2.4430   
               
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!python -m tvm.driver.tvmc run \
    --inputs imagenet_cat.npz \
        --output predictions.npz  \
            --print-time \
                --repeat 100 \
                    resnet50-v2-7-tvm.tar
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Execution time summary:
 mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  
  51.8327      52.5906      67.5374      42.9440       4.4040   
               
</pre></div>
</div>
</div>
</div>
</section>
<section id="id9">
<h2>小结<a class="headerlink" href="#id9" title="永久链接至标题">#</a></h2>
<p>在本教程中，介绍了 TVMC，用于 TVM 的命令行驱动。演示了如何编译、运行和调优模型。还讨论了对输入和输出进行预处理和后处理的必要性。在调优过程之后，演示了如何比较未优化和优化后的模型的性能。</p>
<p>这里介绍了使用 ResNet-50 v2 本地的简单例子。然而，TVMC 支持更多的功能，包括交叉编译、远程执行和剖析/基准测试（profiling/benchmarking）。</p>
<p>要想知道还有哪些可用的选项，请看 <code class="docutils literal notranslate"><span class="pre">tvmc</span> <span class="pre">--help</span></code>。</p>
<p>在 <span class="xref myst">用 Python 接口编译和优化模型</span> 教程中，将使用 Python 接口介绍同样的编译和优化步骤。</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="introduction.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title">TVM 和模型优化的概述</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="tvmc_python.html" title="下一页 页">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">开始使用 TVMC Python：TVM 的高级 API</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By xinetzone<br/>
  
      &copy; Copyright 2022, xinetzone.<br/>
    Last updated on 2022-11-15, 10:47:58.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>