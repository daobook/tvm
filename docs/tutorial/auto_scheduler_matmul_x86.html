
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>使用自动调度优化运算 &#8212; TVM  文档</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/default.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="TensorIR 的突击课程" href="tensor_ir_blitz_course.html" />
    <link rel="prev" title="用调度模板和 AutoTVM 优化算子" href="autotvm_matmul_x86.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/tvm-logo-small.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TVM  文档</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   TVM 文档
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../start.html">
   快速上手
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../install/index.html">
     安装 TVM
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../install/from_source.html">
       从源码安装
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../install/nnpack.html">
         NNPACK Contrib Installation
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../install/docker.html">
       Docker 镜像
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../install/tlcpack.html">
       TLCPack
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../contribute/index.html">
     贡献者指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/community.html">
       TVM 社区指南
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/pull_request.html">
       提交 Pull Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/code_review.html">
       Code Reviews
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/committer_guide.html">
       Committer Guide
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/document.html">
       Documentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/code_guide.html">
       Code Guide and Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/git_howto.html">
       Git Usage Tips
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/ci.html">
       Using TVM’s CI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/release_process.html">
       Release Process
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../contribute/error_handling.html">
       Error Handling Guide
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../study/index.html">
   学习笔记
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../study/start.html">
     TVM 入门指南
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../study/test.html">
     测试 TVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../user-guide.html">
   用户手册
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     用户指南
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="introduction.html">
       TVM 和模型优化的概述
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tvmc_command_line_driver.html">
       用 TVMC 编译和优化模型
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tvmc_python.html">
       开始使用 TVMC Python：TVM 的高级 API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="autotvm_relay_x86.html">
       用 Python 接口编译和优化模型（AutoTVM）
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tensor_expr_get_started.html">
       使用张量表达式处理算子
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="autotvm_matmul_x86.html">
       用调度模板和 AutoTVM 优化算子
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       使用自动调度优化运算
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tensor_ir_blitz_course.html">
       TensorIR 的突击课程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="cross_compilation_and_rpc.html">
       交叉编译和RPC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="relay_quick_start.html">
       编译深度学习模型的快速入门教程
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="intro_topi.html">
       TOPI 简介
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../how_to/index.html">
     How To 指南
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/compile_models/index.html">
       编译深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_pytorch.html">
         编译 PyTorch 模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_tensorflow.html">
         Compile Tensorflow Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_mxnet.html">
         Compile MXNet Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_onnx.html">
         Compile ONNX Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_keras.html">
         Compile Keras Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_tflite.html">
         Compile TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_coreml.html">
         Compile CoreML Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_darknet.html">
         Compile YOLO-V2 and YOLO-V3 in DarkNet Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_caffe2.html">
         Compile Caffe2 Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/compile_models/from_paddle.html">
         Compile PaddlePaddle Models
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/deploy_models/index.html">
       部署深度学习模型
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_model_on_android.html">
         Deploy the Pretrained Model on Android
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_model_on_rasp.html">
         Deploy the Pretrained Model on Raspberry Pi
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_object_detection_pytorch.html">
         Compile PyTorch Object Detection Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_prequantized.html">
         使用 TVM 部署框架预量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_prequantized_tflite.html">
         Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_quantized.html">
         在 CUDA 上部署已量化模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_sparse.html">
         Deploy a Hugging Face Pruned Model on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/deploy_models/deploy_ssd_gluoncv.html">
         Deploy Single Shot Multibox Detector(SSD) model
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_relay/index.html">
       Work With Relay
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/build_gcn.html">
         Building a Graph Convolutional Network
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_relay/using_external_lib.html">
         Using External Libraries in Relay
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_schedules/index.html">
       使用 Tensor Expression 和 Schedules
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/schedule_primitives.html">
         Schedule Primitives in TVM
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/reduction.html">
         Reduction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/intrin_math.html">
         Intrinsics and Math Functions
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/scan.html">
         Scan and Recurrent Kernel
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/extern_op.html">
         External Tensor Functions
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tensorize.html">
         Use Tensorize to Leverage Hardware Intrinsics
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tuple_inputs.html">
         Compute and Reduce with Tuple Inputs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_schedules/tedd.html">
         Use Tensor Expression Debug Display (TEDD) for Visualization
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/optimize_operators/index.html">
       Optimize Tensor Operators
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_gemm.html">
         How to optimize GEMM on CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_conv_cuda.html">
         How to optimize convolution on GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/optimize_operators/opt_conv_tensorcore.html">
         How to optimize convolution using TensorCores
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/tune_with_autotvm/index.html">
       Auto-Tune with Templates and AutoTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_conv2d_cuda.html">
         Tuning High Performance Convolution on NVIDIA GPUs
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_cuda.html">
         Auto-tuning a Convolutional Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_x86.html">
         Auto-tuning a Convolutional Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_arm.html">
         Auto-tuning a Convolutional Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autotvm/tune_relay_mobile_gpu.html">
         Auto-tuning a Convolutional Network for Mobile GPU
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/tune_with_autoscheduler/index.html">
       Use AutoScheduler for Template-Free Scheduling
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.html">
         Auto-scheduling a Convolution Layer for GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_x86.html">
         Auto-scheduling a Neural Network for x86 CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_cuda.html">
         Auto-scheduling a Neural Network for NVIDIA GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_arm.html">
         Auto-scheduling a Neural Network for ARM CPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_network_mali.html">
         Auto-scheduling a Neural Network for mali GPU
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/tune_with_autoscheduler/tune_sparse_x86.html">
         Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/work_with_microtvm/index.html">
       使用 microTVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_autotune.html">
         使用 microTVM Autotuning
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_ethosu.html">
         在 bare metal Arm® Cortex®-M55 CPU 和 Ethos™-U55 NPU 上运行 TVM
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_reference_vm.html">
         microTVM 参考虚拟机
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_tflite.html">
         microTVM with TFLite Models
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/work_with_microtvm/micro_tvmc.html">
         Executing a Tiny Model with TVMC Micro
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/extend_tvm/index.html">
       Extend TVM
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/low_level_custom_pass.html">
         Writing a Customized Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/use_pass_infra.html">
         How to Use TVM Pass Infra
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/use_pass_instrument.html">
         How to Use TVM Pass Instrument
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/extend_tvm/bring_your_own_datatypes.html">
         Bring Your Own Datatypes to TVM
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../how_to/profile/index.html">
       Profile Models
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../how_to/profile/papi.html">
         Getting Started With PAPI
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../developer-guide.html">
   开发手册
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev/tutorial/index.html">
     开发者教程
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/tutorial/codebase_walkthrough.html">
       TVM 代码库的实例演练
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../dev/how_to/how_to.html">
     Developer How-To Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_add_op.html">
       Adding an Operator to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_add_pass.html">
       Adding a Compiler Pass to Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/relay_bring_your_own_codegen.html">
       Bring Your Own Codegen To TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../dev/how_to/pytest_target_parametrization.html">
       Python Target Parametrization
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../arch/index.html">
   设计与架构
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/runtime.html">
     TVM 运行时系统
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/debugger.html">
     Debugger
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/virtual_machine.html">
     Putting the VM in TVM: The Relay Virtual Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/introduction_to_module_serialization.html">
     Introduction to Module Serialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/device_target_interactions.html">
     Device/Target Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/pass_infra.html">
     Pass Infrastructure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/device_target_interactions.html">
     Device/Target Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/inferbound.html">
     InferBound Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/hybrid_script.html">
     Hybrid Frontend Developer Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/relay_intro.html">
     Introduction to Relay IR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/relay_op_strategy.html">
     Relay Operator Strategy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/convert_layout.html">
     Convert Layout Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/benchmark.html">
     Benchmark Performance Log Format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/frontend/tensorflow.html">
     TensorFlow Frontend
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/security.html">
     Security Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/microtvm_design.html">
     microTVM Design Document
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/microtvm_project_api.html">
     microTVM Project API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../arch/model_library_format.html">
     Model Library Format
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../topic-guides.html">
   主题指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../topic/microtvm/index.html">
     microTVM：裸机上的 TVM
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../topic/vta/index.html">
     VTA：通用张量加速器
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../topic/vta/install.html">
       VTA 安装指南
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../topic/vta/dev/index.html">
       VTA 设计和开发指南
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
      <label for="toctree-checkbox-25">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/dev/config.html">
         VTA 配置
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/dev/hardware.html">
         VTA 硬件指南
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../topic/vta/tutorials/index.html">
       VTA 教程
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
      <label for="toctree-checkbox-26">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/vta_get_started.html">
         VTA 入门
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/matrix_multiply.html">
         简单的矩阵乘法
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/frontend/index.html">
         编译深度学习模型
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/optimize/index.html">
         优化 Tensor 算子
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../topic/vta/tutorials/autotvm/index.html">
         自动调优
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../reference-guide.html">
   参考指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
  <label for="toctree-checkbox-27">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../reference/langref/index.html">
     语言参考
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
    <label for="toctree-checkbox-28">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_expr.html">
       Relay 表达式
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_type.html">
       Relay’s Type System
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_adt.html">
       Algebraic Data Types in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_op.html">
       Relay Core Tensor Operators
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/relay_pattern.html">
       Pattern Matching in Relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/langref/hybrid_script.html">
       Hybrid Frontend Language Reference
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../reference/api/python/index.html">
     Python API
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/runtime.html">
       tvm.runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ndarray.html">
       tvm.runtime.ndarray
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/error.html">
       tvm.error
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/ir.html">
       tvm.ir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/target.html">
       tvm.target
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/tir.html">
       tvm.tir
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/te.html">
       tvm.te
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/driver.html">
       tvm.driver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/index.html">
       tvm.relay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/frontend.html">
       tvm.relay.frontend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/nn.html">
       tvm.relay.nn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/vision.html">
       tvm.relay.vision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/image.html">
       tvm.relay.image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/transform.html">
       tvm.relay.transform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/analysis.html">
       tvm.relay.analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/backend.html">
       tvm.relay.backend
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/dataflow_pattern.html">
       tvm.relay.dataflow_pattern
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/relay/testing.html">
       tvm.relay.testing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/autotvm.html">
       tvm.autotvm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/auto_scheduler.html">
       tvm.auto_scheduler
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/rpc.html">
       tvm.rpc
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/micro.html">
       tvm.micro
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/contrib.html">
       tvm.contrib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/graph_executor.html">
       tvm.contrib.graph_executor
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/topi.html">
       tvm.topi
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../reference/api/python/vta/index.html">
       vta
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/api/links.html">
     其他 API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/publications.html">
     出版物
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../refs/index.html">
   参考
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../refs/_ffi/index.html">
     <code class="docutils literal notranslate">
      <span class="pre">
       _ffi
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/base.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.base
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/libinfo.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.libinfo
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/object.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi._ctypes.object
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/registry.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.registry
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../refs/_ffi/runtime_ctypes.html">
       <code class="docutils literal notranslate">
        <span class="pre">
         _ffi.runtime_ctypes
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/docs/tutorial/auto_scheduler_matmul_x86.ipynb.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> 导航
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   定义矩阵乘法
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   创建搜索任务
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   为自动调度设置参数
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   运行搜索
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   检查优化后的调度
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   检查正确性并评估性能
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   使用纪录文件
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   最后说明和总结
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>使用自动调度优化运算</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> 导航 </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   定义矩阵乘法
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   创建搜索任务
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   为自动调度设置参数
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   运行搜索
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   检查优化后的调度
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   检查正确性并评估性能
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   使用纪录文件
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   最后说明和总结
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="sphx-glr-tutorial-auto-scheduler-matmul-x86">
<span id="id1"></span><h1>使用自动调度优化运算<a class="headerlink" href="#sphx-glr-tutorial-auto-scheduler-matmul-x86" title="永久链接至标题">#</a></h1>
<p><strong>作者</strong>: <a class="reference external" href="https://github.com/merrymercy">Lianmin Zheng</a>，<a class="reference external" href="https://github.com/jcf94/">Chengfan Jia</a></p>
<p>在本教程中，我们将展示 TVM 的自动调度功能如何在不需要编写自定义模板的情况下找到最佳调度。</p>
<p>与基于模板的 <a class="reference internal" href="autotvm_matmul_x86.html"><span class="doc std std-doc">AutoTVM</span></a> 不同，后者依赖于手动模板来定义搜索空间，而自动调度器不需要任何模板。</p>
<p>用户只需要编写计算声明，而不需要任何调度命令或模板。自动调度器可以自动生成一个大的搜索空间，并在空间中找到一个好的调度。</p>
<p>本教程中我们以矩阵乘法为例。</p>
<div class="alert alert-info admonition hint">
<p class="admonition-title">提示</p>
<p>请注意，本教程不能在 Windows 或最近版本的 MacOS 上运行。为了让它运行，你需要将本教程的主体包裹在一个 <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">&quot;__main__&quot;:</span></code> 块中。</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">te</span><span class="p">,</span> <span class="n">auto_scheduler</span>
</pre></div>
</div>
</div>
</div>
<section id="id2">
<h2>定义矩阵乘法<a class="headerlink" href="#id2" title="永久链接至标题">#</a></h2>
<p>首先，我们定义一个带有偏置加法的矩阵乘法。注意，这使用了 TVM 张量表达式语言中的标准操作。主要的区别是在函数定义的顶部使用了 <code class="xref any docutils literal notranslate"><span class="pre">register_workload</span></code> 装饰器。该函数应该返回一个输入/输出张量的列表。从这些张量中，自动调度器可以得到整个计算图。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@auto_scheduler</span><span class="o">.</span><span class="n">register_workload</span>  <span class="c1"># 注意 auto_scheduler 装饰器</span>
<span class="k">def</span> <span class="nf">matmul_add</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">placeholder</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
    <span class="n">matmul</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
        <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span>
        <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">te</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;matmul&quot;</span><span class="p">,</span>
        <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;layout_free_placeholders&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">B</span><span class="p">]},</span>  <span class="c1"># 启用张量 B 的自动布局转换</span>
    <span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">te</span><span class="o">.</span><span class="n">compute</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">matmul</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;out&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">out</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h2>创建搜索任务<a class="headerlink" href="#id3" title="永久链接至标题">#</a></h2>
<p>在定义了函数之后，我们现在可以为 <code class="docutils literal notranslate"><span class="pre">auto_scheduler</span></code> 创建一个任务来进行搜索。我们指定这个矩阵乘法的特殊参数，在这个例子中，是对 <span class="math notranslate nohighlight">\(1024 \times 1024\)</span> 大小的正方形矩阵的乘法。然后我们使用 <code class="docutils literal notranslate"> <span class="pre">N=L=M=1024</span> <span class="pre">and</span> <span class="pre">dtype=&quot;float32&quot;</span></code> 创建一个搜索任务。</p>
<div class="admonition- admonition">
<p class="admonition-title">用自定义目标提高性能</p>
<p>为了使 TVM 能够充分利用特定的硬件平台，你需要手动指定你的 CPU 能力。例如：</p>
<ul class="simple">
<li><p>用 <code class="docutils literal notranslate"><span class="pre">llvm</span> <span class="pre">-mcpu=core-avx2</span></code> 替换下面的 <code class="docutils literal notranslate"><span class="pre">llvm</span></code>，以启用 AVX2</p></li>
<li><p>用 <code class="docutils literal notranslate"><span class="pre">llvm</span> <span class="pre">-mcpu=skylake-avx512</span></code> 替换下面的 <code class="docutils literal notranslate"><span class="pre">llvm</span></code>，以启用 AVX-512</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span><span class="p">(</span><span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">L</span> <span class="o">=</span> <span class="n">M</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">task</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">SearchTask</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">matmul_add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>

<span class="c1"># 检查计算图</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computational DAG:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">compute_dag</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Computational DAG:
A = PLACEHOLDER [1024, 1024]
B = PLACEHOLDER [1024, 1024]
matmul(i, j) += (A[i, k]*B[k, j])
C = PLACEHOLDER [1024, 1024]
out(i, j) = (matmul[i, j] + C[i, j])
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h2>为自动调度设置参数<a class="headerlink" href="#id4" title="永久链接至标题">#</a></h2>
<p>下一步，我们为自动调度设置参数。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_measure_trials</span></code> 是我们在搜索过程中可以使用的测量试验的数量。为了快速演示，我们在本教程中只做了 10 次试验。在实践中，1000 是一个很好的搜索收敛值。你可以根据你的时间预算做更多的试验。</p></li>
<li><p>此外，我们使用 <code class="xref any docutils literal notranslate"><span class="pre">RecordToFile</span></code> 来 log 测量记录到 <code class="docutils literal notranslate"><span class="pre">matmul.json</span></code> 文件中。这些测量记录可以用来查询历史最好的，恢复搜索，并在以后做更多的分析。</p></li>
<li><p>查阅 <code class="xref any docutils literal notranslate"><span class="pre">TuningOptions</span></code> 了解参数的更多信息。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_file</span> <span class="o">=</span> <span class="s2">&quot;matmul.json&quot;</span>
<span class="n">tune_option</span> <span class="o">=</span> <span class="n">auto_scheduler</span><span class="o">.</span><span class="n">TuningOptions</span><span class="p">(</span>
    <span class="n">num_measure_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">measure_callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">RecordToFile</span><span class="p">(</span><span class="n">log_file</span><span class="p">)],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h2>运行搜索<a class="headerlink" href="#id5" title="永久链接至标题">#</a></h2>
<p>现在我们把所有的输入准备好。很简单，不是吗？我们可以启动搜索，让自动调度发挥它的魔力。经过一些测量试验后，我们可以从日志文件中加载最佳调度并加以应用。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 运行 auto-tuning (search)</span>
<span class="n">task</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">tune_option</span><span class="p">)</span>
<span class="c1"># 应用最优 schedule</span>
<span class="n">sch</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">apply_best</span><span class="p">(</span><span class="n">log_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2021	fail_ct: 3	Time elapsed: 0.97
GA Iter: 0	Max score: 0.9996	Min score: 0.9289	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9853	#Pop: 128	#M+: 1379	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 4.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 10 programs to measure:
..........**********
==================================================
No: 1	GFLOPS: 4.11 / 4.11	results: MeasureResult(cost:[0.5229], error_no:0, all_cost:2.68, Tstamp:1642407662.03)
==================================================
Placeholder: A, B, C
matmul auto_unroll: 16
parallel i.0@j.0@i.1@j.1@ (0,2048)
  for k.0 (0,1024)
    for j.2 (0,32)
      for i.3 (0,16)
        matmul = ...
parallel i (0,1024)
  for j (0,1024)
    out = ...

==================================================
No: 2	GFLOPS: 22.56 / 22.56	results: MeasureResult(cost:[0.0952], error_no:0, all_cost:1.37, Tstamp:1642407662.65)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@ (0,8)
  matmul auto_unroll: 64
  for j.1 (0,32)
    for k.0 (0,256)
      for i.2 (0,128)
        for j.2 (0,4)
          for k.1 (0,4)
            vectorize j.3 (0,8)
              matmul = ...
  for i.1 (0,128)
    for j.1 (0,1024)
      out = ...

==================================================
No: 3	GFLOPS: 40.27 / 40.27	results: MeasureResult(cost:[0.0533], error_no:0, all_cost:0.86, Tstamp:1642407663.08)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@ (0,2048)
  matmul auto_unroll: 64
  for i.1 (0,32)
    for k.0 (0,64)
      for k.1 (0,16)
        for i.3 (0,4)
          vectorize j.3 (0,4)
            matmul = ...
  for i.1 (0,128)
    for j.1 (0,4)
      out = ...

==================================================
No: 4	GFLOPS: 4.62 / 40.27	results: MeasureResult(cost:[0.4649], error_no:0, all_cost:3.12, Tstamp:1642407665.17)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@ (0,32768)
  matmul auto_unroll: 64
  for i.1 (0,4)
    for j.1 (0,8)
      for k.0 (0,16)
        for k.1 (0,64)
          matmul = ...
  for i.1 (0,4)
    vectorize j.1 (0,8)
      out = ...

==================================================
No: 5	GFLOPS: 16.60 / 40.27	results: MeasureResult(cost:[0.1294], error_no:0, all_cost:1.74, Tstamp:1642407665.91)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@ (0,32)
  matmul auto_unroll: 16
  for i.1 (0,128)
    for j.1 (0,2)
      for k.0 (0,64)
        for j.2 (0,8)
          for k.1 (0,16)
            for i.3 (0,8)
              vectorize j.3 (0,2)
                matmul = ...
  for i.1 (0,1024)
    for j.1 (0,32)
      out = ...

==================================================
No: 6	GFLOPS: 34.80 / 40.27	results: MeasureResult(cost:[0.0617], error_no:0, all_cost:2.21, Tstamp:1642407666.39)
==================================================
Placeholder: A, B, C
matmul auto_unroll: 512
parallel i.0 (0,128)
  for j.0 (0,4)
    for j.1 (0,4)
      for k.0 (0,256)
        for i.2 (0,2)
          for j.2 (0,16)
            for k.1 (0,4)
              for i.3 (0,4)
                vectorize j.3 (0,4)
                  matmul = ...
parallel i (0,1024)
  for j (0,1024)
    out = ...

==================================================
No: 7	GFLOPS: 15.34 / 40.27	results: MeasureResult(cost:[0.1401], error_no:0, all_cost:1.32, Tstamp:1642407667.17)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@ (0,16384)
  matmul auto_unroll: 16
  for i.1 (0,8)
    for k.0 (0,64)
      for i.2 (0,2)
        for j.2 (0,2)
          for k.1 (0,16)
            vectorize j.3 (0,2)
              matmul = ...
  for i.1 (0,16)
    vectorize j.1 (0,4)
      out = ...

==================================================
No: 8	GFLOPS: 6.52 / 40.27	results: MeasureResult(cost:[0.3294], error_no:0, all_cost:1.68, Tstamp:1642407668.71)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@ (0,16384)
  for i.1 (0,32)
    matmul auto_unroll: 16
    for k.0 (0,16)
      for j.2 (0,2)
        for k.1 (0,64)
          matmul = ...
    vectorize j.2 (0,2)
      out = ...

==================================================
No: 9	GFLOPS: 51.38 / 51.38	results: MeasureResult(cost:[0.0418], error_no:0, all_cost:1.36, Tstamp:1642407669.10)
==================================================
Placeholder: A, B, C
parallel i.0@j.0@i.1@j.1@ (0,64)
  matmul auto_unroll: 64
  for k.0 (0,64)
    for i.2 (0,4)
      for j.2 (0,128)
        for k.1 (0,16)
          for i.3 (0,4)
            vectorize j.3 (0,8)
              matmul = ...
  for i.2 (0,16)
    for j.2 (0,1024)
      out = ...

==================================================
No: 10	GFLOPS: 5.34 / 51.38	results: MeasureResult(cost:[0.4025], error_no:0, all_cost:2.03, Tstamp:1642407670.94)
==================================================
Placeholder: A, B, C
matmul auto_unroll: 16
parallel i.0@j.0@ (0,1024)
  for i.1 (0,8)
    for j.1 (0,2)
      for k.0 (0,512)
        for i.2 (0,16)
          for j.2 (0,2)
            for k.1 (0,2)
              vectorize j.3 (0,2)
                matmul = ...
parallel i (0,1024)
  for j (0,1024)
    out = ...

Time elapsed for measurement: 14.31 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h2>检查优化后的调度<a class="headerlink" href="#id6" title="永久链接至标题">#</a></h2>
<p>我们可以 lower 调度，看看自动调度后的 IR。自动调度器正确地进行了优化，包括多级平铺（tiling）、布局转换（layout transformation）、并行化（parallelization）、矢量化（vectorization）、解卷（unrolling）和运算符融合（operator fusion）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lowered TIR:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Lowered TIR:
@main = primfn(A_1: handle, B_1: handle, C_1: handle, out_1: handle) -&gt; ()
  attr = {&quot;from_legacy_te_schedule&quot;: True, &quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True}
  buffers = {out: Buffer(out_2: Pointer(float32), float32, [1024, 1024], []),
             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),
             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),
             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], [])}
  buffer_map = {A_1: A, B_1: B, C_1: C, out_1: out} {
  allocate(auto_scheduler_layout_transform: Pointer(global float32), float32, [1048576]), storage_scope = global {
    for (ax4: int32, 0, 64) {
      for (ax5: int32, 0, 128) {
        for (ax6: int32, 0, 16) {
          for (ax7: int32, 0, 8) {
            auto_scheduler_layout_transform[((((ax4*16384) + (ax5*128)) + (ax6*8)) + ax7)] = (float32*)B_2[((((ax4*16384) + (ax6*1024)) + (ax5*8)) + ax7)]
          }
        }
      }
    }
    for (i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused: int32, 0, 64) &quot;parallel&quot; {
      allocate(matmul: Pointer(global float32), float32, [16384]), storage_scope = global {
        for (i.outer.inner.init: int32, 0, 4) {
          for (j.outer.inner.init: int32, 0, 128) {
            matmul[ramp(((i.outer.inner.init*4096) + (j.outer.inner.init*8)), 1, 8)] = broadcast(0f32, 8)
            matmul[ramp((((i.outer.inner.init*4096) + (j.outer.inner.init*8)) + 1024), 1, 8)] = broadcast(0f32, 8)
            matmul[ramp((((i.outer.inner.init*4096) + (j.outer.inner.init*8)) + 2048), 1, 8)] = broadcast(0f32, 8)
            matmul[ramp((((i.outer.inner.init*4096) + (j.outer.inner.init*8)) + 3072), 1, 8)] = broadcast(0f32, 8)
          }
        }
        for (k.outer: int32, 0, 64) {
          for (i.outer.inner: int32, 0, 4) {
            for (j.outer.inner: int32, 0, 128) {
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[(((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16))], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1024)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2048)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3072)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1025)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2049)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3073)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1026)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2050)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3074)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1027)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2051)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3075)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 4)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1028)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2052)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3076)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 5)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1029)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2053)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3077)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 6)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1030)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2054)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3078)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 7)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1031)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2055)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3079)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 8)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1032)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2056)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3080)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 9)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1033)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2057)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3081)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 10)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1034)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2058)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3082)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 11)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1035)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2059)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3083)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 12)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1036)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2060)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3084)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 13)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1037)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2061)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3085)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 14)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1038)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2062)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3086)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))
              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 15)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1039)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2063)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))
              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3087)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))
            }
          }
        }
        for (i.inner: int32, 0, 16) {
          for (j.inner: int32, 0, 1024) {
            out_2[(((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.inner*1024)) + j.inner)] = ((float32*)matmul[((i.inner*1024) + j.inner)] + (float32*)C_2[(((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.inner*1024)) + j.inner)])
          }
        }
      }
    }
  }
}
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h2>检查正确性并评估性能<a class="headerlink" href="#id7" title="永久链接至标题">#</a></h2>
<p>我们建立二进制文件，并检查其正确性（correctness）和性能（performance）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">a_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">out_np</span> <span class="o">=</span> <span class="n">a_np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b_np</span><span class="p">)</span> <span class="o">+</span> <span class="n">c_np</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">a_tvm</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">b_tvm</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">c_tvm</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">c_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">out_tvm</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_np</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">func</span><span class="p">(</span><span class="n">a_tvm</span><span class="p">,</span> <span class="n">b_tvm</span><span class="p">,</span> <span class="n">c_tvm</span><span class="p">,</span> <span class="n">out_tvm</span><span class="p">)</span>

<span class="c1"># Check results</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">out_np</span><span class="p">,</span> <span class="n">out_tvm</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># Evaluate execution time.</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="n">entry_name</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Execution time of this operator: </span><span class="si">%.3f</span><span class="s2"> ms&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">evaluator</span><span class="p">(</span><span class="n">a_tvm</span><span class="p">,</span> <span class="n">b_tvm</span><span class="p">,</span> <span class="n">c_tvm</span><span class="p">,</span> <span class="n">out_tvm</span><span class="p">)</span><span class="o">.</span><span class="n">results</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Execution time of this operator: 41.735 ms
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h2>使用纪录文件<a class="headerlink" href="#id8" title="永久链接至标题">#</a></h2>
<p>在搜索过程中，所有的测量记录都被 log 到记录文件 <code class="docutils literal notranslate"><span class="pre">matmul.json</span></code>。这些测量记录可以用来重新应用搜索结果，恢复搜索，并进行其他分析。</p>
<p>这里有一个例子，我们从一个文件中加载最佳调度，并打印出等效的 python 调度 API。这可以用于调试和学习自动调度的行为。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Equivalent python schedule:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">print_best</span><span class="p">(</span><span class="n">log_file</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Equivalent python schedule:
matmul_i, matmul_j, matmul_k = tuple(matmul.op.axis) + tuple(matmul.op.reduce_axis)
out_i, out_j = tuple(out.op.axis) + tuple(out.op.reduce_axis)
matmul_i_o_i, matmul_i_i = s[matmul].split(matmul_i, factor=4)
matmul_i_o_o_i, matmul_i_o_i = s[matmul].split(matmul_i_o_i, factor=4)
matmul_i_o_o_o, matmul_i_o_o_i = s[matmul].split(matmul_i_o_o_i, factor=2)
matmul_j_o_i, matmul_j_i = s[matmul].split(matmul_j, factor=8)
matmul_j_o_o_i, matmul_j_o_i = s[matmul].split(matmul_j_o_i, factor=128)
matmul_j_o_o_o, matmul_j_o_o_i = s[matmul].split(matmul_j_o_o_i, factor=1)
matmul_k_o, matmul_k_i = s[matmul].split(matmul_k, factor=16)
s[matmul].reorder(matmul_i_o_o_o, matmul_j_o_o_o, matmul_i_o_o_i, matmul_j_o_o_i, matmul_k_o, matmul_i_o_i, matmul_j_o_i, matmul_k_i, matmul_i_i, matmul_j_i)
out_i_o_i, out_i_i = s[out].split(out_i, factor=16)
out_i_o_o, out_i_o_i = s[out].split(out_i_o_i, factor=2)
out_j_o_i, out_j_i = s[out].split(out_j, factor=1024)
out_j_o_o, out_j_o_i = s[out].split(out_j_o_i, factor=1)
s[out].reorder(out_i_o_o, out_j_o_o, out_i_o_i, out_j_o_i, out_i_i, out_j_i)
s[matmul].compute_at(s[out], out_j_o_i)
out_i_o_o_j_o_o_fused_i_o_i_fused_j_o_i_fused = s[out].fuse(out_i_o_o, out_j_o_o, out_i_o_i, out_j_o_i)
s[out].parallel(out_i_o_o_j_o_o_fused_i_o_i_fused_j_o_i_fused)
s[matmul].pragma(matmul_i_o_o_o, &quot;auto_unroll_max_step&quot;, 64)
s[matmul].pragma(matmul_i_o_o_o, &quot;unroll_explicit&quot;, True)
s[matmul].vectorize(matmul_j_i)
</pre></div>
</div>
</div>
</div>
<p>一个更复杂的例子是恢复搜索。在这种情况下，我们需要自己创建搜索策略和成本模型，并通过日志文件恢复搜索策略和成本模型（cost model）的状态。在下面的例子中，我们恢复了状态并做了更多的 5 次试验。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resume_search</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">log_file</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Resume search:&quot;</span><span class="p">)</span>
    <span class="n">cost_model</span> <span class="o">=</span> <span class="n">auto_scheduler</span><span class="o">.</span><span class="n">XGBModel</span><span class="p">()</span>
    <span class="n">cost_model</span><span class="o">.</span><span class="n">update_from_file</span><span class="p">(</span><span class="n">log_file</span><span class="p">)</span>
    <span class="n">search_policy</span> <span class="o">=</span> <span class="n">auto_scheduler</span><span class="o">.</span><span class="n">SketchPolicy</span><span class="p">(</span>
        <span class="n">task</span><span class="p">,</span> <span class="n">cost_model</span><span class="p">,</span> <span class="n">init_search_callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">PreloadMeasuredStates</span><span class="p">(</span><span class="n">log_file</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="n">tune_option</span> <span class="o">=</span> <span class="n">auto_scheduler</span><span class="o">.</span><span class="n">TuningOptions</span><span class="p">(</span>
        <span class="n">num_measure_trials</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">measure_callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">RecordToFile</span><span class="p">(</span><span class="n">log_file</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="n">task</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">tune_option</span><span class="p">,</span> <span class="n">search_policy</span><span class="o">=</span><span class="n">search_policy</span><span class="p">)</span>

<span class="n">resume_search</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">log_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Resume search:
----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
SearchPolicy: Loaded 10 measurement records from matmul.json for [&quot;matmul_add&quot;, 1024, 1024, 1024, &quot;float32&quot;]
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2012	fail_ct: 5	Time elapsed: 1.68
GA Iter: 0	Max score: 0.9993	Min score: 0.9381	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9876	#Pop: 128	#M+: 1378	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 6.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 5 programs to measure:
.....*****
Time elapsed for measurement: 8.77 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
</section>
<section id="id9">
<h2>最后说明和总结<a class="headerlink" href="#id9" title="永久链接至标题">#</a></h2>
<p>在本教程中，我们已经展示了如何使用 TVM 自动调度器来自动优化矩阵乘法，而不需要指定搜索模板。它结束了一系列从张量表达式（Tensor Expression，简称 TE）语言开始的例子，展示了 TVM 如何优化计算操作。</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="autotvm_matmul_x86.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title">用调度模板和 AutoTVM 优化算子</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="tensor_ir_blitz_course.html" title="下一页 页">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">TensorIR 的突击课程</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By xinetzone<br/>
  
      &copy; Copyright 2022, xinetzone.<br/>
    Last updated on 2022-05-10, 16:59:25.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>