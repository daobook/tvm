{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 使用自动调度优化运算\n",
        "\n",
        "**作者**: [Lianmin Zheng](https://github.com/merrymercy)，[Chengfan Jia](https://github.com/jcf94/)\n",
        "\n",
        "在本教程中，我们将展示 TVM 的自动调度功能如何在不需要编写自定义模板的情况下找到最佳调度。\n",
        "\n",
        "与基于模板的 [AutoTVM](autotvm_matmul_x86) 不同，后者依赖于手动模板来定义搜索空间，而自动调度器不需要任何模板。\n",
        "\n",
        "用户只需要编写计算声明，而不需要任何调度命令或模板。自动调度器可以自动生成一个大的搜索空间，并在空间中找到一个好的调度。\n",
        "\n",
        "本教程中我们以矩阵乘法为例。\n",
        "\n",
        "```{hint}\n",
        ":class: alert alert-info\n",
        "\n",
        "请注意，本教程不能在 Windows 或最近版本的 MacOS 上运行。为了让它运行，你需要将本教程的主体包裹在一个 `if __name__ == \"__main__\":` 块中。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import te, auto_scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 定义矩阵乘法\n",
        "\n",
        "首先，我们定义一个带有偏置加法的矩阵乘法。注意，这使用了 TVM 张量表达式语言中的标准操作。主要的区别是在函数定义的顶部使用了 {any}`register_workload` 装饰器。该函数应该返回一个输入/输出张量的列表。从这些张量中，自动调度器可以得到整个计算图。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@auto_scheduler.register_workload  # 注意 auto_scheduler 装饰器\n",
        "def matmul_add(N, L, M, dtype):\n",
        "    A = te.placeholder((N, L), name=\"A\", dtype=dtype)\n",
        "    B = te.placeholder((L, M), name=\"B\", dtype=dtype)\n",
        "    C = te.placeholder((N, M), name=\"C\", dtype=dtype)\n",
        "\n",
        "    k = te.reduce_axis((0, L), name=\"k\")\n",
        "    matmul = te.compute(\n",
        "        (N, M),\n",
        "        lambda i, j: te.sum(A[i, k] * B[k, j], axis=k),\n",
        "        name=\"matmul\",\n",
        "        attrs={\"layout_free_placeholders\": [B]},  # 启用张量 B 的自动布局转换\n",
        "    )\n",
        "    out = te.compute((N, M), lambda i, j: matmul[i, j] + C[i, j], name=\"out\")\n",
        "    return [A, B, C, out]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建搜索任务\n",
        "\n",
        "在定义了函数之后，我们现在可以为 `auto_scheduler` 创建一个任务来进行搜索。我们指定这个矩阵乘法的特殊参数，在这个例子中，是对 $1024 \\times 1024$ 大小的正方形矩阵的乘法。然后我们使用 ` N=L=M=1024 and dtype=\"float32\"` 创建一个搜索任务。\n",
        "\n",
        "```{admonition} 用自定义目标提高性能\n",
        "为了使 TVM 能够充分利用特定的硬件平台，你需要手动指定你的 CPU 能力。例如：\n",
        "\n",
        "- 用 ``llvm -mcpu=core-avx2`` 替换下面的 ``llvm``，以启用 AVX2\n",
        "- 用 ``llvm -mcpu=skylake-avx512`` 替换下面的 ``llvm``，以启用 AVX-512\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computational DAG:\n",
            "A = PLACEHOLDER [1024, 1024]\n",
            "B = PLACEHOLDER [1024, 1024]\n",
            "matmul(i, j) += (A[i, k]*B[k, j])\n",
            "C = PLACEHOLDER [1024, 1024]\n",
            "out(i, j) = (matmul[i, j] + C[i, j])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "target = tvm.target.Target(\"llvm\")\n",
        "N = L = M = 1024\n",
        "task = tvm.auto_scheduler.SearchTask(func=matmul_add, args=(N, L, M, \"float32\"), target=target)\n",
        "\n",
        "# 检查计算图\n",
        "print(\"Computational DAG:\")\n",
        "print(task.compute_dag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 为自动调度设置参数\n",
        "\n",
        "下一步，我们为自动调度设置参数。\n",
        "\n",
        "* `num_measure_trials` 是我们在搜索过程中可以使用的测量试验的数量。为了快速演示，我们在本教程中只做了 10 次试验。在实践中，1000 是一个很好的搜索收敛值。你可以根据你的时间预算做更多的试验。\n",
        "* 此外，我们使用 {any}`RecordToFile <auto_scheduler.RecordToFile>` 来 log 测量记录到 `matmul.json` 文件中。这些测量记录可以用来查询历史最好的，恢复搜索，并在以后做更多的分析。\n",
        "* 查阅 {any}`TuningOptions <auto_scheduler.TuningOptions>` 了解参数的更多信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "log_file = \"matmul.json\"\n",
        "tune_option = auto_scheduler.TuningOptions(\n",
        "    num_measure_trials=10,\n",
        "    measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 运行搜索\n",
        "\n",
        "现在我们把所有的输入准备好。很简单，不是吗？我们可以启动搜索，让自动调度发挥它的魔力。经过一些测量试验后，我们可以从日志文件中加载最佳调度并加以应用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Search ]\n",
            "----------------------------------------------------------------------\n",
            "Generate Sketches\t\t#s: 3\n",
            "Sample Initial Population\t#s: 2021\tfail_ct: 3\tTime elapsed: 0.97\n",
            "GA Iter: 0\tMax score: 0.9996\tMin score: 0.9289\t#Pop: 128\t#M+: 0\t#M-: 0\n",
            "GA Iter: 4\tMax score: 0.9997\tMin score: 0.9853\t#Pop: 128\t#M+: 1379\t#M-: 71\n",
            "EvolutionarySearch\t\t#s: 128\tTime elapsed: 4.05\n",
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Measure ]\n",
            "----------------------------------------------------------------------\n",
            "Get 10 programs to measure:\n",
            "..........**********\n",
            "==================================================\n",
            "No: 1\tGFLOPS: 4.11 / 4.11\tresults: MeasureResult(cost:[0.5229], error_no:0, all_cost:2.68, Tstamp:1642407662.03)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "matmul auto_unroll: 16\n",
            "parallel i.0@j.0@i.1@j.1@ (0,2048)\n",
            "  for k.0 (0,1024)\n",
            "    for j.2 (0,32)\n",
            "      for i.3 (0,16)\n",
            "        matmul = ...\n",
            "parallel i (0,1024)\n",
            "  for j (0,1024)\n",
            "    out = ...\n",
            "\n",
            "==================================================\n",
            "No: 2\tGFLOPS: 22.56 / 22.56\tresults: MeasureResult(cost:[0.0952], error_no:0, all_cost:1.37, Tstamp:1642407662.65)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@ (0,8)\n",
            "  matmul auto_unroll: 64\n",
            "  for j.1 (0,32)\n",
            "    for k.0 (0,256)\n",
            "      for i.2 (0,128)\n",
            "        for j.2 (0,4)\n",
            "          for k.1 (0,4)\n",
            "            vectorize j.3 (0,8)\n",
            "              matmul = ...\n",
            "  for i.1 (0,128)\n",
            "    for j.1 (0,1024)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 3\tGFLOPS: 40.27 / 40.27\tresults: MeasureResult(cost:[0.0533], error_no:0, all_cost:0.86, Tstamp:1642407663.08)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@ (0,2048)\n",
            "  matmul auto_unroll: 64\n",
            "  for i.1 (0,32)\n",
            "    for k.0 (0,64)\n",
            "      for k.1 (0,16)\n",
            "        for i.3 (0,4)\n",
            "          vectorize j.3 (0,4)\n",
            "            matmul = ...\n",
            "  for i.1 (0,128)\n",
            "    for j.1 (0,4)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 4\tGFLOPS: 4.62 / 40.27\tresults: MeasureResult(cost:[0.4649], error_no:0, all_cost:3.12, Tstamp:1642407665.17)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@ (0,32768)\n",
            "  matmul auto_unroll: 64\n",
            "  for i.1 (0,4)\n",
            "    for j.1 (0,8)\n",
            "      for k.0 (0,16)\n",
            "        for k.1 (0,64)\n",
            "          matmul = ...\n",
            "  for i.1 (0,4)\n",
            "    vectorize j.1 (0,8)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 5\tGFLOPS: 16.60 / 40.27\tresults: MeasureResult(cost:[0.1294], error_no:0, all_cost:1.74, Tstamp:1642407665.91)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@ (0,32)\n",
            "  matmul auto_unroll: 16\n",
            "  for i.1 (0,128)\n",
            "    for j.1 (0,2)\n",
            "      for k.0 (0,64)\n",
            "        for j.2 (0,8)\n",
            "          for k.1 (0,16)\n",
            "            for i.3 (0,8)\n",
            "              vectorize j.3 (0,2)\n",
            "                matmul = ...\n",
            "  for i.1 (0,1024)\n",
            "    for j.1 (0,32)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 6\tGFLOPS: 34.80 / 40.27\tresults: MeasureResult(cost:[0.0617], error_no:0, all_cost:2.21, Tstamp:1642407666.39)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "matmul auto_unroll: 512\n",
            "parallel i.0 (0,128)\n",
            "  for j.0 (0,4)\n",
            "    for j.1 (0,4)\n",
            "      for k.0 (0,256)\n",
            "        for i.2 (0,2)\n",
            "          for j.2 (0,16)\n",
            "            for k.1 (0,4)\n",
            "              for i.3 (0,4)\n",
            "                vectorize j.3 (0,4)\n",
            "                  matmul = ...\n",
            "parallel i (0,1024)\n",
            "  for j (0,1024)\n",
            "    out = ...\n",
            "\n",
            "==================================================\n",
            "No: 7\tGFLOPS: 15.34 / 40.27\tresults: MeasureResult(cost:[0.1401], error_no:0, all_cost:1.32, Tstamp:1642407667.17)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@ (0,16384)\n",
            "  matmul auto_unroll: 16\n",
            "  for i.1 (0,8)\n",
            "    for k.0 (0,64)\n",
            "      for i.2 (0,2)\n",
            "        for j.2 (0,2)\n",
            "          for k.1 (0,16)\n",
            "            vectorize j.3 (0,2)\n",
            "              matmul = ...\n",
            "  for i.1 (0,16)\n",
            "    vectorize j.1 (0,4)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 8\tGFLOPS: 6.52 / 40.27\tresults: MeasureResult(cost:[0.3294], error_no:0, all_cost:1.68, Tstamp:1642407668.71)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@ (0,16384)\n",
            "  for i.1 (0,32)\n",
            "    matmul auto_unroll: 16\n",
            "    for k.0 (0,16)\n",
            "      for j.2 (0,2)\n",
            "        for k.1 (0,64)\n",
            "          matmul = ...\n",
            "    vectorize j.2 (0,2)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 9\tGFLOPS: 51.38 / 51.38\tresults: MeasureResult(cost:[0.0418], error_no:0, all_cost:1.36, Tstamp:1642407669.10)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "parallel i.0@j.0@i.1@j.1@ (0,64)\n",
            "  matmul auto_unroll: 64\n",
            "  for k.0 (0,64)\n",
            "    for i.2 (0,4)\n",
            "      for j.2 (0,128)\n",
            "        for k.1 (0,16)\n",
            "          for i.3 (0,4)\n",
            "            vectorize j.3 (0,8)\n",
            "              matmul = ...\n",
            "  for i.2 (0,16)\n",
            "    for j.2 (0,1024)\n",
            "      out = ...\n",
            "\n",
            "==================================================\n",
            "No: 10\tGFLOPS: 5.34 / 51.38\tresults: MeasureResult(cost:[0.4025], error_no:0, all_cost:2.03, Tstamp:1642407670.94)\n",
            "==================================================\n",
            "Placeholder: A, B, C\n",
            "matmul auto_unroll: 16\n",
            "parallel i.0@j.0@ (0,1024)\n",
            "  for i.1 (0,8)\n",
            "    for j.1 (0,2)\n",
            "      for k.0 (0,512)\n",
            "        for i.2 (0,16)\n",
            "          for j.2 (0,2)\n",
            "            for k.1 (0,2)\n",
            "              vectorize j.3 (0,2)\n",
            "                matmul = ...\n",
            "parallel i (0,1024)\n",
            "  for j (0,1024)\n",
            "    out = ...\n",
            "\n",
            "Time elapsed for measurement: 14.31 s\n",
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Done ]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 运行 auto-tuning (search)\n",
        "task.tune(tune_option)\n",
        "# 应用最优 schedule\n",
        "sch, args = task.apply_best(log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 检查优化后的调度\n",
        "\n",
        "我们可以 lower 调度，看看自动调度后的 IR。自动调度器正确地进行了优化，包括多级平铺（tiling）、布局转换（layout transformation）、并行化（parallelization）、矢量化（vectorization）、解卷（unrolling）和运算符融合（operator fusion）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lowered TIR:\n",
            "@main = primfn(A_1: handle, B_1: handle, C_1: handle, out_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {out: Buffer(out_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], [])}\n",
            "  buffer_map = {A_1: A, B_1: B, C_1: C, out_1: out} {\n",
            "  allocate(auto_scheduler_layout_transform: Pointer(global float32), float32, [1048576]), storage_scope = global {\n",
            "    for (ax4: int32, 0, 64) {\n",
            "      for (ax5: int32, 0, 128) {\n",
            "        for (ax6: int32, 0, 16) {\n",
            "          for (ax7: int32, 0, 8) {\n",
            "            auto_scheduler_layout_transform[((((ax4*16384) + (ax5*128)) + (ax6*8)) + ax7)] = (float32*)B_2[((((ax4*16384) + (ax6*1024)) + (ax5*8)) + ax7)]\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    for (i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused: int32, 0, 64) \"parallel\" {\n",
            "      allocate(matmul: Pointer(global float32), float32, [16384]), storage_scope = global {\n",
            "        for (i.outer.inner.init: int32, 0, 4) {\n",
            "          for (j.outer.inner.init: int32, 0, 128) {\n",
            "            matmul[ramp(((i.outer.inner.init*4096) + (j.outer.inner.init*8)), 1, 8)] = broadcast(0f32, 8)\n",
            "            matmul[ramp((((i.outer.inner.init*4096) + (j.outer.inner.init*8)) + 1024), 1, 8)] = broadcast(0f32, 8)\n",
            "            matmul[ramp((((i.outer.inner.init*4096) + (j.outer.inner.init*8)) + 2048), 1, 8)] = broadcast(0f32, 8)\n",
            "            matmul[ramp((((i.outer.inner.init*4096) + (j.outer.inner.init*8)) + 3072), 1, 8)] = broadcast(0f32, 8)\n",
            "          }\n",
            "        }\n",
            "        for (k.outer: int32, 0, 64) {\n",
            "          for (i.outer.inner: int32, 0, 4) {\n",
            "            for (j.outer.inner: int32, 0, 128) {\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[(((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16))], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1024)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2048)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3072)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp(((k.outer*16384) + (j.outer.inner*128)), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1025)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2049)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3073)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 8), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1026)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2050)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3074)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 16), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1027)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2051)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3075)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 24), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 4)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1028)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2052)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3076)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 32), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 5)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1029)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2053)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3077)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 40), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 6)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1030)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2054)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3078)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 48), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 7)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1031)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2055)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3079)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 56), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 8)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1032)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2056)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3080)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 64), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 9)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1033)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2057)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3081)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 72), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 10)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1034)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2058)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3082)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 80), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 11)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1035)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2059)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3083)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 88), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 12)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1036)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2060)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3084)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 96), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 13)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1037)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2061)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3085)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 104), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 14)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1038)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2062)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3086)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 112), 1, 8)]))\n",
            "              matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] = ((float32x8*)matmul[ramp(((i.outer.inner*4096) + (j.outer.inner*8)), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 15)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 1024), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 1039)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 2048), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 2063)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))\n",
            "              matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] = ((float32x8*)matmul[ramp((((i.outer.inner*4096) + (j.outer.inner*8)) + 3072), 1, 8)] + (broadcast((float32*)A_2[((((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.outer.inner*4096)) + (k.outer*16)) + 3087)], 8)*(float32x8*)auto_scheduler_layout_transform[ramp((((k.outer*16384) + (j.outer.inner*128)) + 120), 1, 8)]))\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        for (i.inner: int32, 0, 16) {\n",
            "          for (j.inner: int32, 0, 1024) {\n",
            "            out_2[(((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.inner*1024)) + j.inner)] = ((float32*)matmul[((i.inner*1024) + j.inner)] + (float32*)C_2[(((i.outer.outer.j.outer.outer.fused.i.outer.inner.fused.j.outer.inner.fused*16384) + (i.inner*1024)) + j.inner)])\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Lowered TIR:\")\n",
        "print(tvm.lower(sch, args, simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 检查正确性并评估性能\n",
        "\n",
        "我们建立二进制文件，并检查其正确性（correctness）和性能（performance）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time of this operator: 41.735 ms\n"
          ]
        }
      ],
      "source": [
        "func = tvm.build(sch, args, target)\n",
        "a_np = np.random.uniform(size=(N, L)).astype(np.float32)\n",
        "b_np = np.random.uniform(size=(L, M)).astype(np.float32)\n",
        "c_np = np.random.uniform(size=(N, M)).astype(np.float32)\n",
        "out_np = a_np.dot(b_np) + c_np\n",
        "\n",
        "dev = tvm.cpu()\n",
        "a_tvm = tvm.nd.array(a_np, device=dev)\n",
        "b_tvm = tvm.nd.array(b_np, device=dev)\n",
        "c_tvm = tvm.nd.array(c_np, device=dev)\n",
        "out_tvm = tvm.nd.empty(out_np.shape, device=dev)\n",
        "func(a_tvm, b_tvm, c_tvm, out_tvm)\n",
        "\n",
        "# Check results\n",
        "np.testing.assert_allclose(out_np, out_tvm.numpy(), rtol=1e-3)\n",
        "\n",
        "# Evaluate execution time.\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, min_repeat_ms=500)\n",
        "print(\n",
        "    \"Execution time of this operator: %.3f ms\"\n",
        "    % (np.median(evaluator(a_tvm, b_tvm, c_tvm, out_tvm).results) * 1000)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用纪录文件\n",
        "\n",
        "在搜索过程中，所有的测量记录都被 log 到记录文件 `matmul.json`。这些测量记录可以用来重新应用搜索结果，恢复搜索，并进行其他分析。\n",
        "\n",
        "这里有一个例子，我们从一个文件中加载最佳调度，并打印出等效的 python 调度 API。这可以用于调试和学习自动调度的行为。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equivalent python schedule:\n",
            "matmul_i, matmul_j, matmul_k = tuple(matmul.op.axis) + tuple(matmul.op.reduce_axis)\n",
            "out_i, out_j = tuple(out.op.axis) + tuple(out.op.reduce_axis)\n",
            "matmul_i_o_i, matmul_i_i = s[matmul].split(matmul_i, factor=4)\n",
            "matmul_i_o_o_i, matmul_i_o_i = s[matmul].split(matmul_i_o_i, factor=4)\n",
            "matmul_i_o_o_o, matmul_i_o_o_i = s[matmul].split(matmul_i_o_o_i, factor=2)\n",
            "matmul_j_o_i, matmul_j_i = s[matmul].split(matmul_j, factor=8)\n",
            "matmul_j_o_o_i, matmul_j_o_i = s[matmul].split(matmul_j_o_i, factor=128)\n",
            "matmul_j_o_o_o, matmul_j_o_o_i = s[matmul].split(matmul_j_o_o_i, factor=1)\n",
            "matmul_k_o, matmul_k_i = s[matmul].split(matmul_k, factor=16)\n",
            "s[matmul].reorder(matmul_i_o_o_o, matmul_j_o_o_o, matmul_i_o_o_i, matmul_j_o_o_i, matmul_k_o, matmul_i_o_i, matmul_j_o_i, matmul_k_i, matmul_i_i, matmul_j_i)\n",
            "out_i_o_i, out_i_i = s[out].split(out_i, factor=16)\n",
            "out_i_o_o, out_i_o_i = s[out].split(out_i_o_i, factor=2)\n",
            "out_j_o_i, out_j_i = s[out].split(out_j, factor=1024)\n",
            "out_j_o_o, out_j_o_i = s[out].split(out_j_o_i, factor=1)\n",
            "s[out].reorder(out_i_o_o, out_j_o_o, out_i_o_i, out_j_o_i, out_i_i, out_j_i)\n",
            "s[matmul].compute_at(s[out], out_j_o_i)\n",
            "out_i_o_o_j_o_o_fused_i_o_i_fused_j_o_i_fused = s[out].fuse(out_i_o_o, out_j_o_o, out_i_o_i, out_j_o_i)\n",
            "s[out].parallel(out_i_o_o_j_o_o_fused_i_o_i_fused_j_o_i_fused)\n",
            "s[matmul].pragma(matmul_i_o_o_o, \"auto_unroll_max_step\", 64)\n",
            "s[matmul].pragma(matmul_i_o_o_o, \"unroll_explicit\", True)\n",
            "s[matmul].vectorize(matmul_j_i)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Equivalent python schedule:\")\n",
        "print(task.print_best(log_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "一个更复杂的例子是恢复搜索。在这种情况下，我们需要自己创建搜索策略和成本模型，并通过日志文件恢复搜索策略和成本模型（cost model）的状态。在下面的例子中，我们恢复了状态并做了更多的 5 次试验。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume search:\n",
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Call init-search callbacks ]\n",
            "----------------------------------------------------------------------\n",
            "SearchPolicy: Loaded 10 measurement records from matmul.json for [\"matmul_add\", 1024, 1024, 1024, \"float32\"]\n",
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Search ]\n",
            "----------------------------------------------------------------------\n",
            "Generate Sketches\t\t#s: 3\n",
            "Sample Initial Population\t#s: 2012\tfail_ct: 5\tTime elapsed: 1.68\n",
            "GA Iter: 0\tMax score: 0.9993\tMin score: 0.9381\t#Pop: 128\t#M+: 0\t#M-: 0\n",
            "GA Iter: 4\tMax score: 0.9999\tMin score: 0.9876\t#Pop: 128\t#M+: 1378\t#M-: 78\n",
            "EvolutionarySearch\t\t#s: 128\tTime elapsed: 6.68\n",
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Measure ]\n",
            "----------------------------------------------------------------------\n",
            "Get 5 programs to measure:\n",
            ".....*****\n",
            "Time elapsed for measurement: 8.77 s\n",
            "----------------------------------------------------------------------\n",
            "------------------------------  [ Done ]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def resume_search(task, log_file):\n",
        "    print(\"Resume search:\")\n",
        "    cost_model = auto_scheduler.XGBModel()\n",
        "    cost_model.update_from_file(log_file)\n",
        "    search_policy = auto_scheduler.SketchPolicy(\n",
        "        task, cost_model, init_search_callbacks=[auto_scheduler.PreloadMeasuredStates(log_file)]\n",
        "    )\n",
        "    tune_option = auto_scheduler.TuningOptions(\n",
        "        num_measure_trials=5, measure_callbacks=[auto_scheduler.RecordToFile(log_file)]\n",
        "    )\n",
        "    task.tune(tune_option, search_policy=search_policy)\n",
        "\n",
        "resume_search(task, log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 最后说明和总结\n",
        "\n",
        "在本教程中，我们已经展示了如何使用 TVM 自动调度器来自动优化矩阵乘法，而不需要指定搜索模板。它结束了一系列从张量表达式（Tensor Expression，简称 TE）语言开始的例子，展示了 TVM 如何优化计算操作。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
