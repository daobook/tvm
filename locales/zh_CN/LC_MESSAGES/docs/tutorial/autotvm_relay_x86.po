# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-13 14:28+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20002
msgid "用 Python 接口编译和优化模型"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20004
msgid "**Author**: [Chris Hoge](https://github.com/hogepodge>)"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20006
msgid ""
"在 [TVMC 教程](tvmc_command_line_driver) 中，我们介绍了如何使用 TVM 的命令行界面 TVMC "
"来编译、运行和调整一个预训练的视觉模型 ResNet-50 v2。不过，TVM 不仅仅是一个命令行工具，它是一个优化框架，其 API "
"可用于许多不同的语言，在处理机器学习模型方面给你带来巨大的灵活性。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20008
msgid ""
"在本教程中，我们将涵盖与 TVMC 相同的内容，但展示如何用 Python API 来完成它。完成本节后，我们将使用 TVM 的 Python "
"API 来完成以下任务："
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20010
msgid "为 TVM 运行时编译一个预先训练好的 ResNet-50 v2 模型。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20011
msgid "通过编译后的模型运行真实图像，并解释输出和模型性能。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20012
msgid "使用 TVM 在 CPU 上调整该模型。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20013
msgid "使用 TVM 收集的调整数据重新编译一个优化的模型。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20014
msgid "通过优化后的模型运行图像，并比较输出和模型的性能。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20016
msgid "本节的目的是让你了解 TVM 的能力以及如何通过 Python API 使用它们。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20018
msgid ""
"TVM 是一个深度学习编译器框架，有许多不同的模块可用于处理深度学习模型和运算符。在本教程中，我们将研究如何使用 Python API "
"加载、编译和优化一个模型。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:20020
msgid ""
"我们首先要导入一些依赖关系，包括用于加载和转换模型的 ``onnx``，用于下载测试数据的辅助工具，用于处理图像数据的 Python "
"图像库，用于图像数据预处理和后处理的 ``numpy``，TVM Relay 框架，以及 TVM Graph Executor。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:40002
msgid "下载和加载 ONNX 模型"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:40004
msgid ""
"在本教程中，我们将使用 ResNet-50 v2。ResNet-50 是一个卷积神经网络，有 50 "
"层深度，旨在对图像进行分类。我们将使用的模型已经在超过一百万张图片上进行了预训练，有 1000 种不同的分类。该网络的输入图像大小为 "
"224x224。如果你有兴趣探索更多关于 ResNet-50 模型的结构，我们建议下载 "
"[Netron](https://netron.app)，一个免费的 ML 模型查看器。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:40006
msgid ""
"TVM 提供了一个辅助库来下载预训练的模型。通过该模块提供模型的 URL、文件名和模型类型，TVM 将下载模型并保存到磁盘。对于 ONNX "
"模型的实例，你就可以使用 ONNX 运行时将其加载到内存中。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:40008
msgid "与其他模型格式一起工作"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:1
msgid "TVM 支持许多流行的模型格式。清单可以在 TVM 文档的 [编译深度学习模型](tutorial-frontend) 部分找到。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:60002
msgid "下载、预处理和加载测试图像"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:60004
msgid ""
"当涉及到预期的张量形状、格式和数据类型时，每个模型都很特别。出于这个原因，大多数模型需要一些预处理和后处理，以确保输入是有效的，并解释输出。TVMC"
" 对输入和输出数据都采用了 NumPy 的 ``.npz`` 格式。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:60006
msgid "作为本教程的输入，我们将使用一只猫的图像，但你可以自由地用你选择的任何图像来代替这个图像。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:60010
msgid "下载图像数据，然后将其转换成一个 numpy 数组，作为模型的输入。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:80002
msgid "用 Relay 编译模型"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:80004
msgid ""
"下一步是编译 ResNet 模型。我们首先使用 `from_onnx` 导入器将模型导入到 relay。然后，我们将模型与标准优化一起构建成一个 "
"TVM 库。最后，我们从该库中创建一个 TVM 图运行时模块。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:100002
msgid "定义正确的目标"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:1
msgid ""
"指定正确的目标可以对编译后的模块的性能产生巨大影响，因为它可以利用目标上可用的硬件特性。欲了解更多信息，请参考为 [x86 CPU "
"自动调整卷积网络](tune_relay_x86)。我们建议确定你运行的是哪种 CPU，以及可选的功能，并适当地设置目标。例如，对于某些处理器， "
"`target = \"llvm -mcpu=skylake\"`，或者对于具有 AVX-512 向量指令集的处理器， `target = "
"\"llvm-mcpu=skylake-avx512\"`。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:120002
msgid "在 TVM 运行时上执行"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:120004
msgid "现在我们已经编译了模型，我们可以使用 TVM 运行时来进行预测。要使用 TVM 来运行模型并进行预测，我们需要两样东西："
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:120006
msgid "编译后的模型，也就是我们刚刚制作的模型。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:120007
msgid "对模型的有效输入，以便进行预测。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:140002
msgid "收集基本性能数据"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:140004
msgid ""
"我们想收集一些与这个未优化的模型相关的基本性能数据，并在以后与调整后的模型进行比较。为了帮助说明 CPU "
"的噪音，我们在多个批次的重复中运行计算，然后收集一些关于平均值、中位数和标准差的基础统计数据。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:160002
msgid "对输出进行后处理"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:160004
msgid "如前所述，每个模型都有自己提供输出张量的特殊方式。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:160006
msgid "在我们的案例中，我们需要运行一些后处理，利用为模型提供的查找表，将 ResNet-50 v2 的输出渲染成更适合人类阅读的形式。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180002
msgid "调优模型"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180004
msgid ""
"之前的模型是为了在 TVM 运行时工作而编译的，但不包括任何特定平台的优化。在本节中，我们将向你展示如何使用 TVM "
"建立一个针对你工作平台的优化模型。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180006
msgid ""
"在某些情况下，当使用我们编译的模块运行推理时，我们可能无法获得预期的性能。在这种情况下，我们可以利用自动调谐器，为我们的模型找到一个更好的配置，获得性能的提升。TVM"
" "
"中的调谐是指对模型进行优化以在给定目标上更快地运行的过程。这与训练或微调不同，因为它不影响模型的准确性，而只影响运行时的性能。作为调优过程的一部分，TVM"
" 将尝试运行许多不同的运算器实现变体，以观察哪些运算器表现最佳。这些运行的结果被储存在调优记录文件中。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180008
msgid "在最简单的形式下，调优需要你提供三样东西："
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180010
msgid "你打算在上面运行这个模型的设备的目标规格"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180011
msgid "输出文件的路径，调优记录将被存储在该文件中"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:180012
msgid "要调优的模型的路径"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:200002
msgid ""
"为运行器设置一些基本参数。运行器采用一组特定参数生成的编译代码，并测量其性能。``number`` 指定我们将测试的不同配置的数量，而 "
"``repeat`` 指定我们将对每个配置进行多少次测量。``min_repeat_ms`` "
"是一个值，指定需要多长时间运行配置测试。如果重复次数低于这个时间，它将被增加。这个选项对于在 GPU 上进行精确的调优是必要的，而对于 CPU "
"的调优则不需要。把这个值设置为 0 可以禁用它。``timeout`` 为每个测试的配置运行训练代码的时间设置了上限。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:220002
msgid ""
"创建一个简单的结构来保存调谐选项。我们使用一个 XGBoost 算法来指导搜索。对于一个生产作业来说，你会想把试验的数量设置得比这里使用的 10 "
"的值大。对于 CPU，我们推荐 1500，对于 GPU，推荐 "
"3000-4000。所需的试验次数可能取决于特定的模型和处理器，因此值得花一些时间来评估各种数值的性能，以找到调整时间和模型优化之间的最佳平衡。因为运行调谐是需要时间的，我们将试验次数设置为"
" 10 次，但不建议使用这么小的值。``early_stopping`` "
"参数是在应用提前停止搜索的条件之前，要运行的最小轨数。``measure`` "
"选项表示将在哪里建立试验代码，以及将在哪里运行。在这种情况下，我们使用刚刚创建的 ``LocalRunner`` 和一个 "
"``LocalBuilder``。``tuning_records`` 选项指定了一个文件来写入调整数据。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:240002
msgid "定义调谐搜索算法"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:1
msgid "默认情况下，这种搜索是使用 XGBoost 网格算法指导的。根据你的模型的复杂性和可用的时间量，你可能想选择一个不同的算法。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:240006
msgid "设置调谐参数"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:1
msgid ""
"在这个例子中，为了节省时间，我们将试验次数和提前停止设置为 "
"10。如果你把这些值设置得更高，你可能会看到更多的性能改进，但这是以花时间调整为代价的。收敛所需的试验次数将取决于模型和目标平台的具体情况。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:260002
msgid "用调优数据编译优化后的模型"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:260004
msgid ""
"作为上述调优过程的输出，我们获得了存储在 ``resnet-50-v2-autotuning.json`` "
"的调优记录。编译器将使用这些结果，在你指定的目标上为模型生成高性能代码。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:260006
msgid "现在，模型的调优数据已经收集完毕，我们可以使用优化的运算符重新编译模型，以加快我们的计算速度。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:280002
msgid "验证优化后的模型是否运行并产生相同的结果："
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:300002
msgid "比较已调谐和未调谐的模型"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:300004
msgid "我们想收集一些与这个优化模型相关的基本性能数据，将其与未优化的模型进行比较。根据你的底层硬件、迭代次数和其他因素，你应该看到优化后的模型与未优化的模型相比有性能的提高。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:320002
msgid "小结"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:320004
msgid ""
"在本教程中，我们介绍了 TVMC，一个用于 TVM "
"的命令行驱动。我们演示了如何编译、运行和调优一个模型。我们还讨论了对输入和输出进行预处理和后处理的必要性。在调优过程之后，我们演示了如何比较未优化和优化后的模型的性能。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:320006
msgid ""
"这里我们介绍了一个使用 ResNet-50 v2 本地的简单例子。然而，TVMC "
"支持更多的功能，包括交叉编译、远程执行和剖析/基准测试（profiling/benchmarking）。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:320008
msgid ""
"在本教程中，我们举了一个简短的例子，说明如何使用 TVM Python API "
"来编译、运行和调整一个模型。我们还讨论了对输入和输出进行预处理和后处理的必要性。在调优过程之后，我们演示了如何比较未优化和优化后的模型的性能。"
msgstr ""

#: ../../user-guide/tutorial/autotvm_relay_x86.ipynb:320010
msgid "这里我们介绍了一个使用 ResNet-50 v2 本地的简单例子。然而，TVM 支持更多的功能，包括交叉编译、远程执行和剖析/基准测试。"
msgstr ""

