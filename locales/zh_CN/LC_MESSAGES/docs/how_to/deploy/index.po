# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# xinetzone <735613050@qq.com>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-10 21:32+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: xinetzone <735613050@qq.com>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../docs/how_to/deploy/index.rst:21
msgid "Deploy Models and Integrate TVM"
msgstr "部署模型和集成 TVM"

#: ../../docs/how_to/deploy/index.rst:23
msgid ""
"This page contains guidelines on how to deploy TVM to various platforms "
"as well as how to integrate it with your project."
msgstr ""
"这个页面包含了关于如何将 TVM 部署到各种平台以及如何将其与你的项目集成的指南。"

#: ../../docs/how_to/deploy/index.rst:29
msgid "Build the TVM runtime library"
msgstr "构建 TVM 运行时库"

#: ../../docs/how_to/deploy/index.rst:33
msgid ""
"Unlike traditional deep learning frameworks. TVM stack is divided into "
"two major components:"
msgstr ""
"与传统的深度学习框架不同。TVM 堆栈分为两个主要部分："

#: ../../docs/how_to/deploy/index.rst:35
msgid ""
"TVM compiler, which does all the compilation and optimizations of the "
"model"
msgstr ""
"TVM 编译器，它对模型进行所有的编译和优化"

#: ../../docs/how_to/deploy/index.rst:36
msgid "TVM runtime, which runs on the target devices."
msgstr "TVM 运行时，它在目标设备上运行。"

#: ../../docs/how_to/deploy/index.rst:38
msgid ""
"In order to integrate the compiled module, we **do not** need to build "
"entire TVM on the target device. You only need to build the TVM compiler "
"stack on your desktop and use that to cross-compile modules that are "
"deployed on the target device."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:42
msgid ""
"We only need to use a light-weight runtime API that can be integrated "
"into various platforms."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:44
msgid ""
"For example, you can run the following commands to build the runtime API "
"on a Linux based embedded system such as Raspberry Pi:"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:57
msgid "Note that we type ``make runtime`` to only build the runtime library."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:59
msgid ""
"It is also possible to cross compile the runtime. Cross compiling the "
"runtime library should not be confused with cross compiling models for "
"embedded devices."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:63
msgid ""
"If you want to include additional runtime such as OpenCL, you can modify "
"``config.cmake`` to enable these options. After you get the TVM runtime "
"library, you can link the compiled library"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:71
msgid ""
"A model (optimized or not by TVM) can be cross compiled by TVM for "
"different architectures such as ``aarch64`` on a ``x64_64`` host. Once "
"the model is cross compiled it is neccessary to have a runtime compatible"
" with the target architecture to be able to run the cross compiled model."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:78
msgid "Cross compile the TVM runtime for other architectures"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:80
msgid ""
"In the example :ref:`above <build-tvm-runtime-on-target-device>` the "
"runtime library was compiled on a Raspberry Pi. Producing the runtime "
"library can be done much faster on hosts that have high performace "
"processors with ample resources (such as laptops, workstation) compared "
"to a target devices such as a Raspberry Pi. In-order to cross compile the"
" runtime the toolchain for the target device must be installed. After "
"installing the correct toolchain, the main difference compared to "
"compiling natively is to pass some additional command line argument to "
"cmake that specify a toolchain to be used. For reference building the TVM"
" runtime library on a modern laptop (using 8 threads) for ``aarch64`` "
"takes around 20 seconds vs ~10 min to build the runtime on a Raspberry Pi"
" 4."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:91
msgid "cross-compile for aarch64"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:112
msgid ""
"For bare metal ARM devices the following toolchain is quite handy to "
"install instead of gcc-aarch64-linux-*"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:120
msgid "cross-compile for RISC-V"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:142
msgid ""
"The ``file`` command can be used to query the architecture of the "
"produced runtime."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:152
msgid "Optimize and tune models for target devices"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:154
msgid ""
"The easiest and recommended way to test, tune and benchmark TVM kernels "
"on embedded devices is through TVM's RPC API. Here are the links to the "
"related tutorials."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:158
msgid ":ref:`tutorial-cross-compilation-and-rpc`"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:159
msgid ":ref:`tutorial-deploy-model-on-rasp`"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:162
msgid "Deploy optimized model on target devices"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:164
msgid ""
"After you finished tuning and benchmarking, you might need to deploy the "
"model on the target device without relying on RPC. See the following "
"resources on how to do so."
msgstr ""

#: ../../docs/how_to/deploy/index.rst:180
msgid "Additional Deployment How-Tos"
msgstr ""

#: ../../docs/how_to/deploy/index.rst:182
msgid ""
"We have also developed a number of how-tos targeting specific devices, "
"with working Python code that can be viewed in a Jupyter notebook. These "
"how-tos describe how to prepare and deploy models to many of the "
"supported backends."
msgstr ""

