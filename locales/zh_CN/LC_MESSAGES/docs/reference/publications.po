# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-10 21:32+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../docs/reference/publications.rst:19
msgid "Publications"
msgstr "出版物"

#: ../../docs/reference/publications.rst:21
msgid ""
"TVM is developed as part of peer-reviewed research in machine learning "
"compiler framework for CPUs, GPUs, and machine learning accelerators."
msgstr ""
"TVM 是作为 CPU、GPU 和机器学习加速器的机器学习编译器框架的同行评审研究的一部分而开发的。"

#: ../../docs/reference/publications.rst:24
msgid ""
"This document includes references to publications describing the "
"research, results, and design underlying TVM."
msgstr ""
"本文档包括对描述 TVM 基础研究、结果和设计的出版物的参考。"

#: ../../docs/reference/publications.rst:27
msgid ""
"`TVM: An Automated End-to-End Optimizing Compiler for Deep Learning "
"<https://arxiv.org/abs/1802.04799>`_"
msgstr ""
"`TVM: 用于深度学习的自动端到端优化编译器 "
"<https://arxiv.org/abs/1802.04799>`_"

#: ../../docs/reference/publications.rst:28
msgid ""
"`Learning to Optimize Tensor Programs "
"<https://arxiv.org/pdf/1805.08166.pdf>`_"
msgstr ""
"`学习优化张量程序 "
"<https://arxiv.org/pdf/1805.08166.pdf>`_"

#: ../../docs/reference/publications.rst:29
msgid ""
"`Ansor: Generating High-Performance Tensor Programs for Deep Learning "
"<https://arxiv.org/abs/2006.06762>`_"
msgstr ""
"`Ansor: 为深度学习生成高性能的张量程序 "
"<https://arxiv.org/abs/2006.06762>`_"

#: ../../docs/reference/publications.rst:30
msgid ""
"`Nimble: Efficiently Compiling Dynamic Neural Networks for Model "
"Inference <https://arxiv.org/abs/2006.03031>`_"
msgstr ""
"`Nimble: 高效地编译动态神经网络的模型推理 "
"<https://arxiv.org/abs/2006.03031>`_"
